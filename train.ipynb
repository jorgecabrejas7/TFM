{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4531,
     "status": "ok",
     "timestamp": 1692365819133,
     "user": {
      "displayName": "Jorge Cabrejas",
      "userId": "11610545751064957174"
     },
     "user_tz": -120
    },
    "id": "14joatIQJYTe",
    "outputId": "9dfa49dd-a1b1-482e-d44e-ab8b1757f5a4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 17:27:40.492060: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-14 17:27:40.519430: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-14 17:27:40.982224: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from typing import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import (\n",
    "    LSTM,\n",
    "    BatchNormalization,\n",
    "    Concatenate,\n",
    "    Conv1D,\n",
    "    ConvLSTM1D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    Layer,\n",
    "    LayerNormalization,\n",
    "    MaxPooling1D,\n",
    "    MultiHeadAttention,\n",
    ")\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.utils import Sequence\n",
    "# from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "# from keras_tuner.tuners import BayesianOptimization, Hyperband\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.callbacks import (\n",
    "    BackupAndRestore,\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    ReduceLROnPlateau,\n",
    "    TensorBoard,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from metrics_tf import MBE, SMAPE, pearsons_r, r2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "\n",
    "DRIVE_PATH = \"/content/drive/MyDrive/TFM\"\n",
    "# PATH = os.path.join(DRIVE_PATH, \"data\")\n",
    "PATH = \"./data\"\n",
    "SYMBOLS = [\"ADA\", \"BNB\", \"BTC\", \"EOS\", \"ETH\", \"LTC\", \"TRX\", \"VET\", \"XRP\"]\n",
    "\n",
    "\n",
    "def to_csvf(x):\n",
    "    return x + \"USDT.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3860,
     "status": "ok",
     "timestamp": 1692365822992,
     "user": {
      "displayName": "Jorge Cabrejas",
      "userId": "11610545751064957174"
     },
     "user_tz": -120
    },
    "id": "sVNAkcFcJYju",
    "outputId": "1dbd9ad5-2307-460b-ba66-1e2cff14659c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1839, 750, 5), (1839, 24))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_file(symbol: str, tf: str, timestamp_unit: str = \"ms\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a CSV file, assigns column names, converts the 'date' column to datetime,\n",
    "    and sets it as the DataFrame's index.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    symbol : str\n",
    "        The symbol.\n",
    "    tf : str\n",
    "        The tf.\n",
    "    timestamp_unit : str, default 'ms'\n",
    "        The unit of the timestamp in the 'date' column. By default, it's 'ms' (milliseconds).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The DataFrame with the 'date' column converted to datetime and set as the index.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(to_csvf(os.path.join(PATH, tf, symbol)), header=None).iloc[:, 0:6]\n",
    "    df.columns = [\"date\", \"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], unit=timestamp_unit)\n",
    "    df.set_index(\"date\", inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_input_tensor(data, lookback=250 * 3):\n",
    "    inputs = []\n",
    "    for i in range(0, len(data) - lookback, 3):\n",
    "        inputs.append(data.iloc[i : i + lookback].values)\n",
    "        # if i < 24: print(data.iloc[i+lookback])\n",
    "\n",
    "    return np.array(inputs)\n",
    "\n",
    "\n",
    "def create_target_tensor(data_dict):\n",
    "    # Step 1: Create a dataframe with closing prices for each currency\n",
    "    close_prices_df = pd.DataFrame(\n",
    "        {symbol: df[\"close\"] for symbol, df in data_dict.items()}\n",
    "    ).dropna()\n",
    "    # Step 2: Repeat each value three times\n",
    "    # print(close_prices_df)\n",
    "    target_array = np.array(\n",
    "        close_prices_df.apply(\n",
    "            lambda x: np.array([item for item in x for _ in range(3)]), axis=1\n",
    "        ).values\n",
    "    )\n",
    "\n",
    "    return np.vstack(target_array)\n",
    "\n",
    "\n",
    "def prepare_data(PATH):\n",
    "    # 1. Read BTC hourly data\n",
    "    btc_data = read_file(\"BTC\", \"8h\")\n",
    "    # Create a new index to fill missing values\n",
    "    full_index = pd.date_range(btc_data.index.min(), btc_data.index.max(), freq=\"8H\")\n",
    "    df_full = pd.DataFrame(index=full_index)\n",
    "    # Create the new dataframe forwarding missing values\n",
    "    btc_data = df_full.merge(\n",
    "        btc_data, left_index=True, right_index=True, how=\"left\"\n",
    "    ).fillna(method=\"ffill\")\n",
    "    # 2. Read other currencies' daily data\n",
    "    daily_data = {}\n",
    "    for symbol in SYMBOLS:\n",
    "        if symbol != \"BTC\":\n",
    "            daily_data[symbol] = read_file(f\"{symbol}\", \"1d\")\n",
    "\n",
    "    # 3. Find overlapping date range\n",
    "    min_date = btc_data.index.min()\n",
    "    max_date = btc_data.index.max()\n",
    "    for df in daily_data.values():\n",
    "        min_date = max(min_date, df.index.min())\n",
    "        max_date = min(max_date, df.index.max())\n",
    "\n",
    "    # 4. Prune each dataset to the overlapping range\n",
    "    btc_data = btc_data.loc[min_date - pd.Timedelta(days=250) : max_date]\n",
    "    for symbol in daily_data:\n",
    "        daily_data[symbol] = daily_data[symbol].loc[min_date:max_date]\n",
    "    # 5. Scale the BTC data and each feature separately\n",
    "    scalers_btc = {}\n",
    "    for col in btc_data.columns:\n",
    "        scaler = MinMaxScaler()\n",
    "        btc_data[col] = scaler.fit_transform(btc_data[col].values.reshape(-1, 1))\n",
    "        scalers_btc[col] = scaler\n",
    "\n",
    "    # Create input tensor from scaled BTC hourly data\n",
    "\n",
    "    input_tensor = create_input_tensor(btc_data)\n",
    "    # 6. Scale target data (Close Price) for each currency\n",
    "    scalers_targets = {}\n",
    "    scaled_targets = {}\n",
    "    for symbol, df in daily_data.items():\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled_data = scaler.fit_transform(df[\"close\"].values.reshape(-1, 1))\n",
    "        scaled_targets[symbol] = pd.DataFrame(\n",
    "            scaled_data, columns=[\"close\"], index=df.index\n",
    "        )  # Save the scaled data as dataframe\n",
    "        scalers_targets[symbol] = scaler\n",
    "    # Create target tensor using scaled data\n",
    "    train_means = {\n",
    "        name: np.mean(value.close[int(value.index.size * 0.7) :].values)\n",
    "        for name, value in scaled_targets.items()\n",
    "    }\n",
    "    target_tensors = create_target_tensor(scaled_targets)\n",
    "\n",
    "    return input_tensor, target_tensors, scalers_btc, scalers_targets, train_means\n",
    "\n",
    "\n",
    "# Use the function\n",
    "input_data, target_data, btc_scalers, target_scalers, means = prepare_data(PATH)\n",
    "#\n",
    "# target_data = target_data.reshape(-1, 24, 1)\n",
    "input_data.shape, target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1692365822993,
     "user": {
      "displayName": "Jorge Cabrejas",
      "userId": "11610545751064957174"
     },
     "user_tz": -120
    },
    "id": "r1Z47IYZJYtD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Time2Vec(Layer):\n",
    "    def __init__(self, output_dim=None, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(Time2Vec, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(\n",
    "            name=\"W\",\n",
    "            shape=(input_shape[-1], self.output_dim),\n",
    "            initializer=\"uniform\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.P = self.add_weight(\n",
    "            name=\"P\",\n",
    "            shape=(input_shape[1], self.output_dim),\n",
    "            initializer=\"uniform\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.w = self.add_weight(\n",
    "            name=\"w\", shape=(input_shape[1], 1), initializer=\"uniform\", trainable=True\n",
    "        )\n",
    "        self.p = self.add_weight(\n",
    "            name=\"p\", shape=(input_shape[1], 1), initializer=\"uniform\", trainable=True\n",
    "        )\n",
    "        super(Time2Vec, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        original = self.w * x + self.p\n",
    "        sin_trans = K.sin(K.dot(x, self.W) + self.P)\n",
    "\n",
    "        return K.concatenate([sin_trans, original], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1692365822993,
     "user": {
      "displayName": "Jorge Cabrejas",
      "userId": "11610545751064957174"
     },
     "user_tz": -120
    },
    "id": "dFLbshkQJY23",
    "outputId": "56f852db-1f16-4b19-c0cf-2ca222d98ef5",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1287, 750, 5),\n",
       " (276, 750, 5),\n",
       " (276, 750, 5),\n",
       " (1287, 24),\n",
       " (276, 24),\n",
       " (276, 24))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the indices for the splits\n",
    "index_70_percent = int(0.7 * len(input_data))\n",
    "index_85_percent = int(0.85 * len(input_data))\n",
    "\n",
    "# Splitting the data into train, validation, and test sets\n",
    "train_input = input_data[:index_70_percent]\n",
    "train_target = target_data[:index_70_percent]\n",
    "\n",
    "valid_input = input_data[index_70_percent:index_85_percent]\n",
    "valid_target = target_data[index_70_percent:index_85_percent]\n",
    "\n",
    "test_input = input_data[index_85_percent:]\n",
    "test_target = target_data[index_85_percent:]\n",
    "\n",
    "train_input.shape, valid_input.shape, test_input.shape, train_target.shape, valid_target.shape, test_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_0_1_prediction': ['mse',\n",
       "  <function metrics_tf.pearsons_r(y_true, y_pred)>,\n",
       "  <function metrics_tf.SMAPE(y_true, y_pred)>,\n",
       "  <function metrics_tf.MBE(y_true, y_pred)>,\n",
       "  <function metrics_tf.r2.<locals>.R2(y_true, y_pred)>],\n",
       " 'output_1_1_prediction': ['mse',\n",
       "  <function metrics_tf.pearsons_r(y_true, y_pred)>,\n",
       "  <function metrics_tf.SMAPE(y_true, y_pred)>,\n",
       "  <function metrics_tf.MBE(y_true, y_pred)>,\n",
       "  <function metrics_tf.r2.<locals>.R2(y_true, y_pred)>],\n",
       " 'output_2_1_prediction': ['mse',\n",
       "  <function metrics_tf.pearsons_r(y_true, y_pred)>,\n",
       "  <function metrics_tf.SMAPE(y_true, y_pred)>,\n",
       "  <function metrics_tf.MBE(y_true, y_pred)>,\n",
       "  <function metrics_tf.r2.<locals>.R2(y_true, y_pred)>],\n",
       " 'output_3_1_prediction': ['mse',\n",
       "  <function metrics_tf.pearsons_r(y_true, y_pred)>,\n",
       "  <function metrics_tf.SMAPE(y_true, y_pred)>,\n",
       "  <function metrics_tf.MBE(y_true, y_pred)>,\n",
       "  <function metrics_tf.r2.<locals>.R2(y_true, y_pred)>],\n",
       " 'output_4_1_prediction': ['mse',\n",
       "  <function metrics_tf.pearsons_r(y_true, y_pred)>,\n",
       "  <function metrics_tf.SMAPE(y_true, y_pred)>,\n",
       "  <function metrics_tf.MBE(y_true, y_pred)>,\n",
       "  <function metrics_tf.r2.<locals>.R2(y_true, y_pred)>],\n",
       " 'output_5_1_prediction': ['mse',\n",
       "  <function metrics_tf.pearsons_r(y_true, y_pred)>,\n",
       "  <function metrics_tf.SMAPE(y_true, y_pred)>,\n",
       "  <function metrics_tf.MBE(y_true, y_pred)>,\n",
       "  <function metrics_tf.r2.<locals>.R2(y_true, y_pred)>],\n",
       " 'output_6_1_prediction': ['mse',\n",
       "  <function metrics_tf.pearsons_r(y_true, y_pred)>,\n",
       "  <function metrics_tf.SMAPE(y_true, y_pred)>,\n",
       "  <function metrics_tf.MBE(y_true, y_pred)>,\n",
       "  <function metrics_tf.r2.<locals>.R2(y_true, y_pred)>],\n",
       " 'output_7_1_prediction': ['mse',\n",
       "  <function metrics_tf.pearsons_r(y_true, y_pred)>,\n",
       "  <function metrics_tf.SMAPE(y_true, y_pred)>,\n",
       "  <function metrics_tf.MBE(y_true, y_pred)>,\n",
       "  <function metrics_tf.r2.<locals>.R2(y_true, y_pred)>]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metrics common to all outputs\n",
    "common_metrics = [\"mse\", pearsons_r, SMAPE, MBE]\n",
    "\n",
    "# Metrics specific to certain outputs\n",
    "specific_metrics = {\n",
    "    f\"output_{i}_1_prediction\": [r2(mean)] for i, mean in zip(range(8), means.values())\n",
    "}\n",
    "# Combine the common and specific metrics\n",
    "metrics = {\n",
    "    name: common_metrics + specific_metrics.get(name, []) for name in specific_metrics\n",
    "}\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1692365822994,
     "user": {
      "displayName": "Jorge Cabrejas",
      "userId": "11610545751064957174"
     },
     "user_tz": -120
    },
    "id": "saDWnSgYHT88",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    lookback: int = 250 * 3,\n",
    "    num_transformer_layers: int = 4,\n",
    "    num_attention_heads: int = 3,\n",
    "    kernel_size: int = 32,\n",
    "    conv_layers: int = 3,\n",
    "    lr: float = 0.000185\n",
    "):\n",
    "    \n",
    "    input_data, target_data, btc_scalers, target_scalers, means = prepare_data(PATH)\n",
    "    \n",
    "        # Metrics common to all outputs\n",
    "    common_metrics = [\"mse\", pearsons_r, SMAPE, MBE]\n",
    "\n",
    "    # Metrics specific to certain outputs\n",
    "    specific_metrics = {\n",
    "        f\"output_{i}_1_prediction\": [r2(mean)] for i, mean in zip(range(8), means.values())\n",
    "    }\n",
    "    # Combine the common and specific metrics\n",
    "    metrics = {\n",
    "        name: common_metrics + specific_metrics.get(name, []) for name in specific_metrics\n",
    "    }\n",
    "    \n",
    "    input_shape = (lookback, 5)  # Assuming lookback is defined\n",
    "\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = Time2Vec(lookback)(input_layer)\n",
    "\n",
    "    for _ in range(num_transformer_layers, 0, -1):\n",
    "        x = MultiHeadAttention(num_heads=num_attention_heads, key_dim=lookback)(x, x)\n",
    "        x = LayerNormalization()(x)\n",
    "\n",
    "    encoder_output = x\n",
    "\n",
    "    # Define output branches\n",
    "    outputs = []\n",
    "    losses = {}\n",
    "\n",
    "    for i in range(8):\n",
    "        for j in range(conv_layers, 0, -1):\n",
    "            x = Conv1D(32 * (2**j), kernel_size)(encoder_output)\n",
    "        x = MaxPooling1D(2)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(32)(x)\n",
    "        output_1 = Dense(1, name=f\"output_{i}_1_prediction\")(x)\n",
    "        output_2 = Dense(1, name=f\"output_{i}_2_quantile_05\")(x)\n",
    "        output_3 = Dense(1, name=f\"output_{i}_3_quantile_95\")(x)\n",
    "        losses[f\"output_{i}_1_prediction\"] = \"mae\"\n",
    "        losses[f\"output_{i}_2_quantile_05\"] = tfa.losses.PinballLoss(tau=0.05)\n",
    "        losses[f\"output_{i}_3_quantile_95\"] = tfa.losses.PinballLoss(tau=0.95)\n",
    "        outputs.extend([output_1, output_2, output_3])\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=outputs)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=losses, optimizer=Adam(learning_rate=lr), metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_plot_data(model, input_data, targets, scalers):\n",
    "    # Generate model predictions\n",
    "    predictions = model.predict(input_data)\n",
    "\n",
    "    # Convert predictions to numpy array if they aren't already\n",
    "    if not isinstance(predictions, np.ndarray):\n",
    "        predictions = np.array(predictions)\n",
    "\n",
    "    data_dict = {}\n",
    "\n",
    "    for currency_idx, name in zip(\n",
    "        range(8), [\"ADA\", \"BNB\", \"EOS\", \"ETH\", \"LTC\", \"TRX\", \"VET\", \"XRP\"]\n",
    "    ):\n",
    "        # Extract and inverse scale true values for the given currency\n",
    "        true_values = (\n",
    "            scalers[name]\n",
    "            .inverse_transform(targets[:, currency_idx * 3].reshape(-1, 1))\n",
    "            .flatten()\n",
    "        )\n",
    "\n",
    "        # Extract and inverse scale predictions and quantiles\n",
    "        preds = (\n",
    "            scalers[name]\n",
    "            .inverse_transform(predictions[currency_idx * 3].reshape(-1, 1))\n",
    "            .flatten()\n",
    "        )\n",
    "        q5 = (\n",
    "            scalers[name]\n",
    "            .inverse_transform(predictions[currency_idx * 3 + 1].reshape(-1, 1))\n",
    "            .flatten()\n",
    "        )\n",
    "        q95 = (\n",
    "            scalers[name]\n",
    "            .inverse_transform(predictions[currency_idx * 3 + 2].reshape(-1, 1))\n",
    "            .flatten()\n",
    "        )\n",
    "\n",
    "        data_dict[name] = {\n",
    "            \"true_values\": true_values.tolist(),\n",
    "            \"predictions\": np.clip(preds, 0, None).tolist(),\n",
    "            \"q5\": np.clip(q5, 0, None).tolist(),\n",
    "            \"q95\": q95.tolist(),\n",
    "        }\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1KbGH86-J5-X",
    "outputId": "b8bfb5f3-fd4a-4699-bcc8-5ff428c5d66b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/home/apollo/anaconda3/envs/tfm/lib/'\n",
    "# for i in range(6, 50):\n",
    "#     model = build_model()\n",
    "#     history = model.fit(\n",
    "#         train_input,\n",
    "#         train_target,\n",
    "#         validation_data=(valid_input, valid_target),\n",
    "#         epochs=2000,\n",
    "#         callbacks=[\n",
    "#             EarlyStopping(\n",
    "#                 monitor=\"val_loss\", patience=200, restore_best_weights=True, verbose=1\n",
    "#             ),\n",
    "#             ReduceLROnPlateau(monitor=\"val_loss\", patience=50),\n",
    "#             ModelCheckpoint(\n",
    "#                 \"./tmp/checkpoint/model_checkpoint_{epoch}.hdf5\", save_freq=5\n",
    "#             ),\n",
    "#             TensorBoard(log_dir=\"./logs\"),\n",
    "#             BackupAndRestore(\"tmp/backup\"),\n",
    "#         ],\n",
    "#     )\n",
    "\n",
    "#     model.save(f\"./train/models/model_trial_{i}.hdf5\")\n",
    "\n",
    "#     history_dict = history.history\n",
    "#     with open(f\"./train/history/history_trial_{i}.pkl\", \"wb\") as pickle_file:  # Use \"wb\" for write binary mode\n",
    "#         pickle.dump(history_dict, pickle_file)\n",
    "\n",
    "#     # Assuming your model is stored in the variable 'model'\n",
    "#     plot_data = extract_plot_data(model, input_data, target_data, target_scalers)\n",
    "\n",
    "#     # Store in a JSON file\n",
    "#     with open(f\"./train/predictions/plot_data_trial_{i}.json\", \"w\") as json_file:\n",
    "#         json.dump(plot_data, json_file)\n",
    "\n",
    "#     !rm -r tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ne8C-1VvM8ZC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Get the list of metrics from the model\n",
    "# metrics = [metric for metric in model.metrics_names if not metric.endswith(\"loss\")]\n",
    "\n",
    "# # Calculate the total number of subplots needed (one for each metric, and one for the loss)\n",
    "# num_plots = len(metrics) + 1\n",
    "\n",
    "# plt.figure(figsize=(15, 5 * num_plots))\n",
    "\n",
    "# # Plotting the loss\n",
    "# plt.subplot(num_plots, 1, 1)\n",
    "# plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "# plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "# plt.title(\"Loss\")\n",
    "# plt.legend()\n",
    "\n",
    "# # Plotting the metrics\n",
    "# for i, metric in enumerate(metrics):\n",
    "#     plt.subplot(num_plots, 1, i + 2)\n",
    "#     plt.plot(history.history[metric], label=f\"Train {metric}\")\n",
    "#     plt.plot(history.history[f\"val_{metric}\"], label=f\"Validation {metric}\")\n",
    "#     plt.title(metric.capitalize())\n",
    "#     plt.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# test_results = model.evaluate(test_input, test_target, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "g7mdFgJsiBDH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "uq1RGzF6hy9s",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict for the entire dataset\n",
    "# all_predictions = model.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "pxJCCXfSeXXw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_all_predictions(predictions, targets, test_start_idx, title_prefix):\n",
    "    # Total length of the data\n",
    "    total_length = targets.shape[0]\n",
    "\n",
    "    # Plot each cryptocurrency\n",
    "    for currency_idx, name in zip(\n",
    "        range(8), [\"ADA\", \"BNB\", \"EOS\", \"ETH\", \"LTC\", \"TRX\", \"VET\", \"XRP\"]\n",
    "    ):\n",
    "        # Extract true values for the given currency\n",
    "        true_values = targets[:, currency_idx * 3]\n",
    "        l = 0\n",
    "        # Extract predictions and quantiles\n",
    "        preds = predictions[currency_idx * 3].reshape(-1)\n",
    "        print(f\"Son iguales {preds == l}\")\n",
    "        q5 = predictions[currency_idx * 3 + 1].reshape(-1)\n",
    "        q95 = predictions[currency_idx * 3 + 2].reshape(-1)\n",
    "        l = preds\n",
    "        plt.figure(figsize=(14, 6))\n",
    "\n",
    "        # Plot true values and predictions\n",
    "        plt.plot(true_values, label=\"True Values\", color=\"black\")\n",
    "        plt.plot(preds, label=\"Predictions\", color=\"blue\")\n",
    "\n",
    "        # Fill between for the confidence interval\n",
    "        plt.fill_between(\n",
    "            range(total_length),\n",
    "            q5,\n",
    "            q95,\n",
    "            color=\"blue\",\n",
    "            alpha=0.2,\n",
    "            label=\"5-95% Confidence Interval\",\n",
    "        )\n",
    "\n",
    "        # Mark where the test set starts\n",
    "        plt.axvline(\n",
    "            x=test_start_idx, color=\"red\", linestyle=\"--\", label=\"Start of Test Data\"\n",
    "        )\n",
    "\n",
    "        plt.title(\n",
    "            f\"{name} - Cryptocurrency {currency_idx + 1} Predictions vs True Values\"\n",
    "        )\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Plot for all data\n",
    "# plot_all_predictions(all_predictions, target_data, len(input_data) - 184, \"All Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "qrASes5KeDHk",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276, 24)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "9VYnbYRpenRH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_all_predictions(model_preds, targets):\n",
    "    \"\"\"\n",
    "    Plots all prediction values for each currency on the same graph.\n",
    "\n",
    "    Args:\n",
    "    - model_preds (list of arrays): List of model outputs. Each entry in the list corresponds to a prediction for a currency.\n",
    "    - targets (array): True target values for all the currencies.\n",
    "\n",
    "    \"\"\"\n",
    "    num_currencies = (\n",
    "        len(model_preds) // 3\n",
    "    )  # Assuming 3 outputs per currency: prediction, 5% quantile, 95% quantile\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    # Define colors (if you have more than 8 currencies, extend this list)\n",
    "    colors = [\"b\", \"g\", \"r\", \"c\", \"m\", \"y\", \"k\", \"orange\"]\n",
    "\n",
    "    for i in range(num_currencies):\n",
    "        pred = model_preds[i * 3]\n",
    "        actual = targets[:, i * 3]  # Assuming targets are structured similarly\n",
    "\n",
    "        # Plotting\n",
    "        plt.plot(pred, color=colors[i], label=f\"Currency {i+1} Prediction\")\n",
    "        # plt.plot(actual, color=colors[i], linestyle='--', label=f'Currency {i+1} Actual')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title(\"Predictions vs. Actual Values\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Usage\n",
    "# plot_all_predictions(all_predictions, target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "5cb0qEKtjamO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# target_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "VXKnrQP_j0GI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_all_predictions(predictions, targets, test_start_idx, title_prefix, scalers):\n",
    "    # Total length of the data\n",
    "    total_length = targets.shape[0]\n",
    "\n",
    "    # Plot each cryptocurrency\n",
    "    for currency_idx, name in zip(\n",
    "        range(8), [\"ADA\", \"BNB\", \"EOS\", \"ETH\", \"LTC\", \"TRX\", \"VET\", \"XRP\"]\n",
    "    ):\n",
    "        # Extract true values for the given currency and inverse scale them\n",
    "        true_values = (\n",
    "            scalers[name]\n",
    "            .inverse_transform(targets[:, currency_idx * 3].reshape(-1, 1))\n",
    "            .flatten()\n",
    "        )\n",
    "\n",
    "        # Extract predictions and quantiles, and inverse scale them\n",
    "        preds = (\n",
    "            scalers[name]\n",
    "            .inverse_transform(predictions[currency_idx * 3].reshape(-1, 1))\n",
    "            .flatten()\n",
    "        )\n",
    "        q5 = (\n",
    "            scalers[name]\n",
    "            .inverse_transform(predictions[currency_idx * 3 + 1].reshape(-1, 1))\n",
    "            .flatten()\n",
    "        )\n",
    "        q95 = (\n",
    "            scalers[name]\n",
    "            .inverse_transform(predictions[currency_idx * 3 + 2].reshape(-1, 1))\n",
    "            .flatten()\n",
    "        )\n",
    "\n",
    "        plt.figure(figsize=(14, 6))\n",
    "\n",
    "        # Plot true values and predictions\n",
    "        plt.plot(true_values, label=\"True Values\", color=\"black\")\n",
    "        plt.plot(preds, label=\"Predictions\", color=\"blue\")\n",
    "\n",
    "        # Fill between for the confidence interval\n",
    "        plt.fill_between(\n",
    "            range(total_length),\n",
    "            q5,\n",
    "            q95,\n",
    "            color=\"blue\",\n",
    "            alpha=0.2,\n",
    "            label=\"5-95% Confidence Interval\",\n",
    "        )\n",
    "\n",
    "        # Mark where the test set starts\n",
    "        plt.axvline(\n",
    "            x=test_start_idx, color=\"red\", linestyle=\"--\", label=\"Start of Test Data\"\n",
    "        )\n",
    "        plt.axvline(\n",
    "            x=test_start_idx - 184,\n",
    "            color=\"yellow\",\n",
    "            linestyle=\"--\",\n",
    "            label=\"Start of Validation Data\",\n",
    "        )\n",
    "\n",
    "        plt.title(\n",
    "            f\"{name} - Cryptocurrency {currency_idx + 1} Predictions vs True Values\"\n",
    "        )\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# plot_all_predictions(\n",
    "#     all_predictions, target_data, len(input_data) - 184, \"All Data\", target_scalers\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "zZMXnChEldsR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_interval_stats(predictions, targets, test_start_idx):\n",
    "    # Starting index for the test set\n",
    "    start_idx = test_start_idx - 184\n",
    "\n",
    "    stats = {}\n",
    "\n",
    "    # For each cryptocurrency\n",
    "    for currency_idx, name in zip(\n",
    "        range(8), [\"ADA\", \"BNB\", \"EOS\", \"ETH\", \"LTC\", \"TRX\", \"VET\", \"XRP\"]\n",
    "    ):\n",
    "        # Extract true values for the test set\n",
    "        true_values = targets[start_idx:, currency_idx * 3]\n",
    "\n",
    "        # Extract quantiles for the test set\n",
    "        q5 = predictions[currency_idx * 3 + 1][start_idx:].reshape(-1)\n",
    "        q95 = predictions[currency_idx * 3 + 2][start_idx:].reshape(-1)\n",
    "\n",
    "        # Count how many of the true values fall within the confidence interval\n",
    "        count_inside_interval = np.sum((true_values >= q5) & (true_values <= q95))\n",
    "\n",
    "        # Count outside the interval\n",
    "        count_outside_interval = len(true_values) - count_inside_interval\n",
    "\n",
    "        # Calculate precision\n",
    "        precision = count_inside_interval / len(true_values)\n",
    "\n",
    "        stats[name] = {\n",
    "            \"precision\": precision,\n",
    "            \"inside_interval\": count_inside_interval,\n",
    "            \"outside_interval\": count_outside_interval,\n",
    "        }\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "# # Calculate precision for each cryptocurrency\n",
    "# stats = calculate_interval_stats(all_predictions, target_data, len(input_data) - 184)\n",
    "\n",
    "# for name, data in stats.items():\n",
    "#     print(f\"{name}:\")\n",
    "#     print(f\"  Precision: {data['precision']:.4f}\")\n",
    "#     print(f\"  Inside Interval: {data['inside_interval']}\")\n",
    "#     print(f\"  Outside Interval: {data['outside_interval']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4cBYiBOkqOnx",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Input shape: (1656, 750, 5) Test Input shape: (183, 750, 5)\n",
      "Train Target shape: (1656, 24) Test Target shape: (183, 24)\n",
      "Epoch 1/2000\n",
      " 4/52 [=>............................] - ETA: 16s - loss: 203.0067 - output_0_1_prediction_loss: 18.4004 - output_0_2_quantile_05_loss: 17.5346 - output_0_3_quantile_95_loss: 20.8978 - output_1_1_prediction_loss: 11.7716 - output_1_2_quantile_05_loss: 2.1443 - output_1_3_quantile_95_loss: 3.0852 - output_2_1_prediction_loss: 15.6322 - output_2_2_quantile_05_loss: 6.8391 - output_2_3_quantile_95_loss: 0.5546 - output_3_1_prediction_loss: 9.5976 - output_3_2_quantile_05_loss: 4.1904 - output_3_3_quantile_95_loss: 2.3342 - output_4_1_prediction_loss: 15.5959 - output_4_2_quantile_05_loss: 0.5219 - output_4_3_quantile_95_loss: 3.0676 - output_5_1_prediction_loss: 11.4441 - output_5_2_quantile_05_loss: 2.0562 - output_5_3_quantile_95_loss: 2.1328 - output_6_1_prediction_loss: 19.8653 - output_6_2_quantile_05_loss: 5.2953 - output_6_3_quantile_95_loss: 3.9939 - output_7_1_prediction_loss: 15.3579 - output_7_2_quantile_05_loss: 6.6234 - output_7_3_quantile_95_loss: 4.0703 - output_0_1_prediction_mse: 679.0939 - output_0_1_prediction_pearsons_r: 1.2503 - output_0_1_prediction_SMAPE: 1.6605 - output_0_1_prediction_MBE: -17.6319 - output_0_1_prediction_R2: -15958.2852 - output_1_1_prediction_mse: 283.3485 - output_1_1_prediction_pearsons_r: 2.3342 - output_1_1_prediction_SMAPE: 1.5211 - output_1_1_prediction_MBE: 11.4800 - output_1_1_prediction_R2: -3117.3745 - output_2_1_prediction_mse: 559.3574 - output_2_1_prediction_pearsons_r: 0.0400 - output_2_1_prediction_SMAPE: 1.9354 - output_2_1_prediction_MBE: -14.7158 - output_2_1_prediction_R2: -8386.0527 - output_3_1_prediction_mse: 171.6013 - output_3_1_prediction_pearsons_r: -0.9000 - output_3_1_prediction_SMAPE: 1.8023 - output_3_1_prediction_MBE: -8.0280 - output_3_1_prediction_R2: -2907.5928 - output_4_1_prediction_mse: 428.9259 - output_4_1_prediction_pearsons_r: 0.0967 - output_4_1_prediction_SMAPE: 1.7076 - output_4_1_prediction_MBE: -13.5562 - output_4_1_prediction_R2: -10326.6211 - output_5_1_prediction_mse: 303.6642 - output_5_1_prediction_pearsons_r: -2.0854 - output_5_1_prediction_SMAPE: 1.8138 - output_5_1_prediction_MBE: -10.6334 - output_5_1_prediction_R2: -5185.6919 - output_6_1_prediction_mse: 802.6586 - output_6_1_prediction_pearsons_r: 0.8480 - output_6_1_prediction_SMAPE: 1.6059 - output_6_1_prediction_MBE: 19.5736 - output_6_1_prediction_R2: -15872.0469 - output_7_1_prediction_mse: 645.9361 - output_7_1_prediction_pearsons_r: -0.5988 - output_7_1_prediction_SMAPE: 1.6486 - output_7_1_prediction_MBE: -14.3454 - output_7_1_prediction_R2: -15964.8584"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 33s 488ms/step - loss: 171.8052 - output_0_1_prediction_loss: 14.3312 - output_0_2_quantile_05_loss: 4.4655 - output_0_3_quantile_95_loss: 5.8169 - output_1_1_prediction_loss: 11.6961 - output_1_2_quantile_05_loss: 2.3454 - output_1_3_quantile_95_loss: 2.7505 - output_2_1_prediction_loss: 12.5038 - output_2_2_quantile_05_loss: 3.0085 - output_2_3_quantile_95_loss: 4.2327 - output_3_1_prediction_loss: 19.0053 - output_3_2_quantile_05_loss: 4.1557 - output_3_3_quantile_95_loss: 2.2662 - output_4_1_prediction_loss: 13.8132 - output_4_2_quantile_05_loss: 0.6868 - output_4_3_quantile_95_loss: 1.5231 - output_5_1_prediction_loss: 17.8687 - output_5_2_quantile_05_loss: 4.0252 - output_5_3_quantile_95_loss: 4.8746 - output_6_1_prediction_loss: 19.0718 - output_6_2_quantile_05_loss: 2.3349 - output_6_3_quantile_95_loss: 3.3289 - output_7_1_prediction_loss: 14.7103 - output_7_2_quantile_05_loss: 1.5738 - output_7_3_quantile_95_loss: 1.4161 - output_0_1_prediction_mse: 427.9106 - output_0_1_prediction_pearsons_r: -0.3230 - output_0_1_prediction_SMAPE: 1.8949 - output_0_1_prediction_MBE: -1.1070 - output_0_1_prediction_R2: -9982.7119 - output_1_1_prediction_mse: 363.9068 - output_1_1_prediction_pearsons_r: -0.1893 - output_1_1_prediction_SMAPE: 1.8440 - output_1_1_prediction_MBE: -1.7104 - output_1_1_prediction_R2: -3874.3259 - output_2_1_prediction_mse: 388.1585 - output_2_1_prediction_pearsons_r: -0.6036 - output_2_1_prediction_SMAPE: 1.8664 - output_2_1_prediction_MBE: 0.2573 - output_2_1_prediction_R2: -5594.6558 - output_3_1_prediction_mse: 943.4283 - output_3_1_prediction_pearsons_r: 0.0467 - output_3_1_prediction_SMAPE: 1.8724 - output_3_1_prediction_MBE: -0.0215 - output_3_1_prediction_R2: -14195.6787 - output_4_1_prediction_mse: 831.2955 - output_4_1_prediction_pearsons_r: -1.0351 - output_4_1_prediction_SMAPE: 1.8409 - output_4_1_prediction_MBE: 1.9746 - output_4_1_prediction_R2: -18408.2266 - output_5_1_prediction_mse: 726.5264 - output_5_1_prediction_pearsons_r: -0.9033 - output_5_1_prediction_SMAPE: 1.9114 - output_5_1_prediction_MBE: -0.0955 - output_5_1_prediction_R2: -11276.2383 - output_6_1_prediction_mse: 689.3934 - output_6_1_prediction_pearsons_r: -0.2177 - output_6_1_prediction_SMAPE: 1.9180 - output_6_1_prediction_MBE: 0.5462 - output_6_1_prediction_R2: -13120.9590 - output_7_1_prediction_mse: 863.3903 - output_7_1_prediction_pearsons_r: 0.0449 - output_7_1_prediction_SMAPE: 1.8424 - output_7_1_prediction_MBE: 4.1862 - output_7_1_prediction_R2: -21132.7832 - val_loss: 54.1078 - val_output_0_1_prediction_loss: 4.7319 - val_output_0_2_quantile_05_loss: 1.7077 - val_output_0_3_quantile_95_loss: 1.6764 - val_output_1_1_prediction_loss: 0.7793 - val_output_1_2_quantile_05_loss: 1.0698 - val_output_1_3_quantile_95_loss: 0.6050 - val_output_2_1_prediction_loss: 1.4316 - val_output_2_2_quantile_05_loss: 2.7715 - val_output_2_3_quantile_95_loss: 0.4213 - val_output_3_1_prediction_loss: 11.4555 - val_output_3_2_quantile_05_loss: 4.6190 - val_output_3_3_quantile_95_loss: 3.9177 - val_output_4_1_prediction_loss: 0.8039 - val_output_4_2_quantile_05_loss: 0.6812 - val_output_4_3_quantile_95_loss: 0.9026 - val_output_5_1_prediction_loss: 0.4951 - val_output_5_2_quantile_05_loss: 1.1134 - val_output_5_3_quantile_95_loss: 1.6012 - val_output_6_1_prediction_loss: 3.7869 - val_output_6_2_quantile_05_loss: 1.2596 - val_output_6_3_quantile_95_loss: 0.6636 - val_output_7_1_prediction_loss: 6.2055 - val_output_7_2_quantile_05_loss: 0.7350 - val_output_7_3_quantile_95_loss: 0.6732 - val_output_0_1_prediction_mse: 22.4010 - val_output_0_1_prediction_pearsons_r: -0.0395 - val_output_0_1_prediction_SMAPE: 1.9331 - val_output_0_1_prediction_MBE: -4.7334 - val_output_0_1_prediction_R2: -1413.1895 - val_output_1_1_prediction_mse: 0.6174 - val_output_1_1_prediction_pearsons_r: 0.1994 - val_output_1_1_prediction_SMAPE: 1.6809 - val_output_1_1_prediction_MBE: -0.7808 - val_output_1_1_prediction_R2: -3.3749 - val_output_2_1_prediction_mse: 2.0596 - val_output_2_1_prediction_pearsons_r: 0.0988 - val_output_2_1_prediction_SMAPE: 2.0000 - val_output_2_1_prediction_MBE: 1.4300 - val_output_2_1_prediction_R2: -330.5368 - val_output_3_1_prediction_mse: 131.2391 - val_output_3_1_prediction_pearsons_r: 0.0602 - val_output_3_1_prediction_SMAPE: 1.9714 - val_output_3_1_prediction_MBE: -11.4571 - val_output_3_1_prediction_R2: -1432.6285 - val_output_4_1_prediction_mse: 0.6564 - val_output_4_1_prediction_pearsons_r: 0.0938 - val_output_4_1_prediction_SMAPE: 2.0000 - val_output_4_1_prediction_MBE: 0.8023 - val_output_4_1_prediction_R2: -40.6214 - val_output_5_1_prediction_mse: 0.2553 - val_output_5_1_prediction_pearsons_r: -0.0928 - val_output_5_1_prediction_SMAPE: 1.5594 - val_output_5_1_prediction_MBE: -0.4966 - val_output_5_1_prediction_R2: -1.7692 - val_output_6_1_prediction_mse: 14.3505 - val_output_6_1_prediction_pearsons_r: -0.0764 - val_output_6_1_prediction_SMAPE: 1.9176 - val_output_6_1_prediction_MBE: -3.7884 - val_output_6_1_prediction_R2: -1548.8734 - val_output_7_1_prediction_mse: 38.5186 - val_output_7_1_prediction_pearsons_r: 0.1400 - val_output_7_1_prediction_SMAPE: 2.0000 - val_output_7_1_prediction_MBE: 6.2040 - val_output_7_1_prediction_R2: -1544.4600 - lr: 1.8500e-04\n",
      "Epoch 2/2000\n",
      "52/52 [==============================] - 23s 452ms/step - loss: 25.6893 - output_0_1_prediction_loss: 1.1525 - output_0_2_quantile_05_loss: 0.6898 - output_0_3_quantile_95_loss: 0.7364 - output_1_1_prediction_loss: 0.6670 - output_1_2_quantile_05_loss: 0.4421 - output_1_3_quantile_95_loss: 0.5781 - output_2_1_prediction_loss: 3.4417 - output_2_2_quantile_05_loss: 1.0679 - output_2_3_quantile_95_loss: 2.4067 - output_3_1_prediction_loss: 2.9130 - output_3_2_quantile_05_loss: 1.3887 - output_3_3_quantile_95_loss: 1.0479 - output_4_1_prediction_loss: 1.1254 - output_4_2_quantile_05_loss: 0.3213 - output_4_3_quantile_95_loss: 0.5414 - output_5_1_prediction_loss: 0.9698 - output_5_2_quantile_05_loss: 0.4207 - output_5_3_quantile_95_loss: 0.5545 - output_6_1_prediction_loss: 0.8939 - output_6_2_quantile_05_loss: 0.4025 - output_6_3_quantile_95_loss: 0.6865 - output_7_1_prediction_loss: 2.2314 - output_7_2_quantile_05_loss: 0.5940 - output_7_3_quantile_95_loss: 0.4161 - output_0_1_prediction_mse: 2.1717 - output_0_1_prediction_pearsons_r: -0.6143 - output_0_1_prediction_SMAPE: 1.6634 - output_0_1_prediction_MBE: 0.1579 - output_0_1_prediction_R2: -46.8423 - output_1_1_prediction_mse: 0.7765 - output_1_1_prediction_pearsons_r: 1.0969 - output_1_1_prediction_SMAPE: 1.4619 - output_1_1_prediction_MBE: -0.1112 - output_1_1_prediction_R2: -7.0942 - output_2_1_prediction_mse: 20.5117 - output_2_1_prediction_pearsons_r: 0.7194 - output_2_1_prediction_SMAPE: 1.7915 - output_2_1_prediction_MBE: -0.1728 - output_2_1_prediction_R2: -297.3619 - output_3_1_prediction_mse: 29.9375 - output_3_1_prediction_pearsons_r: -1.4407 - output_3_1_prediction_SMAPE: 1.5895 - output_3_1_prediction_MBE: 0.3320 - output_3_1_prediction_R2: -433.9246 - output_4_1_prediction_mse: 3.3969 - output_4_1_prediction_pearsons_r: -0.4681 - output_4_1_prediction_SMAPE: 1.5311 - output_4_1_prediction_MBE: 0.1865 - output_4_1_prediction_R2: -77.3793 - output_5_1_prediction_mse: 2.0679 - output_5_1_prediction_pearsons_r: 0.6972 - output_5_1_prediction_SMAPE: 1.5371 - output_5_1_prediction_MBE: 0.2811 - output_5_1_prediction_R2: -31.5242 - output_6_1_prediction_mse: 1.4653 - output_6_1_prediction_pearsons_r: 0.7262 - output_6_1_prediction_SMAPE: 1.5656 - output_6_1_prediction_MBE: -0.0647 - output_6_1_prediction_R2: -27.5936 - output_7_1_prediction_mse: 8.4317 - output_7_1_prediction_pearsons_r: -0.5008 - output_7_1_prediction_SMAPE: 1.6860 - output_7_1_prediction_MBE: 0.4588 - output_7_1_prediction_R2: -195.0461 - val_loss: 7.2133 - val_output_0_1_prediction_loss: 0.9029 - val_output_0_2_quantile_05_loss: 0.1576 - val_output_0_3_quantile_95_loss: 0.0167 - val_output_1_1_prediction_loss: 0.1819 - val_output_1_2_quantile_05_loss: 0.0314 - val_output_1_3_quantile_95_loss: 0.0453 - val_output_2_1_prediction_loss: 0.4789 - val_output_2_2_quantile_05_loss: 0.7806 - val_output_2_3_quantile_95_loss: 0.0269 - val_output_3_1_prediction_loss: 0.0989 - val_output_3_2_quantile_05_loss: 0.2120 - val_output_3_3_quantile_95_loss: 0.0166 - val_output_4_1_prediction_loss: 0.1374 - val_output_4_2_quantile_05_loss: 0.1989 - val_output_4_3_quantile_95_loss: 0.1998 - val_output_5_1_prediction_loss: 0.4263 - val_output_5_2_quantile_05_loss: 0.0699 - val_output_5_3_quantile_95_loss: 0.3051 - val_output_6_1_prediction_loss: 0.4187 - val_output_6_2_quantile_05_loss: 0.0229 - val_output_6_3_quantile_95_loss: 0.2424 - val_output_7_1_prediction_loss: 1.3926 - val_output_7_2_quantile_05_loss: 0.1073 - val_output_7_3_quantile_95_loss: 0.7423 - val_output_0_1_prediction_mse: 0.8255 - val_output_0_1_prediction_pearsons_r: -0.1718 - val_output_0_1_prediction_SMAPE: 1.7149 - val_output_0_1_prediction_MBE: -0.9045 - val_output_0_1_prediction_R2: -51.2567 - val_output_1_1_prediction_mse: 0.0433 - val_output_1_1_prediction_pearsons_r: 0.0701 - val_output_1_1_prediction_SMAPE: 2.0000 - val_output_1_1_prediction_MBE: 0.1803 - val_output_1_1_prediction_R2: 0.6877 - val_output_2_1_prediction_mse: 0.2395 - val_output_2_1_prediction_pearsons_r: 0.1615 - val_output_2_1_prediction_SMAPE: 2.0000 - val_output_2_1_prediction_MBE: 0.4774 - val_output_2_1_prediction_R2: -34.5205 - val_output_3_1_prediction_mse: 0.0131 - val_output_3_1_prediction_pearsons_r: -0.0168 - val_output_3_1_prediction_SMAPE: 1.0453 - val_output_3_1_prediction_MBE: -0.0552 - val_output_3_1_prediction_R2: 0.8567 - val_output_4_1_prediction_mse: 0.0219 - val_output_4_1_prediction_pearsons_r: 0.0437 - val_output_4_1_prediction_SMAPE: 1.1558 - val_output_4_1_prediction_MBE: -0.1097 - val_output_4_1_prediction_R2: -0.3967 - val_output_5_1_prediction_mse: 0.1916 - val_output_5_1_prediction_pearsons_r: 0.0330 - val_output_5_1_prediction_SMAPE: 1.5147 - val_output_5_1_prediction_MBE: -0.4275 - val_output_5_1_prediction_R2: -1.0768 - val_output_6_1_prediction_mse: 0.1851 - val_output_6_1_prediction_pearsons_r: 0.1045 - val_output_6_1_prediction_SMAPE: 1.5091 - val_output_6_1_prediction_MBE: -0.4198 - val_output_6_1_prediction_R2: -19.6722 - val_output_7_1_prediction_mse: 1.9494 - val_output_7_1_prediction_pearsons_r: 0.0233 - val_output_7_1_prediction_SMAPE: 2.0000 - val_output_7_1_prediction_MBE: 1.3910 - val_output_7_1_prediction_R2: -77.3041 - lr: 1.8500e-04\n",
      "Epoch 3/2000\n",
      "52/52 [==============================] - 25s 468ms/step - loss: 5.8831 - output_0_1_prediction_loss: 0.3972 - output_0_2_quantile_05_loss: 0.2924 - output_0_3_quantile_95_loss: 0.3081 - output_1_1_prediction_loss: 0.1948 - output_1_2_quantile_05_loss: 0.0816 - output_1_3_quantile_95_loss: 0.0865 - output_2_1_prediction_loss: 0.8626 - output_2_2_quantile_05_loss: 0.3099 - output_2_3_quantile_95_loss: 0.5986 - output_3_1_prediction_loss: 0.2027 - output_3_2_quantile_05_loss: 0.1179 - output_3_3_quantile_95_loss: 0.0757 - output_4_1_prediction_loss: 0.1758 - output_4_2_quantile_05_loss: 0.0684 - output_4_3_quantile_95_loss: 0.0752 - output_5_1_prediction_loss: 0.2149 - output_5_2_quantile_05_loss: 0.0745 - output_5_3_quantile_95_loss: 0.1637 - output_6_1_prediction_loss: 0.2695 - output_6_2_quantile_05_loss: 0.3028 - output_6_3_quantile_95_loss: 0.3271 - output_7_1_prediction_loss: 0.3334 - output_7_2_quantile_05_loss: 0.1480 - output_7_3_quantile_95_loss: 0.2019 - output_0_1_prediction_mse: 0.2562 - output_0_1_prediction_pearsons_r: 0.2638 - output_0_1_prediction_SMAPE: 1.3311 - output_0_1_prediction_MBE: 0.0196 - output_0_1_prediction_R2: -5.5697 - output_1_1_prediction_mse: 0.0607 - output_1_1_prediction_pearsons_r: 2.3584 - output_1_1_prediction_SMAPE: 1.0732 - output_1_1_prediction_MBE: 0.0222 - output_1_1_prediction_R2: 0.3637 - output_2_1_prediction_mse: 1.8707 - output_2_1_prediction_pearsons_r: -1.5274 - output_2_1_prediction_SMAPE: 1.4645 - output_2_1_prediction_MBE: -0.2335 - output_2_1_prediction_R2: -26.4963 - output_3_1_prediction_mse: 0.0696 - output_3_1_prediction_pearsons_r: -1.2804 - output_3_1_prediction_SMAPE: 1.0455 - output_3_1_prediction_MBE: 0.0412 - output_3_1_prediction_R2: -0.0520 - output_4_1_prediction_mse: 0.0556 - output_4_1_prediction_pearsons_r: -1.3690 - output_4_1_prediction_SMAPE: 0.9503 - output_4_1_prediction_MBE: 0.0644 - output_4_1_prediction_R2: -0.2222 - output_5_1_prediction_mse: 0.0824 - output_5_1_prediction_pearsons_r: 2.7739 - output_5_1_prediction_SMAPE: 1.0302 - output_5_1_prediction_MBE: 0.0501 - output_5_1_prediction_R2: -0.2726 - output_6_1_prediction_mse: 0.1164 - output_6_1_prediction_pearsons_r: 0.4718 - output_6_1_prediction_SMAPE: 1.2508 - output_6_1_prediction_MBE: 0.0106 - output_6_1_prediction_R2: -1.3788 - output_7_1_prediction_mse: 0.2209 - output_7_1_prediction_pearsons_r: -0.3559 - output_7_1_prediction_SMAPE: 1.2311 - output_7_1_prediction_MBE: 0.0149 - output_7_1_prediction_R2: -4.4213 - val_loss: 3.5482 - val_output_0_1_prediction_loss: 0.1898 - val_output_0_2_quantile_05_loss: 0.3710 - val_output_0_3_quantile_95_loss: 0.3961 - val_output_1_1_prediction_loss: 0.0711 - val_output_1_2_quantile_05_loss: 0.0392 - val_output_1_3_quantile_95_loss: 0.0263 - val_output_2_1_prediction_loss: 0.2344 - val_output_2_2_quantile_05_loss: 0.0353 - val_output_2_3_quantile_95_loss: 0.1970 - val_output_3_1_prediction_loss: 0.0765 - val_output_3_2_quantile_05_loss: 0.2745 - val_output_3_3_quantile_95_loss: 0.0425 - val_output_4_1_prediction_loss: 0.1153 - val_output_4_2_quantile_05_loss: 0.0078 - val_output_4_3_quantile_95_loss: 0.0411 - val_output_5_1_prediction_loss: 0.1237 - val_output_5_2_quantile_05_loss: 0.0106 - val_output_5_3_quantile_95_loss: 0.0401 - val_output_6_1_prediction_loss: 0.2417 - val_output_6_2_quantile_05_loss: 0.3483 - val_output_6_3_quantile_95_loss: 0.5103 - val_output_7_1_prediction_loss: 0.0993 - val_output_7_2_quantile_05_loss: 0.0102 - val_output_7_3_quantile_95_loss: 0.0461 - val_output_0_1_prediction_mse: 0.0400 - val_output_0_1_prediction_pearsons_r: -0.1508 - val_output_0_1_prediction_SMAPE: 1.2615 - val_output_0_1_prediction_MBE: -0.1743 - val_output_0_1_prediction_R2: -1.5429 - val_output_1_1_prediction_mse: 0.0102 - val_output_1_1_prediction_pearsons_r: 0.1946 - val_output_1_1_prediction_SMAPE: 0.9486 - val_output_1_1_prediction_MBE: 0.0060 - val_output_1_1_prediction_R2: 0.9258 - val_output_2_1_prediction_mse: 0.0611 - val_output_2_1_prediction_pearsons_r: -0.0568 - val_output_2_1_prediction_SMAPE: 1.3263 - val_output_2_1_prediction_MBE: -0.2271 - val_output_2_1_prediction_R2: -10.3823 - val_output_3_1_prediction_mse: 0.0103 - val_output_3_1_prediction_pearsons_r: -0.1523 - val_output_3_1_prediction_SMAPE: 0.9595 - val_output_3_1_prediction_MBE: -0.0134 - val_output_3_1_prediction_R2: 0.8851 - val_output_4_1_prediction_mse: 0.0162 - val_output_4_1_prediction_pearsons_r: -0.0356 - val_output_4_1_prediction_SMAPE: 1.0978 - val_output_4_1_prediction_MBE: -0.0794 - val_output_4_1_prediction_R2: -0.0302 - val_output_5_1_prediction_mse: 0.0182 - val_output_5_1_prediction_pearsons_r: 0.1107 - val_output_5_1_prediction_SMAPE: 1.1213 - val_output_5_1_prediction_MBE: -0.0912 - val_output_5_1_prediction_R2: 0.8021 - val_output_6_1_prediction_mse: 0.0649 - val_output_6_1_prediction_pearsons_r: -0.1344 - val_output_6_1_prediction_SMAPE: 1.3356 - val_output_6_1_prediction_MBE: -0.2355 - val_output_6_1_prediction_R2: -6.3326 - val_output_7_1_prediction_mse: 0.0131 - val_output_7_1_prediction_pearsons_r: 0.1210 - val_output_7_1_prediction_SMAPE: 1.0467 - val_output_7_1_prediction_MBE: -0.0559 - val_output_7_1_prediction_R2: 0.4736 - lr: 1.8500e-04\n",
      "Epoch 4/2000\n",
      "52/52 [==============================] - 24s 461ms/step - loss: 2.3389 - output_0_1_prediction_loss: 0.1799 - output_0_2_quantile_05_loss: 0.1498 - output_0_3_quantile_95_loss: 0.1684 - output_1_1_prediction_loss: 0.1641 - output_1_2_quantile_05_loss: 0.0225 - output_1_3_quantile_95_loss: 0.0332 - output_2_1_prediction_loss: 0.1882 - output_2_2_quantile_05_loss: 0.0515 - output_2_3_quantile_95_loss: 0.0735 - output_3_1_prediction_loss: 0.1776 - output_3_2_quantile_05_loss: 0.0637 - output_3_3_quantile_95_loss: 0.0420 - output_4_1_prediction_loss: 0.1639 - output_4_2_quantile_05_loss: 0.0197 - output_4_3_quantile_95_loss: 0.0307 - output_5_1_prediction_loss: 0.1638 - output_5_2_quantile_05_loss: 0.0182 - output_5_3_quantile_95_loss: 0.0314 - output_6_1_prediction_loss: 0.2213 - output_6_2_quantile_05_loss: 0.0579 - output_6_3_quantile_95_loss: 0.1044 - output_7_1_prediction_loss: 0.1664 - output_7_2_quantile_05_loss: 0.0142 - output_7_3_quantile_95_loss: 0.0326 - output_0_1_prediction_mse: 0.0555 - output_0_1_prediction_pearsons_r: -0.5041 - output_0_1_prediction_SMAPE: 0.9685 - output_0_1_prediction_MBE: 0.0438 - output_0_1_prediction_R2: -0.2185 - output_1_1_prediction_mse: 0.0507 - output_1_1_prediction_pearsons_r: 2.9894 - output_1_1_prediction_SMAPE: 0.8977 - output_1_1_prediction_MBE: 0.0778 - output_1_1_prediction_R2: 0.4600 - output_2_1_prediction_mse: 0.0608 - output_2_1_prediction_pearsons_r: -1.4647 - output_2_1_prediction_SMAPE: 1.0263 - output_2_1_prediction_MBE: 0.0542 - output_2_1_prediction_R2: 0.1409 - output_3_1_prediction_mse: 0.0559 - output_3_1_prediction_pearsons_r: -1.9328 - output_3_1_prediction_SMAPE: 0.9744 - output_3_1_prediction_MBE: 0.0592 - output_3_1_prediction_R2: 0.1499 - output_4_1_prediction_mse: 0.0505 - output_4_1_prediction_pearsons_r: -2.4489 - output_4_1_prediction_SMAPE: 0.8948 - output_4_1_prediction_MBE: 0.0764 - output_4_1_prediction_R2: -0.0874 - output_5_1_prediction_mse: 0.0500 - output_5_1_prediction_pearsons_r: 2.8510 - output_5_1_prediction_SMAPE: 0.8902 - output_5_1_prediction_MBE: 0.0723 - output_5_1_prediction_R2: 0.2438 - output_6_1_prediction_mse: 0.0846 - output_6_1_prediction_pearsons_r: 1.6974 - output_6_1_prediction_SMAPE: 1.0919 - output_6_1_prediction_MBE: 0.0524 - output_6_1_prediction_R2: -0.5618 - output_7_1_prediction_mse: 0.0510 - output_7_1_prediction_pearsons_r: 2.8568 - output_7_1_prediction_SMAPE: 0.9030 - output_7_1_prediction_MBE: 0.0671 - output_7_1_prediction_R2: -0.1732 - val_loss: 1.4137 - val_output_0_1_prediction_loss: 0.1462 - val_output_0_2_quantile_05_loss: 0.0370 - val_output_0_3_quantile_95_loss: 0.0482 - val_output_1_1_prediction_loss: 0.1155 - val_output_1_2_quantile_05_loss: 0.0202 - val_output_1_3_quantile_95_loss: 0.0434 - val_output_2_1_prediction_loss: 0.0830 - val_output_2_2_quantile_05_loss: 0.0233 - val_output_2_3_quantile_95_loss: 0.0659 - val_output_3_1_prediction_loss: 0.1280 - val_output_3_2_quantile_05_loss: 0.0339 - val_output_3_3_quantile_95_loss: 0.0456 - val_output_4_1_prediction_loss: 0.1319 - val_output_4_2_quantile_05_loss: 0.0042 - val_output_4_3_quantile_95_loss: 0.0326 - val_output_5_1_prediction_loss: 0.0973 - val_output_5_2_quantile_05_loss: 0.0243 - val_output_5_3_quantile_95_loss: 0.0407 - val_output_6_1_prediction_loss: 0.0880 - val_output_6_2_quantile_05_loss: 0.0066 - val_output_6_3_quantile_95_loss: 0.0373 - val_output_7_1_prediction_loss: 0.1197 - val_output_7_2_quantile_05_loss: 0.0077 - val_output_7_3_quantile_95_loss: 0.0331 - val_output_0_1_prediction_mse: 0.0245 - val_output_0_1_prediction_pearsons_r: 0.0529 - val_output_0_1_prediction_SMAPE: 1.1764 - val_output_0_1_prediction_MBE: -0.1210 - val_output_0_1_prediction_R2: -0.5467 - val_output_1_1_prediction_mse: 0.0163 - val_output_1_1_prediction_pearsons_r: 0.1038 - val_output_1_1_prediction_SMAPE: 1.0986 - val_output_1_1_prediction_MBE: -0.0798 - val_output_1_1_prediction_R2: 0.8844 - val_output_2_1_prediction_mse: 0.0109 - val_output_2_1_prediction_pearsons_r: -0.0620 - val_output_2_1_prediction_SMAPE: 0.9854 - val_output_2_1_prediction_MBE: -0.0279 - val_output_2_1_prediction_R2: -0.4000 - val_output_3_1_prediction_mse: 0.0193 - val_output_3_1_prediction_pearsons_r: 0.1030 - val_output_3_1_prediction_SMAPE: 1.1326 - val_output_3_1_prediction_MBE: -0.0971 - val_output_3_1_prediction_R2: 0.7901 - val_output_4_1_prediction_mse: 0.0204 - val_output_4_1_prediction_pearsons_r: -0.0098 - val_output_4_1_prediction_SMAPE: 1.1425 - val_output_4_1_prediction_MBE: -0.1024 - val_output_4_1_prediction_R2: -0.2985 - val_output_5_1_prediction_mse: 0.0128 - val_output_5_1_prediction_pearsons_r: 0.0975 - val_output_5_1_prediction_SMAPE: 1.0395 - val_output_5_1_prediction_MBE: -0.0526 - val_output_5_1_prediction_R2: 0.8599 - val_output_6_1_prediction_mse: 0.0115 - val_output_6_1_prediction_pearsons_r: -0.1006 - val_output_6_1_prediction_SMAPE: 1.0053 - val_output_6_1_prediction_MBE: -0.0371 - val_output_6_1_prediction_R2: -0.1193 - val_output_7_1_prediction_mse: 0.0173 - val_output_7_1_prediction_pearsons_r: 0.1398 - val_output_7_1_prediction_SMAPE: 1.1105 - val_output_7_1_prediction_MBE: -0.0857 - val_output_7_1_prediction_R2: 0.3104 - lr: 1.8500e-04\n",
      "Epoch 5/2000\n",
      "52/52 [==============================] - 25s 474ms/step - loss: 2.0173 - output_0_1_prediction_loss: 0.1650 - output_0_2_quantile_05_loss: 0.0267 - output_0_3_quantile_95_loss: 0.0328 - output_1_1_prediction_loss: 0.1645 - output_1_2_quantile_05_loss: 0.0188 - output_1_3_quantile_95_loss: 0.0346 - output_2_1_prediction_loss: 0.1702 - output_2_2_quantile_05_loss: 0.0329 - output_2_3_quantile_95_loss: 0.0938 - output_3_1_prediction_loss: 0.1814 - output_3_2_quantile_05_loss: 0.1356 - output_3_3_quantile_95_loss: 0.1213 - output_4_1_prediction_loss: 0.1644 - output_4_2_quantile_05_loss: 0.0153 - output_4_3_quantile_95_loss: 0.0300 - output_5_1_prediction_loss: 0.1625 - output_5_2_quantile_05_loss: 0.0201 - output_5_3_quantile_95_loss: 0.0325 - output_6_1_prediction_loss: 0.1649 - output_6_2_quantile_05_loss: 0.0133 - output_6_3_quantile_95_loss: 0.0292 - output_7_1_prediction_loss: 0.1636 - output_7_2_quantile_05_loss: 0.0131 - output_7_3_quantile_95_loss: 0.0309 - output_0_1_prediction_mse: 0.0510 - output_0_1_prediction_pearsons_r: -1.0688 - output_0_1_prediction_SMAPE: 0.8979 - output_0_1_prediction_MBE: 0.0746 - output_0_1_prediction_R2: -0.1015 - output_1_1_prediction_mse: 0.0509 - output_1_1_prediction_pearsons_r: 2.5964 - output_1_1_prediction_SMAPE: 0.8943 - output_1_1_prediction_MBE: 0.0742 - output_1_1_prediction_R2: 0.4584 - output_2_1_prediction_mse: 0.0537 - output_2_1_prediction_pearsons_r: -1.4336 - output_2_1_prediction_SMAPE: 0.9459 - output_2_1_prediction_MBE: 0.0746 - output_2_1_prediction_R2: 0.2492 - output_3_1_prediction_mse: 0.0576 - output_3_1_prediction_pearsons_r: -2.0006 - output_3_1_prediction_SMAPE: 0.9815 - output_3_1_prediction_MBE: 0.0583 - output_3_1_prediction_R2: 0.1278 - output_4_1_prediction_mse: 0.0509 - output_4_1_prediction_pearsons_r: -2.7942 - output_4_1_prediction_SMAPE: 0.8982 - output_4_1_prediction_MBE: 0.0769 - output_4_1_prediction_R2: -0.0991 - output_5_1_prediction_mse: 0.0500 - output_5_1_prediction_pearsons_r: 2.8193 - output_5_1_prediction_SMAPE: 0.8866 - output_5_1_prediction_MBE: 0.0768 - output_5_1_prediction_R2: 0.2423 - output_6_1_prediction_mse: 0.0507 - output_6_1_prediction_pearsons_r: 2.1948 - output_6_1_prediction_SMAPE: 0.8989 - output_6_1_prediction_MBE: 0.0745 - output_6_1_prediction_R2: 0.0841 - output_7_1_prediction_mse: 0.0503 - output_7_1_prediction_pearsons_r: 2.8622 - output_7_1_prediction_SMAPE: 0.8944 - output_7_1_prediction_MBE: 0.0762 - output_7_1_prediction_R2: -0.1551 - val_loss: 1.8083 - val_output_0_1_prediction_loss: 0.0959 - val_output_0_2_quantile_05_loss: 0.0256 - val_output_0_3_quantile_95_loss: 0.0262 - val_output_1_1_prediction_loss: 0.1405 - val_output_1_2_quantile_05_loss: 0.0114 - val_output_1_3_quantile_95_loss: 0.0348 - val_output_2_1_prediction_loss: 0.1261 - val_output_2_2_quantile_05_loss: 0.0231 - val_output_2_3_quantile_95_loss: 0.0554 - val_output_3_1_prediction_loss: 0.1540 - val_output_3_2_quantile_05_loss: 0.2926 - val_output_3_3_quantile_95_loss: 0.2340 - val_output_4_1_prediction_loss: 0.1371 - val_output_4_2_quantile_05_loss: 0.0196 - val_output_4_3_quantile_95_loss: 0.0470 - val_output_5_1_prediction_loss: 0.0728 - val_output_5_2_quantile_05_loss: 0.0043 - val_output_5_3_quantile_95_loss: 0.0202 - val_output_6_1_prediction_loss: 0.0772 - val_output_6_2_quantile_05_loss: 0.0101 - val_output_6_3_quantile_95_loss: 0.0269 - val_output_7_1_prediction_loss: 0.1320 - val_output_7_2_quantile_05_loss: 0.0084 - val_output_7_3_quantile_95_loss: 0.0330 - val_output_0_1_prediction_mse: 0.0126 - val_output_0_1_prediction_pearsons_r: -0.1287 - val_output_0_1_prediction_SMAPE: 1.0345 - val_output_0_1_prediction_MBE: -0.0504 - val_output_0_1_prediction_R2: 0.2179 - val_output_1_1_prediction_mse: 0.0228 - val_output_1_1_prediction_pearsons_r: 0.1237 - val_output_1_1_prediction_SMAPE: 1.1632 - val_output_1_1_prediction_MBE: -0.1137 - val_output_1_1_prediction_R2: 0.8392 - val_output_2_1_prediction_mse: 0.0188 - val_output_2_1_prediction_pearsons_r: -0.0685 - val_output_2_1_prediction_SMAPE: 1.1275 - val_output_2_1_prediction_MBE: -0.0944 - val_output_2_1_prediction_R2: -2.2625 - val_output_3_1_prediction_mse: 0.0339 - val_output_3_1_prediction_pearsons_r: 0.0082 - val_output_3_1_prediction_SMAPE: 2.0000 - val_output_3_1_prediction_MBE: 0.1525 - val_output_3_1_prediction_R2: 0.6211 - val_output_4_1_prediction_mse: 0.0218 - val_output_4_1_prediction_pearsons_r: 0.0436 - val_output_4_1_prediction_SMAPE: 1.1551 - val_output_4_1_prediction_MBE: -0.1093 - val_output_4_1_prediction_R2: -0.3915 - val_output_5_1_prediction_mse: 0.0102 - val_output_5_1_prediction_pearsons_r: -0.0168 - val_output_5_1_prediction_SMAPE: 0.9489 - val_output_5_1_prediction_MBE: -0.0019 - val_output_5_1_prediction_R2: 0.8864 - val_output_6_1_prediction_mse: 0.0104 - val_output_6_1_prediction_pearsons_r: -0.0735 - val_output_6_1_prediction_SMAPE: 0.9624 - val_output_6_1_prediction_MBE: -0.0153 - val_output_6_1_prediction_R2: 0.0472 - val_output_7_1_prediction_mse: 0.0204 - val_output_7_1_prediction_pearsons_r: 0.1074 - val_output_7_1_prediction_SMAPE: 1.1426 - val_output_7_1_prediction_MBE: -0.1025 - val_output_7_1_prediction_R2: 0.1871 - lr: 1.8500e-04\n",
      "Epoch 6/2000\n",
      "52/52 [==============================] - 24s 467ms/step - loss: 1.7656 - output_0_1_prediction_loss: 0.1619 - output_0_2_quantile_05_loss: 0.0156 - output_0_3_quantile_95_loss: 0.0291 - output_1_1_prediction_loss: 0.1625 - output_1_2_quantile_05_loss: 0.0133 - output_1_3_quantile_95_loss: 0.0292 - output_2_1_prediction_loss: 0.1623 - output_2_2_quantile_05_loss: 0.0168 - output_2_3_quantile_95_loss: 0.0358 - output_3_1_prediction_loss: 0.1929 - output_3_2_quantile_05_loss: 0.0639 - output_3_3_quantile_95_loss: 0.0552 - output_4_1_prediction_loss: 0.1634 - output_4_2_quantile_05_loss: 0.0178 - output_4_3_quantile_95_loss: 0.0324 - output_5_1_prediction_loss: 0.1630 - output_5_2_quantile_05_loss: 0.0131 - output_5_3_quantile_95_loss: 0.0294 - output_6_1_prediction_loss: 0.1621 - output_6_2_quantile_05_loss: 0.0154 - output_6_3_quantile_95_loss: 0.0286 - output_7_1_prediction_loss: 0.1615 - output_7_2_quantile_05_loss: 0.0116 - output_7_3_quantile_95_loss: 0.0288 - output_0_1_prediction_mse: 0.0491 - output_0_1_prediction_pearsons_r: -2.4409 - output_0_1_prediction_SMAPE: 0.8804 - output_0_1_prediction_MBE: 0.0719 - output_0_1_prediction_R2: -0.0597 - output_1_1_prediction_mse: 0.0495 - output_1_1_prediction_pearsons_r: 2.8636 - output_1_1_prediction_SMAPE: 0.8839 - output_1_1_prediction_MBE: 0.0723 - output_1_1_prediction_R2: 0.4721 - output_2_1_prediction_mse: 0.0489 - output_2_1_prediction_pearsons_r: -2.7921 - output_2_1_prediction_SMAPE: 0.8854 - output_2_1_prediction_MBE: 0.0713 - output_2_1_prediction_R2: 0.3163 - output_3_1_prediction_mse: 0.0632 - output_3_1_prediction_pearsons_r: 0.0931 - output_3_1_prediction_SMAPE: 1.0459 - output_3_1_prediction_MBE: 0.0526 - output_3_1_prediction_R2: 0.0382 - output_4_1_prediction_mse: 0.0496 - output_4_1_prediction_pearsons_r: -2.7691 - output_4_1_prediction_SMAPE: 0.8874 - output_4_1_prediction_MBE: 0.0707 - output_4_1_prediction_R2: -0.0723 - output_5_1_prediction_mse: 0.0495 - output_5_1_prediction_pearsons_r: 2.7896 - output_5_1_prediction_SMAPE: 0.8867 - output_5_1_prediction_MBE: 0.0721 - output_5_1_prediction_R2: 0.2509 - output_6_1_prediction_mse: 0.0495 - output_6_1_prediction_pearsons_r: -1.0531 - output_6_1_prediction_SMAPE: 0.8830 - output_6_1_prediction_MBE: 0.0742 - output_6_1_prediction_R2: 0.1072 - output_7_1_prediction_mse: 0.0492 - output_7_1_prediction_pearsons_r: 2.7829 - output_7_1_prediction_SMAPE: 0.8815 - output_7_1_prediction_MBE: 0.0752 - output_7_1_prediction_R2: -0.1307 - val_loss: 1.3380 - val_output_0_1_prediction_loss: 0.1132 - val_output_0_2_quantile_05_loss: 0.0081 - val_output_0_3_quantile_95_loss: 0.0291 - val_output_1_1_prediction_loss: 0.1370 - val_output_1_2_quantile_05_loss: 0.0058 - val_output_1_3_quantile_95_loss: 0.0331 - val_output_2_1_prediction_loss: 0.1428 - val_output_2_2_quantile_05_loss: 0.0147 - val_output_2_3_quantile_95_loss: 0.0535 - val_output_3_1_prediction_loss: 0.0920 - val_output_3_2_quantile_05_loss: 0.0087 - val_output_3_3_quantile_95_loss: 0.0331 - val_output_4_1_prediction_loss: 0.1447 - val_output_4_2_quantile_05_loss: 0.0048 - val_output_4_3_quantile_95_loss: 0.0240 - val_output_5_1_prediction_loss: 0.1059 - val_output_5_2_quantile_05_loss: 0.0041 - val_output_5_3_quantile_95_loss: 0.0280 - val_output_6_1_prediction_loss: 0.1267 - val_output_6_2_quantile_05_loss: 0.0112 - val_output_6_3_quantile_95_loss: 0.0298 - val_output_7_1_prediction_loss: 0.1392 - val_output_7_2_quantile_05_loss: 0.0066 - val_output_7_3_quantile_95_loss: 0.0418 - val_output_0_1_prediction_mse: 0.0158 - val_output_0_1_prediction_pearsons_r: -0.0516 - val_output_0_1_prediction_SMAPE: 1.0918 - val_output_0_1_prediction_MBE: -0.0764 - val_output_0_1_prediction_R2: 0.0090 - val_output_1_1_prediction_mse: 0.0218 - val_output_1_1_prediction_pearsons_r: 0.1556 - val_output_1_1_prediction_SMAPE: 1.1548 - val_output_1_1_prediction_MBE: -0.1092 - val_output_1_1_prediction_R2: 0.8462 - val_output_2_1_prediction_mse: 0.0234 - val_output_2_1_prediction_pearsons_r: 0.1556 - val_output_2_1_prediction_SMAPE: 1.1687 - val_output_2_1_prediction_MBE: -0.1167 - val_output_2_1_prediction_R2: -3.2136 - val_output_3_1_prediction_mse: 0.0120 - val_output_3_1_prediction_pearsons_r: 0.1314 - val_output_3_1_prediction_SMAPE: 1.0206 - val_output_3_1_prediction_MBE: -0.0441 - val_output_3_1_prediction_R2: 0.8680 - val_output_4_1_prediction_mse: 0.0240 - val_output_4_1_prediction_pearsons_r: -0.1605 - val_output_4_1_prediction_SMAPE: 1.1730 - val_output_4_1_prediction_MBE: -0.1190 - val_output_4_1_prediction_R2: -0.5337 - val_output_5_1_prediction_mse: 0.0143 - val_output_5_1_prediction_pearsons_r: 0.1592 - val_output_5_1_prediction_SMAPE: 1.0690 - val_output_5_1_prediction_MBE: -0.0659 - val_output_5_1_prediction_R2: 0.8437 - val_output_6_1_prediction_mse: 0.0190 - val_output_6_1_prediction_pearsons_r: -0.0022 - val_output_6_1_prediction_SMAPE: 1.1292 - val_output_6_1_prediction_MBE: -0.0953 - val_output_6_1_prediction_R2: -1.0657 - val_output_7_1_prediction_mse: 0.0224 - val_output_7_1_prediction_pearsons_r: 0.0472 - val_output_7_1_prediction_SMAPE: 1.1602 - val_output_7_1_prediction_MBE: -0.1121 - val_output_7_1_prediction_R2: 0.1066 - lr: 1.8500e-04\n",
      "Epoch 7/2000\n",
      "52/52 [==============================] - 24s 461ms/step - loss: 1.6451 - output_0_1_prediction_loss: 0.1613 - output_0_2_quantile_05_loss: 0.0122 - output_0_3_quantile_95_loss: 0.0282 - output_1_1_prediction_loss: 0.1626 - output_1_2_quantile_05_loss: 0.0115 - output_1_3_quantile_95_loss: 0.0289 - output_2_1_prediction_loss: 0.1617 - output_2_2_quantile_05_loss: 0.0135 - output_2_3_quantile_95_loss: 0.0324 - output_3_1_prediction_loss: 0.1624 - output_3_2_quantile_05_loss: 0.0214 - output_3_3_quantile_95_loss: 0.0288 - output_4_1_prediction_loss: 0.1634 - output_4_2_quantile_05_loss: 0.0124 - output_4_3_quantile_95_loss: 0.0289 - output_5_1_prediction_loss: 0.1610 - output_5_2_quantile_05_loss: 0.0135 - output_5_3_quantile_95_loss: 0.0282 - output_6_1_prediction_loss: 0.1617 - output_6_2_quantile_05_loss: 0.0132 - output_6_3_quantile_95_loss: 0.0286 - output_7_1_prediction_loss: 0.1641 - output_7_2_quantile_05_loss: 0.0124 - output_7_3_quantile_95_loss: 0.0327 - output_0_1_prediction_mse: 0.0491 - output_0_1_prediction_pearsons_r: 1.0858 - output_0_1_prediction_SMAPE: 0.8800 - output_0_1_prediction_MBE: 0.0759 - output_0_1_prediction_R2: -0.0631 - output_1_1_prediction_mse: 0.0499 - output_1_1_prediction_pearsons_r: 2.9030 - output_1_1_prediction_SMAPE: 0.8852 - output_1_1_prediction_MBE: 0.0757 - output_1_1_prediction_R2: 0.4730 - output_2_1_prediction_mse: 0.0491 - output_2_1_prediction_pearsons_r: -2.7138 - output_2_1_prediction_SMAPE: 0.8822 - output_2_1_prediction_MBE: 0.0745 - output_2_1_prediction_R2: 0.3162 - output_3_1_prediction_mse: 0.0494 - output_3_1_prediction_pearsons_r: -1.2911 - output_3_1_prediction_SMAPE: 0.8846 - output_3_1_prediction_MBE: 0.0742 - output_3_1_prediction_R2: 0.2563 - output_4_1_prediction_mse: 0.0502 - output_4_1_prediction_pearsons_r: -2.8079 - output_4_1_prediction_SMAPE: 0.8891 - output_4_1_prediction_MBE: 0.0747 - output_4_1_prediction_R2: -0.0775 - output_5_1_prediction_mse: 0.0491 - output_5_1_prediction_pearsons_r: 2.9033 - output_5_1_prediction_SMAPE: 0.8790 - output_5_1_prediction_MBE: 0.0761 - output_5_1_prediction_R2: 0.2630 - output_6_1_prediction_mse: 0.0495 - output_6_1_prediction_pearsons_r: -1.4431 - output_6_1_prediction_SMAPE: 0.8826 - output_6_1_prediction_MBE: 0.0764 - output_6_1_prediction_R2: 0.1078 - output_7_1_prediction_mse: 0.0508 - output_7_1_prediction_pearsons_r: 2.8316 - output_7_1_prediction_SMAPE: 0.8958 - output_7_1_prediction_MBE: 0.0781 - output_7_1_prediction_R2: -0.1765 - val_loss: 1.0002 - val_output_0_1_prediction_loss: 0.0885 - val_output_0_2_quantile_05_loss: 0.0047 - val_output_0_3_quantile_95_loss: 0.0256 - val_output_1_1_prediction_loss: 0.0873 - val_output_1_2_quantile_05_loss: 0.0059 - val_output_1_3_quantile_95_loss: 0.0210 - val_output_2_1_prediction_loss: 0.1057 - val_output_2_2_quantile_05_loss: 0.0070 - val_output_2_3_quantile_95_loss: 0.0277 - val_output_3_1_prediction_loss: 0.1015 - val_output_3_2_quantile_05_loss: 0.0127 - val_output_3_3_quantile_95_loss: 0.0287 - val_output_4_1_prediction_loss: 0.0922 - val_output_4_2_quantile_05_loss: 0.0045 - val_output_4_3_quantile_95_loss: 0.0241 - val_output_5_1_prediction_loss: 0.0938 - val_output_5_2_quantile_05_loss: 0.0056 - val_output_5_3_quantile_95_loss: 0.0241 - val_output_6_1_prediction_loss: 0.0871 - val_output_6_2_quantile_05_loss: 0.0047 - val_output_6_3_quantile_95_loss: 0.0246 - val_output_7_1_prediction_loss: 0.0908 - val_output_7_2_quantile_05_loss: 0.0049 - val_output_7_3_quantile_95_loss: 0.0274 - val_output_0_1_prediction_mse: 0.0115 - val_output_0_1_prediction_pearsons_r: -0.0137 - val_output_0_1_prediction_SMAPE: 1.0074 - val_output_0_1_prediction_MBE: -0.0380 - val_output_0_1_prediction_R2: 0.2874 - val_output_1_1_prediction_mse: 0.0114 - val_output_1_1_prediction_pearsons_r: 0.0689 - val_output_1_1_prediction_SMAPE: 1.0025 - val_output_1_1_prediction_MBE: -0.0358 - val_output_1_1_prediction_R2: 0.9187 - val_output_2_1_prediction_mse: 0.0143 - val_output_2_1_prediction_pearsons_r: -0.1184 - val_output_2_1_prediction_SMAPE: 1.0682 - val_output_2_1_prediction_MBE: -0.0655 - val_output_2_1_prediction_R2: -1.2701 - val_output_3_1_prediction_mse: 0.0135 - val_output_3_1_prediction_pearsons_r: 0.0326 - val_output_3_1_prediction_SMAPE: 1.0543 - val_output_3_1_prediction_MBE: -0.0593 - val_output_3_1_prediction_R2: 0.8520 - val_output_4_1_prediction_mse: 0.0120 - val_output_4_1_prediction_pearsons_r: -0.2450 - val_output_4_1_prediction_SMAPE: 1.0211 - val_output_4_1_prediction_MBE: -0.0443 - val_output_4_1_prediction_R2: 0.2474 - val_output_5_1_prediction_mse: 0.0123 - val_output_5_1_prediction_pearsons_r: 0.0979 - val_output_5_1_prediction_SMAPE: 1.0270 - val_output_5_1_prediction_MBE: -0.0470 - val_output_5_1_prediction_R2: 0.8656 - val_output_6_1_prediction_mse: 0.0113 - val_output_6_1_prediction_pearsons_r: -0.0647 - val_output_6_1_prediction_SMAPE: 1.0020 - val_output_6_1_prediction_MBE: -0.0356 - val_output_6_1_prediction_R2: -0.1048 - val_output_7_1_prediction_mse: 0.0118 - val_output_7_1_prediction_pearsons_r: 0.1727 - val_output_7_1_prediction_SMAPE: 1.0160 - val_output_7_1_prediction_MBE: -0.0420 - val_output_7_1_prediction_R2: 0.5253 - lr: 1.8500e-04\n",
      "Epoch 8/2000\n",
      "52/52 [==============================] - 25s 468ms/step - loss: 1.6373 - output_0_1_prediction_loss: 0.1615 - output_0_2_quantile_05_loss: 0.0135 - output_0_3_quantile_95_loss: 0.0284 - output_1_1_prediction_loss: 0.1633 - output_1_2_quantile_05_loss: 0.0118 - output_1_3_quantile_95_loss: 0.0297 - output_2_1_prediction_loss: 0.1610 - output_2_2_quantile_05_loss: 0.0137 - output_2_3_quantile_95_loss: 0.0300 - output_3_1_prediction_loss: 0.1617 - output_3_2_quantile_05_loss: 0.0167 - output_3_3_quantile_95_loss: 0.0293 - output_4_1_prediction_loss: 0.1638 - output_4_2_quantile_05_loss: 0.0131 - output_4_3_quantile_95_loss: 0.0298 - output_5_1_prediction_loss: 0.1613 - output_5_2_quantile_05_loss: 0.0135 - output_5_3_quantile_95_loss: 0.0287 - output_6_1_prediction_loss: 0.1617 - output_6_2_quantile_05_loss: 0.0113 - output_6_3_quantile_95_loss: 0.0285 - output_7_1_prediction_loss: 0.1635 - output_7_2_quantile_05_loss: 0.0117 - output_7_3_quantile_95_loss: 0.0297 - output_0_1_prediction_mse: 0.0494 - output_0_1_prediction_pearsons_r: -0.4985 - output_0_1_prediction_SMAPE: 0.8820 - output_0_1_prediction_MBE: 0.0767 - output_0_1_prediction_R2: -0.0656 - output_1_1_prediction_mse: 0.0493 - output_1_1_prediction_pearsons_r: 2.8664 - output_1_1_prediction_SMAPE: 0.8880 - output_1_1_prediction_MBE: 0.0699 - output_1_1_prediction_R2: 0.4743 - output_2_1_prediction_mse: 0.0496 - output_2_1_prediction_pearsons_r: -2.3165 - output_2_1_prediction_SMAPE: 0.8810 - output_2_1_prediction_MBE: 0.0794 - output_2_1_prediction_R2: 0.3077 - output_3_1_prediction_mse: 0.0492 - output_3_1_prediction_pearsons_r: -0.3339 - output_3_1_prediction_SMAPE: 0.8823 - output_3_1_prediction_MBE: 0.0737 - output_3_1_prediction_R2: 0.2569 - output_4_1_prediction_mse: 0.0497 - output_4_1_prediction_pearsons_r: -2.7665 - output_4_1_prediction_SMAPE: 0.8909 - output_4_1_prediction_MBE: 0.0711 - output_4_1_prediction_R2: -0.0688 - output_5_1_prediction_mse: 0.0499 - output_5_1_prediction_pearsons_r: 2.8703 - output_5_1_prediction_SMAPE: 0.8830 - output_5_1_prediction_MBE: 0.0803 - output_5_1_prediction_R2: 0.2463 - output_6_1_prediction_mse: 0.0494 - output_6_1_prediction_pearsons_r: -1.1882 - output_6_1_prediction_SMAPE: 0.8830 - output_6_1_prediction_MBE: 0.0757 - output_6_1_prediction_R2: 0.1083 - output_7_1_prediction_mse: 0.0502 - output_7_1_prediction_pearsons_r: 2.7792 - output_7_1_prediction_SMAPE: 0.8921 - output_7_1_prediction_MBE: 0.0744 - output_7_1_prediction_R2: -0.1540 - val_loss: 1.2418 - val_output_0_1_prediction_loss: 0.1117 - val_output_0_2_quantile_05_loss: 0.0047 - val_output_0_3_quantile_95_loss: 0.0285 - val_output_1_1_prediction_loss: 0.0910 - val_output_1_2_quantile_05_loss: 0.0157 - val_output_1_3_quantile_95_loss: 0.0366 - val_output_2_1_prediction_loss: 0.1141 - val_output_2_2_quantile_05_loss: 0.0058 - val_output_2_3_quantile_95_loss: 0.0245 - val_output_3_1_prediction_loss: 0.1100 - val_output_3_2_quantile_05_loss: 0.0091 - val_output_3_3_quantile_95_loss: 0.0383 - val_output_4_1_prediction_loss: 0.1021 - val_output_4_2_quantile_05_loss: 0.0386 - val_output_4_3_quantile_95_loss: 0.0258 - val_output_5_1_prediction_loss: 0.1201 - val_output_5_2_quantile_05_loss: 0.0058 - val_output_5_3_quantile_95_loss: 0.0255 - val_output_6_1_prediction_loss: 0.1192 - val_output_6_2_quantile_05_loss: 0.0052 - val_output_6_3_quantile_95_loss: 0.0355 - val_output_7_1_prediction_loss: 0.1408 - val_output_7_2_quantile_05_loss: 0.0058 - val_output_7_3_quantile_95_loss: 0.0274 - val_output_0_1_prediction_mse: 0.0155 - val_output_0_1_prediction_pearsons_r: -0.0336 - val_output_0_1_prediction_SMAPE: 1.0873 - val_output_0_1_prediction_MBE: -0.0743 - val_output_0_1_prediction_R2: 0.0293 - val_output_1_1_prediction_mse: 0.0119 - val_output_1_1_prediction_pearsons_r: 0.1078 - val_output_1_1_prediction_SMAPE: 1.0167 - val_output_1_1_prediction_MBE: -0.0423 - val_output_1_1_prediction_R2: 0.9153 - val_output_2_1_prediction_mse: 0.0160 - val_output_2_1_prediction_pearsons_r: 0.0411 - val_output_2_1_prediction_SMAPE: 1.0943 - val_output_2_1_prediction_MBE: -0.0777 - val_output_2_1_prediction_R2: -1.6531 - val_output_3_1_prediction_mse: 0.0151 - val_output_3_1_prediction_pearsons_r: 0.1004 - val_output_3_1_prediction_SMAPE: 1.0819 - val_output_3_1_prediction_MBE: -0.0717 - val_output_3_1_prediction_R2: 0.8351 - val_output_4_1_prediction_mse: 0.0136 - val_output_4_1_prediction_pearsons_r: -0.0681 - val_output_4_1_prediction_SMAPE: 1.0563 - val_output_4_1_prediction_MBE: -0.0602 - val_output_4_1_prediction_R2: 0.1412 - val_output_5_1_prediction_mse: 0.0173 - val_output_5_1_prediction_pearsons_r: 0.1442 - val_output_5_1_prediction_SMAPE: 1.1114 - val_output_5_1_prediction_MBE: -0.0861 - val_output_5_1_prediction_R2: 0.8116 - val_output_6_1_prediction_mse: 0.0171 - val_output_6_1_prediction_pearsons_r: -0.1098 - val_output_6_1_prediction_SMAPE: 1.1090 - val_output_6_1_prediction_MBE: -0.0849 - val_output_6_1_prediction_R2: -0.8436 - val_output_7_1_prediction_mse: 0.0229 - val_output_7_1_prediction_pearsons_r: 0.0252 - val_output_7_1_prediction_SMAPE: 1.1641 - val_output_7_1_prediction_MBE: -0.1142 - val_output_7_1_prediction_R2: 0.0881 - lr: 1.8500e-04\n",
      "Epoch 9/2000\n",
      "52/52 [==============================] - 24s 463ms/step - loss: 1.6509 - output_0_1_prediction_loss: 0.1626 - output_0_2_quantile_05_loss: 0.0147 - output_0_3_quantile_95_loss: 0.0293 - output_1_1_prediction_loss: 0.1621 - output_1_2_quantile_05_loss: 0.0124 - output_1_3_quantile_95_loss: 0.0290 - output_2_1_prediction_loss: 0.1628 - output_2_2_quantile_05_loss: 0.0147 - output_2_3_quantile_95_loss: 0.0366 - output_3_1_prediction_loss: 0.1626 - output_3_2_quantile_05_loss: 0.0168 - output_3_3_quantile_95_loss: 0.0290 - output_4_1_prediction_loss: 0.1628 - output_4_2_quantile_05_loss: 0.0147 - output_4_3_quantile_95_loss: 0.0302 - output_5_1_prediction_loss: 0.1611 - output_5_2_quantile_05_loss: 0.0126 - output_5_3_quantile_95_loss: 0.0285 - output_6_1_prediction_loss: 0.1614 - output_6_2_quantile_05_loss: 0.0118 - output_6_3_quantile_95_loss: 0.0290 - output_7_1_prediction_loss: 0.1630 - output_7_2_quantile_05_loss: 0.0117 - output_7_3_quantile_95_loss: 0.0315 - output_0_1_prediction_mse: 0.0500 - output_0_1_prediction_pearsons_r: 1.6972 - output_0_1_prediction_SMAPE: 0.8869 - output_0_1_prediction_MBE: 0.0761 - output_0_1_prediction_R2: -0.0758 - output_1_1_prediction_mse: 0.0501 - output_1_1_prediction_pearsons_r: 2.8743 - output_1_1_prediction_SMAPE: 0.8873 - output_1_1_prediction_MBE: 0.0779 - output_1_1_prediction_R2: 0.4681 - output_2_1_prediction_mse: 0.0502 - output_2_1_prediction_pearsons_r: -0.3093 - output_2_1_prediction_SMAPE: 0.8897 - output_2_1_prediction_MBE: 0.0769 - output_2_1_prediction_R2: 0.3048 - output_3_1_prediction_mse: 0.0502 - output_3_1_prediction_pearsons_r: -1.5912 - output_3_1_prediction_SMAPE: 0.8889 - output_3_1_prediction_MBE: 0.0767 - output_3_1_prediction_R2: 0.2437 - output_4_1_prediction_mse: 0.0501 - output_4_1_prediction_pearsons_r: -2.0317 - output_4_1_prediction_SMAPE: 0.8887 - output_4_1_prediction_MBE: 0.0762 - output_4_1_prediction_R2: -0.0755 - output_5_1_prediction_mse: 0.0489 - output_5_1_prediction_pearsons_r: 2.8650 - output_5_1_prediction_SMAPE: 0.8787 - output_5_1_prediction_MBE: 0.0739 - output_5_1_prediction_R2: 0.2621 - output_6_1_prediction_mse: 0.0494 - output_6_1_prediction_pearsons_r: -0.2255 - output_6_1_prediction_SMAPE: 0.8813 - output_6_1_prediction_MBE: 0.0756 - output_6_1_prediction_R2: 0.1117 - output_7_1_prediction_mse: 0.0502 - output_7_1_prediction_pearsons_r: 2.8477 - output_7_1_prediction_SMAPE: 0.8902 - output_7_1_prediction_MBE: 0.0765 - output_7_1_prediction_R2: -0.1542 - val_loss: 1.2533 - val_output_0_1_prediction_loss: 0.1373 - val_output_0_2_quantile_05_loss: 0.0041 - val_output_0_3_quantile_95_loss: 0.0268 - val_output_1_1_prediction_loss: 0.1039 - val_output_1_2_quantile_05_loss: 0.0043 - val_output_1_3_quantile_95_loss: 0.0255 - val_output_2_1_prediction_loss: 0.1628 - val_output_2_2_quantile_05_loss: 0.0138 - val_output_2_3_quantile_95_loss: 0.0638 - val_output_3_1_prediction_loss: 0.1141 - val_output_3_2_quantile_05_loss: 0.0043 - val_output_3_3_quantile_95_loss: 0.0273 - val_output_4_1_prediction_loss: 0.1114 - val_output_4_2_quantile_05_loss: 0.0049 - val_output_4_3_quantile_95_loss: 0.0238 - val_output_5_1_prediction_loss: 0.1239 - val_output_5_2_quantile_05_loss: 0.0048 - val_output_5_3_quantile_95_loss: 0.0327 - val_output_6_1_prediction_loss: 0.1106 - val_output_6_2_quantile_05_loss: 0.0042 - val_output_6_3_quantile_95_loss: 0.0301 - val_output_7_1_prediction_loss: 0.0924 - val_output_7_2_quantile_05_loss: 0.0041 - val_output_7_3_quantile_95_loss: 0.0224 - val_output_0_1_prediction_mse: 0.0219 - val_output_0_1_prediction_pearsons_r: -0.2521 - val_output_0_1_prediction_SMAPE: 1.1555 - val_output_0_1_prediction_MBE: -0.1096 - val_output_0_1_prediction_R2: -0.3805 - val_output_1_1_prediction_mse: 0.0139 - val_output_1_1_prediction_pearsons_r: 0.1297 - val_output_1_1_prediction_SMAPE: 1.0623 - val_output_1_1_prediction_MBE: -0.0628 - val_output_1_1_prediction_R2: 0.9009 - val_output_2_1_prediction_mse: 0.0298 - val_output_2_1_prediction_pearsons_r: -8.8887e-04 - val_output_2_1_prediction_SMAPE: 1.2120 - val_output_2_1_prediction_MBE: -0.1417 - val_output_2_1_prediction_R2: -4.4804 - val_output_3_1_prediction_mse: 0.0160 - val_output_3_1_prediction_pearsons_r: -0.0605 - val_output_3_1_prediction_SMAPE: 1.0943 - val_output_3_1_prediction_MBE: -0.0777 - val_output_3_1_prediction_R2: 0.8258 - val_output_4_1_prediction_mse: 0.0154 - val_output_4_1_prediction_pearsons_r: 0.1469 - val_output_4_1_prediction_SMAPE: 1.0863 - val_output_4_1_prediction_MBE: -0.0738 - val_output_4_1_prediction_R2: 0.0242 - val_output_5_1_prediction_mse: 0.0183 - val_output_5_1_prediction_pearsons_r: 0.1275 - val_output_5_1_prediction_SMAPE: 1.1220 - val_output_5_1_prediction_MBE: -0.0915 - val_output_5_1_prediction_R2: 0.8015 - val_output_6_1_prediction_mse: 0.0153 - val_output_6_1_prediction_pearsons_r: -0.1413 - val_output_6_1_prediction_SMAPE: 1.0839 - val_output_6_1_prediction_MBE: -0.0727 - val_output_6_1_prediction_R2: -0.6116 - val_output_7_1_prediction_mse: 0.0120 - val_output_7_1_prediction_pearsons_r: 0.1397 - val_output_7_1_prediction_SMAPE: 1.0219 - val_output_7_1_prediction_MBE: -0.0447 - val_output_7_1_prediction_R2: 0.5166 - lr: 1.8500e-04\n",
      "Epoch 10/2000\n",
      "52/52 [==============================] - 25s 483ms/step - loss: 1.6279 - output_0_1_prediction_loss: 0.1616 - output_0_2_quantile_05_loss: 0.0123 - output_0_3_quantile_95_loss: 0.0286 - output_1_1_prediction_loss: 0.1624 - output_1_2_quantile_05_loss: 0.0110 - output_1_3_quantile_95_loss: 0.0289 - output_2_1_prediction_loss: 0.1620 - output_2_2_quantile_05_loss: 0.0135 - output_2_3_quantile_95_loss: 0.0324 - output_3_1_prediction_loss: 0.1621 - output_3_2_quantile_05_loss: 0.0123 - output_3_3_quantile_95_loss: 0.0286 - output_4_1_prediction_loss: 0.1637 - output_4_2_quantile_05_loss: 0.0118 - output_4_3_quantile_95_loss: 0.0293 - output_5_1_prediction_loss: 0.1609 - output_5_2_quantile_05_loss: 0.0129 - output_5_3_quantile_95_loss: 0.0287 - output_6_1_prediction_loss: 0.1622 - output_6_2_quantile_05_loss: 0.0106 - output_6_3_quantile_95_loss: 0.0287 - output_7_1_prediction_loss: 0.1632 - output_7_2_quantile_05_loss: 0.0108 - output_7_3_quantile_95_loss: 0.0294 - output_0_1_prediction_mse: 0.0492 - output_0_1_prediction_pearsons_r: 0.1682 - output_0_1_prediction_SMAPE: 0.8812 - output_0_1_prediction_MBE: 0.0743 - output_0_1_prediction_R2: -0.0621 - output_1_1_prediction_mse: 0.0495 - output_1_1_prediction_pearsons_r: 2.8382 - output_1_1_prediction_SMAPE: 0.8852 - output_1_1_prediction_MBE: 0.0739 - output_1_1_prediction_R2: 0.4745 - output_2_1_prediction_mse: 0.0492 - output_2_1_prediction_pearsons_r: -0.7371 - output_2_1_prediction_SMAPE: 0.8822 - output_2_1_prediction_MBE: 0.0732 - output_2_1_prediction_R2: 0.3144 - output_3_1_prediction_mse: 0.0495 - output_3_1_prediction_pearsons_r: -2.0043 - output_3_1_prediction_SMAPE: 0.8842 - output_3_1_prediction_MBE: 0.0748 - output_3_1_prediction_R2: 0.2524 - output_4_1_prediction_mse: 0.0500 - output_4_1_prediction_pearsons_r: -2.0416 - output_4_1_prediction_SMAPE: 0.8908 - output_4_1_prediction_MBE: 0.0722 - output_4_1_prediction_R2: -0.0763 - output_5_1_prediction_mse: 0.0490 - output_5_1_prediction_pearsons_r: 2.8691 - output_5_1_prediction_SMAPE: 0.8788 - output_5_1_prediction_MBE: 0.0753 - output_5_1_prediction_R2: 0.2613 - output_6_1_prediction_mse: 0.0496 - output_6_1_prediction_pearsons_r: -1.1746 - output_6_1_prediction_SMAPE: 0.8849 - output_6_1_prediction_MBE: 0.0754 - output_6_1_prediction_R2: 0.1039 - output_7_1_prediction_mse: 0.0498 - output_7_1_prediction_pearsons_r: 2.8382 - output_7_1_prediction_SMAPE: 0.8889 - output_7_1_prediction_MBE: 0.0733 - output_7_1_prediction_R2: -0.1459 - val_loss: 1.1406 - val_output_0_1_prediction_loss: 0.1136 - val_output_0_2_quantile_05_loss: 0.0051 - val_output_0_3_quantile_95_loss: 0.0285 - val_output_1_1_prediction_loss: 0.1146 - val_output_1_2_quantile_05_loss: 0.0055 - val_output_1_3_quantile_95_loss: 0.0299 - val_output_2_1_prediction_loss: 0.1031 - val_output_2_2_quantile_05_loss: 0.0083 - val_output_2_3_quantile_95_loss: 0.0262 - val_output_3_1_prediction_loss: 0.1171 - val_output_3_2_quantile_05_loss: 0.0064 - val_output_3_3_quantile_95_loss: 0.0295 - val_output_4_1_prediction_loss: 0.0998 - val_output_4_2_quantile_05_loss: 0.0042 - val_output_4_3_quantile_95_loss: 0.0225 - val_output_5_1_prediction_loss: 0.0987 - val_output_5_2_quantile_05_loss: 0.0072 - val_output_5_3_quantile_95_loss: 0.0250 - val_output_6_1_prediction_loss: 0.1201 - val_output_6_2_quantile_05_loss: 0.0042 - val_output_6_3_quantile_95_loss: 0.0291 - val_output_7_1_prediction_loss: 0.1103 - val_output_7_2_quantile_05_loss: 0.0050 - val_output_7_3_quantile_95_loss: 0.0269 - val_output_0_1_prediction_mse: 0.0159 - val_output_0_1_prediction_pearsons_r: -0.0798 - val_output_0_1_prediction_SMAPE: 1.0927 - val_output_0_1_prediction_MBE: -0.0769 - val_output_0_1_prediction_R2: 0.0043 - val_output_1_1_prediction_mse: 0.0161 - val_output_1_1_prediction_pearsons_r: 0.1799 - val_output_1_1_prediction_SMAPE: 1.0957 - val_output_1_1_prediction_MBE: -0.0784 - val_output_1_1_prediction_R2: 0.8860 - val_output_2_1_prediction_mse: 0.0138 - val_output_2_1_prediction_pearsons_r: -0.0206 - val_output_2_1_prediction_SMAPE: 1.0595 - val_output_2_1_prediction_MBE: -0.0616 - val_output_2_1_prediction_R2: -1.1582 - val_output_3_1_prediction_mse: 0.0167 - val_output_3_1_prediction_pearsons_r: 0.0464 - val_output_3_1_prediction_SMAPE: 1.1032 - val_output_3_1_prediction_MBE: -0.0820 - val_output_3_1_prediction_R2: 0.8185 - val_output_4_1_prediction_mse: 0.0132 - val_output_4_1_prediction_pearsons_r: 0.0332 - val_output_4_1_prediction_SMAPE: 1.0484 - val_output_4_1_prediction_MBE: -0.0566 - val_output_4_1_prediction_R2: 0.1676 - val_output_5_1_prediction_mse: 0.0130 - val_output_5_1_prediction_pearsons_r: 0.2995 - val_output_5_1_prediction_SMAPE: 1.0445 - val_output_5_1_prediction_MBE: -0.0549 - val_output_5_1_prediction_R2: 0.8574 - val_output_6_1_prediction_mse: 0.0174 - val_output_6_1_prediction_pearsons_r: 0.1102 - val_output_6_1_prediction_SMAPE: 1.1115 - val_output_6_1_prediction_MBE: -0.0862 - val_output_6_1_prediction_R2: -0.8690 - val_output_7_1_prediction_mse: 0.0152 - val_output_7_1_prediction_pearsons_r: 0.0599 - val_output_7_1_prediction_SMAPE: 1.0829 - val_output_7_1_prediction_MBE: -0.0722 - val_output_7_1_prediction_R2: 0.3929 - lr: 1.8500e-04\n",
      "Epoch 11/2000\n",
      "52/52 [==============================] - 25s 481ms/step - loss: 1.6338 - output_0_1_prediction_loss: 0.1614 - output_0_2_quantile_05_loss: 0.0126 - output_0_3_quantile_95_loss: 0.0291 - output_1_1_prediction_loss: 0.1636 - output_1_2_quantile_05_loss: 0.0110 - output_1_3_quantile_95_loss: 0.0298 - output_2_1_prediction_loss: 0.1612 - output_2_2_quantile_05_loss: 0.0139 - output_2_3_quantile_95_loss: 0.0346 - output_3_1_prediction_loss: 0.1617 - output_3_2_quantile_05_loss: 0.0130 - output_3_3_quantile_95_loss: 0.0290 - output_4_1_prediction_loss: 0.1636 - output_4_2_quantile_05_loss: 0.0112 - output_4_3_quantile_95_loss: 0.0285 - output_5_1_prediction_loss: 0.1615 - output_5_2_quantile_05_loss: 0.0121 - output_5_3_quantile_95_loss: 0.0296 - output_6_1_prediction_loss: 0.1623 - output_6_2_quantile_05_loss: 0.0107 - output_6_3_quantile_95_loss: 0.0292 - output_7_1_prediction_loss: 0.1629 - output_7_2_quantile_05_loss: 0.0111 - output_7_3_quantile_95_loss: 0.0302 - output_0_1_prediction_mse: 0.0493 - output_0_1_prediction_pearsons_r: 0.9107 - output_0_1_prediction_SMAPE: 0.8810 - output_0_1_prediction_MBE: 0.0756 - output_0_1_prediction_R2: -0.0628 - output_1_1_prediction_mse: 0.0503 - output_1_1_prediction_pearsons_r: 2.6798 - output_1_1_prediction_SMAPE: 0.8929 - output_1_1_prediction_MBE: 0.0753 - output_1_1_prediction_R2: 0.4594 - output_2_1_prediction_mse: 0.0494 - output_2_1_prediction_pearsons_r: 0.5253 - output_2_1_prediction_SMAPE: 0.8809 - output_2_1_prediction_MBE: 0.0768 - output_2_1_prediction_R2: 0.3107 - output_3_1_prediction_mse: 0.0493 - output_3_1_prediction_pearsons_r: -1.0220 - output_3_1_prediction_SMAPE: 0.8820 - output_3_1_prediction_MBE: 0.0735 - output_3_1_prediction_R2: 0.2539 - output_4_1_prediction_mse: 0.0497 - output_4_1_prediction_pearsons_r: 1.2564 - output_4_1_prediction_SMAPE: 0.8906 - output_4_1_prediction_MBE: 0.0718 - output_4_1_prediction_R2: -0.0785 - output_5_1_prediction_mse: 0.0497 - output_5_1_prediction_pearsons_r: 2.8469 - output_5_1_prediction_SMAPE: 0.8825 - output_5_1_prediction_MBE: 0.0783 - output_5_1_prediction_R2: 0.2459 - output_6_1_prediction_mse: 0.0494 - output_6_1_prediction_pearsons_r: 0.1992 - output_6_1_prediction_SMAPE: 0.8838 - output_6_1_prediction_MBE: 0.0720 - output_6_1_prediction_R2: 0.1038 - output_7_1_prediction_mse: 0.0498 - output_7_1_prediction_pearsons_r: 1.5944 - output_7_1_prediction_SMAPE: 0.8882 - output_7_1_prediction_MBE: 0.0752 - output_7_1_prediction_R2: -0.1466 - val_loss: 1.1851 - val_output_0_1_prediction_loss: 0.1228 - val_output_0_2_quantile_05_loss: 0.0049 - val_output_0_3_quantile_95_loss: 0.0331 - val_output_1_1_prediction_loss: 0.1120 - val_output_1_2_quantile_05_loss: 0.0043 - val_output_1_3_quantile_95_loss: 0.0273 - val_output_2_1_prediction_loss: 0.1082 - val_output_2_2_quantile_05_loss: 0.0152 - val_output_2_3_quantile_95_loss: 0.0283 - val_output_3_1_prediction_loss: 0.1050 - val_output_3_2_quantile_05_loss: 0.0053 - val_output_3_3_quantile_95_loss: 0.0292 - val_output_4_1_prediction_loss: 0.1364 - val_output_4_2_quantile_05_loss: 0.0043 - val_output_4_3_quantile_95_loss: 0.0311 - val_output_5_1_prediction_loss: 0.1013 - val_output_5_2_quantile_05_loss: 0.0056 - val_output_5_3_quantile_95_loss: 0.0271 - val_output_6_1_prediction_loss: 0.1120 - val_output_6_2_quantile_05_loss: 0.0053 - val_output_6_3_quantile_95_loss: 0.0284 - val_output_7_1_prediction_loss: 0.1066 - val_output_7_2_quantile_05_loss: 0.0049 - val_output_7_3_quantile_95_loss: 0.0266 - val_output_0_1_prediction_mse: 0.0180 - val_output_0_1_prediction_pearsons_r: 0.0988 - val_output_0_1_prediction_SMAPE: 1.1189 - val_output_0_1_prediction_MBE: -0.0900 - val_output_0_1_prediction_R2: -0.1333 - val_output_1_1_prediction_mse: 0.0155 - val_output_1_1_prediction_pearsons_r: 0.0890 - val_output_1_1_prediction_SMAPE: 1.0882 - val_output_1_1_prediction_MBE: -0.0747 - val_output_1_1_prediction_R2: 0.8898 - val_output_2_1_prediction_mse: 0.0148 - val_output_2_1_prediction_pearsons_r: 0.1030 - val_output_2_1_prediction_SMAPE: 1.0762 - val_output_2_1_prediction_MBE: -0.0691 - val_output_2_1_prediction_R2: -1.3786 - val_output_3_1_prediction_mse: 0.0141 - val_output_3_1_prediction_pearsons_r: -0.0845 - val_output_3_1_prediction_SMAPE: 1.0659 - val_output_3_1_prediction_MBE: -0.0644 - val_output_3_1_prediction_R2: 0.8454 - val_output_4_1_prediction_mse: 0.0216 - val_output_4_1_prediction_pearsons_r: -0.1369 - val_output_4_1_prediction_SMAPE: 1.1535 - val_output_4_1_prediction_MBE: -0.1084 - val_output_4_1_prediction_R2: -0.3796 - val_output_5_1_prediction_mse: 0.0135 - val_output_5_1_prediction_pearsons_r: 0.1741 - val_output_5_1_prediction_SMAPE: 1.0536 - val_output_5_1_prediction_MBE: -0.0589 - val_output_5_1_prediction_R2: 0.8527 - val_output_6_1_prediction_mse: 0.0155 - val_output_6_1_prediction_pearsons_r: 0.0972 - val_output_6_1_prediction_SMAPE: 1.0880 - val_output_6_1_prediction_MBE: -0.0746 - val_output_6_1_prediction_R2: -0.6466 - val_output_7_1_prediction_mse: 0.0145 - val_output_7_1_prediction_pearsons_r: -0.0889 - val_output_7_1_prediction_SMAPE: 1.0712 - val_output_7_1_prediction_MBE: -0.0668 - val_output_7_1_prediction_R2: 0.4219 - lr: 1.8500e-04\n",
      "Epoch 12/2000\n",
      "52/52 [==============================] - 24s 460ms/step - loss: 1.6032 - output_0_1_prediction_loss: 0.1606 - output_0_2_quantile_05_loss: 0.0110 - output_0_3_quantile_95_loss: 0.0281 - output_1_1_prediction_loss: 0.1612 - output_1_2_quantile_05_loss: 0.0110 - output_1_3_quantile_95_loss: 0.0280 - output_2_1_prediction_loss: 0.1607 - output_2_2_quantile_05_loss: 0.0112 - output_2_3_quantile_95_loss: 0.0298 - output_3_1_prediction_loss: 0.1609 - output_3_2_quantile_05_loss: 0.0110 - output_3_3_quantile_95_loss: 0.0282 - output_4_1_prediction_loss: 0.1618 - output_4_2_quantile_05_loss: 0.0115 - output_4_3_quantile_95_loss: 0.0282 - output_5_1_prediction_loss: 0.1606 - output_5_2_quantile_05_loss: 0.0106 - output_5_3_quantile_95_loss: 0.0282 - output_6_1_prediction_loss: 0.1608 - output_6_2_quantile_05_loss: 0.0110 - output_6_3_quantile_95_loss: 0.0282 - output_7_1_prediction_loss: 0.1614 - output_7_2_quantile_05_loss: 0.0111 - output_7_3_quantile_95_loss: 0.0283 - output_0_1_prediction_mse: 0.0489 - output_0_1_prediction_pearsons_r: 2.7464 - output_0_1_prediction_SMAPE: 0.8772 - output_0_1_prediction_MBE: 0.0759 - output_0_1_prediction_R2: -0.0565 - output_1_1_prediction_mse: 0.0491 - output_1_1_prediction_pearsons_r: 2.8079 - output_1_1_prediction_SMAPE: 0.8797 - output_1_1_prediction_MBE: 0.0757 - output_1_1_prediction_R2: 0.4747 - output_2_1_prediction_mse: 0.0494 - output_2_1_prediction_pearsons_r: 1.4051 - output_2_1_prediction_SMAPE: 0.8787 - output_2_1_prediction_MBE: 0.0779 - output_2_1_prediction_R2: 0.3143 - output_3_1_prediction_mse: 0.0494 - output_3_1_prediction_pearsons_r: 1.0539 - output_3_1_prediction_SMAPE: 0.8795 - output_3_1_prediction_MBE: 0.0776 - output_3_1_prediction_R2: 0.2529 - output_4_1_prediction_mse: 0.0496 - output_4_1_prediction_pearsons_r: 2.1205 - output_4_1_prediction_SMAPE: 0.8837 - output_4_1_prediction_MBE: 0.0773 - output_4_1_prediction_R2: -0.0671 - output_5_1_prediction_mse: 0.0488 - output_5_1_prediction_pearsons_r: 2.8464 - output_5_1_prediction_SMAPE: 0.8764 - output_5_1_prediction_MBE: 0.0747 - output_5_1_prediction_R2: 0.2624 - output_6_1_prediction_mse: 0.0493 - output_6_1_prediction_pearsons_r: 2.0159 - output_6_1_prediction_SMAPE: 0.8794 - output_6_1_prediction_MBE: 0.0780 - output_6_1_prediction_R2: 0.1091 - output_7_1_prediction_mse: 0.0494 - output_7_1_prediction_pearsons_r: 2.0691 - output_7_1_prediction_SMAPE: 0.8812 - output_7_1_prediction_MBE: 0.0769 - output_7_1_prediction_R2: -0.1376 - val_loss: 0.9950 - val_output_0_1_prediction_loss: 0.0892 - val_output_0_2_quantile_05_loss: 0.0042 - val_output_0_3_quantile_95_loss: 0.0265 - val_output_1_1_prediction_loss: 0.0916 - val_output_1_2_quantile_05_loss: 0.0069 - val_output_1_3_quantile_95_loss: 0.0246 - val_output_2_1_prediction_loss: 0.0955 - val_output_2_2_quantile_05_loss: 0.0045 - val_output_2_3_quantile_95_loss: 0.0264 - val_output_3_1_prediction_loss: 0.0967 - val_output_3_2_quantile_05_loss: 0.0041 - val_output_3_3_quantile_95_loss: 0.0256 - val_output_4_1_prediction_loss: 0.0958 - val_output_4_2_quantile_05_loss: 0.0049 - val_output_4_3_quantile_95_loss: 0.0265 - val_output_5_1_prediction_loss: 0.0916 - val_output_5_2_quantile_05_loss: 0.0050 - val_output_5_3_quantile_95_loss: 0.0248 - val_output_6_1_prediction_loss: 0.0905 - val_output_6_2_quantile_05_loss: 0.0045 - val_output_6_3_quantile_95_loss: 0.0251 - val_output_7_1_prediction_loss: 0.0948 - val_output_7_2_quantile_05_loss: 0.0111 - val_output_7_3_quantile_95_loss: 0.0246 - val_output_0_1_prediction_mse: 0.0116 - val_output_0_1_prediction_pearsons_r: 0.0909 - val_output_0_1_prediction_SMAPE: 1.0100 - val_output_0_1_prediction_MBE: -0.0392 - val_output_0_1_prediction_R2: 0.2818 - val_output_1_1_prediction_mse: 0.0119 - val_output_1_1_prediction_pearsons_r: 0.2700 - val_output_1_1_prediction_SMAPE: 1.0188 - val_output_1_1_prediction_MBE: -0.0433 - val_output_1_1_prediction_R2: 0.9148 - val_output_2_1_prediction_mse: 0.0125 - val_output_2_1_prediction_pearsons_r: 0.0238 - val_output_2_1_prediction_SMAPE: 1.0332 - val_output_2_1_prediction_MBE: -0.0498 - val_output_2_1_prediction_R2: -0.8496 - val_output_3_1_prediction_mse: 0.0127 - val_output_3_1_prediction_pearsons_r: 0.0828 - val_output_3_1_prediction_SMAPE: 1.0375 - val_output_3_1_prediction_MBE: -0.0517 - val_output_3_1_prediction_R2: 0.8606 - val_output_4_1_prediction_mse: 0.0126 - val_output_4_1_prediction_pearsons_r: -0.1493 - val_output_4_1_prediction_SMAPE: 1.0342 - val_output_4_1_prediction_MBE: -0.0503 - val_output_4_1_prediction_R2: 0.2113 - val_output_5_1_prediction_mse: 0.0119 - val_output_5_1_prediction_pearsons_r: 0.1268 - val_output_5_1_prediction_SMAPE: 1.0189 - val_output_5_1_prediction_MBE: -0.0433 - val_output_5_1_prediction_R2: 0.8690 - val_output_6_1_prediction_mse: 0.0118 - val_output_6_1_prediction_pearsons_r: -0.0505 - val_output_6_1_prediction_SMAPE: 1.0150 - val_output_6_1_prediction_MBE: -0.0415 - val_output_6_1_prediction_R2: -0.1659 - val_output_7_1_prediction_mse: 0.0124 - val_output_7_1_prediction_pearsons_r: 0.2052 - val_output_7_1_prediction_SMAPE: 1.0309 - val_output_7_1_prediction_MBE: -0.0488 - val_output_7_1_prediction_R2: 0.5020 - lr: 1.8500e-04\n",
      "Epoch 13/2000\n",
      "52/52 [==============================] - 24s 465ms/step - loss: 1.6374 - output_0_1_prediction_loss: 0.1626 - output_0_2_quantile_05_loss: 0.0115 - output_0_3_quantile_95_loss: 0.0291 - output_1_1_prediction_loss: 0.1642 - output_1_2_quantile_05_loss: 0.0109 - output_1_3_quantile_95_loss: 0.0289 - output_2_1_prediction_loss: 0.1619 - output_2_2_quantile_05_loss: 0.0115 - output_2_3_quantile_95_loss: 0.0347 - output_3_1_prediction_loss: 0.1627 - output_3_2_quantile_05_loss: 0.0127 - output_3_3_quantile_95_loss: 0.0289 - output_4_1_prediction_loss: 0.1653 - output_4_2_quantile_05_loss: 0.0111 - output_4_3_quantile_95_loss: 0.0295 - output_5_1_prediction_loss: 0.1623 - output_5_2_quantile_05_loss: 0.0108 - output_5_3_quantile_95_loss: 0.0295 - output_6_1_prediction_loss: 0.1627 - output_6_2_quantile_05_loss: 0.0111 - output_6_3_quantile_95_loss: 0.0285 - output_7_1_prediction_loss: 0.1655 - output_7_2_quantile_05_loss: 0.0119 - output_7_3_quantile_95_loss: 0.0296 - output_0_1_prediction_mse: 0.0502 - output_0_1_prediction_pearsons_r: 1.6447 - output_0_1_prediction_SMAPE: 0.8866 - output_0_1_prediction_MBE: 0.0778 - output_0_1_prediction_R2: -0.0802 - output_1_1_prediction_mse: 0.0506 - output_1_1_prediction_pearsons_r: 2.6835 - output_1_1_prediction_SMAPE: 0.8938 - output_1_1_prediction_MBE: 0.0757 - output_1_1_prediction_R2: 0.4563 - output_2_1_prediction_mse: 0.0496 - output_2_1_prediction_pearsons_r: 0.6885 - output_2_1_prediction_SMAPE: 0.8830 - output_2_1_prediction_MBE: 0.0762 - output_2_1_prediction_R2: 0.3116 - output_3_1_prediction_mse: 0.0501 - output_3_1_prediction_pearsons_r: 0.5034 - output_3_1_prediction_SMAPE: 0.8864 - output_3_1_prediction_MBE: 0.0765 - output_3_1_prediction_R2: 0.2406 - output_4_1_prediction_mse: 0.0510 - output_4_1_prediction_pearsons_r: 0.3487 - output_4_1_prediction_SMAPE: 0.8983 - output_4_1_prediction_MBE: 0.0746 - output_4_1_prediction_R2: -0.0971 - output_5_1_prediction_mse: 0.0500 - output_5_1_prediction_pearsons_r: 2.8390 - output_5_1_prediction_SMAPE: 0.8853 - output_5_1_prediction_MBE: 0.0776 - output_5_1_prediction_R2: 0.2420 - output_6_1_prediction_mse: 0.0500 - output_6_1_prediction_pearsons_r: 1.4688 - output_6_1_prediction_SMAPE: 0.8862 - output_6_1_prediction_MBE: 0.0761 - output_6_1_prediction_R2: 0.0994 - output_7_1_prediction_mse: 0.0510 - output_7_1_prediction_pearsons_r: 1.5316 - output_7_1_prediction_SMAPE: 0.8992 - output_7_1_prediction_MBE: 0.0734 - output_7_1_prediction_R2: -0.1670 - val_loss: 0.9613 - val_output_0_1_prediction_loss: 0.0864 - val_output_0_2_quantile_05_loss: 0.0049 - val_output_0_3_quantile_95_loss: 0.0270 - val_output_1_1_prediction_loss: 0.1111 - val_output_1_2_quantile_05_loss: 0.0075 - val_output_1_3_quantile_95_loss: 0.0268 - val_output_2_1_prediction_loss: 0.0855 - val_output_2_2_quantile_05_loss: 0.0084 - val_output_2_3_quantile_95_loss: 0.0304 - val_output_3_1_prediction_loss: 0.0890 - val_output_3_2_quantile_05_loss: 0.0081 - val_output_3_3_quantile_95_loss: 0.0267 - val_output_4_1_prediction_loss: 0.0742 - val_output_4_2_quantile_05_loss: 0.0041 - val_output_4_3_quantile_95_loss: 0.0261 - val_output_5_1_prediction_loss: 0.0826 - val_output_5_2_quantile_05_loss: 0.0044 - val_output_5_3_quantile_95_loss: 0.0227 - val_output_6_1_prediction_loss: 0.0865 - val_output_6_2_quantile_05_loss: 0.0048 - val_output_6_3_quantile_95_loss: 0.0237 - val_output_7_1_prediction_loss: 0.0895 - val_output_7_2_quantile_05_loss: 0.0049 - val_output_7_3_quantile_95_loss: 0.0260 - val_output_0_1_prediction_mse: 0.0113 - val_output_0_1_prediction_pearsons_r: -0.0925 - val_output_0_1_prediction_SMAPE: 0.9990 - val_output_0_1_prediction_MBE: -0.0342 - val_output_0_1_prediction_R2: 0.3051 - val_output_1_1_prediction_mse: 0.0153 - val_output_1_1_prediction_pearsons_r: 0.1550 - val_output_1_1_prediction_SMAPE: 1.0854 - val_output_1_1_prediction_MBE: -0.0734 - val_output_1_1_prediction_R2: 0.8911 - val_output_2_1_prediction_mse: 0.0112 - val_output_2_1_prediction_pearsons_r: -0.0073 - val_output_2_1_prediction_SMAPE: 0.9956 - val_output_2_1_prediction_MBE: -0.0326 - val_output_2_1_prediction_R2: -0.4846 - val_output_3_1_prediction_mse: 0.0116 - val_output_3_1_prediction_pearsons_r: -0.0857 - val_output_3_1_prediction_SMAPE: 1.0091 - val_output_3_1_prediction_MBE: -0.0388 - val_output_3_1_prediction_R2: 0.8724 - val_output_4_1_prediction_mse: 0.0102 - val_output_4_1_prediction_pearsons_r: -0.0291 - val_output_4_1_prediction_SMAPE: 0.9522 - val_output_4_1_prediction_MBE: -0.0069 - val_output_4_1_prediction_R2: 0.3711 - val_output_5_1_prediction_mse: 0.0108 - val_output_5_1_prediction_pearsons_r: 0.0753 - val_output_5_1_prediction_SMAPE: 0.9836 - val_output_5_1_prediction_MBE: -0.0270 - val_output_5_1_prediction_R2: 0.8803 - val_output_6_1_prediction_mse: 0.0113 - val_output_6_1_prediction_pearsons_r: 0.0327 - val_output_6_1_prediction_SMAPE: 0.9994 - val_output_6_1_prediction_MBE: -0.0344 - val_output_6_1_prediction_R2: -0.0931 - val_output_7_1_prediction_mse: 0.0117 - val_output_7_1_prediction_pearsons_r: 0.1236 - val_output_7_1_prediction_SMAPE: 1.0112 - val_output_7_1_prediction_MBE: -0.0398 - val_output_7_1_prediction_R2: 0.5320 - lr: 1.8500e-04\n",
      "Epoch 14/2000\n",
      "52/52 [==============================] - 24s 462ms/step - loss: 1.6276 - output_0_1_prediction_loss: 0.1617 - output_0_2_quantile_05_loss: 0.0108 - output_0_3_quantile_95_loss: 0.0287 - output_1_1_prediction_loss: 0.1628 - output_1_2_quantile_05_loss: 0.0119 - output_1_3_quantile_95_loss: 0.0295 - output_2_1_prediction_loss: 0.1611 - output_2_2_quantile_05_loss: 0.0111 - output_2_3_quantile_95_loss: 0.0352 - output_3_1_prediction_loss: 0.1617 - output_3_2_quantile_05_loss: 0.0120 - output_3_3_quantile_95_loss: 0.0285 - output_4_1_prediction_loss: 0.1631 - output_4_2_quantile_05_loss: 0.0111 - output_4_3_quantile_95_loss: 0.0292 - output_5_1_prediction_loss: 0.1616 - output_5_2_quantile_05_loss: 0.0109 - output_5_3_quantile_95_loss: 0.0286 - output_6_1_prediction_loss: 0.1619 - output_6_2_quantile_05_loss: 0.0111 - output_6_3_quantile_95_loss: 0.0285 - output_7_1_prediction_loss: 0.1634 - output_7_2_quantile_05_loss: 0.0141 - output_7_3_quantile_95_loss: 0.0292 - output_0_1_prediction_mse: 0.0491 - output_0_1_prediction_pearsons_r: 2.4988 - output_0_1_prediction_SMAPE: 0.8816 - output_0_1_prediction_MBE: 0.0741 - output_0_1_prediction_R2: -0.0608 - output_1_1_prediction_mse: 0.0492 - output_1_1_prediction_pearsons_r: 2.2132 - output_1_1_prediction_SMAPE: 0.8849 - output_1_1_prediction_MBE: 0.0712 - output_1_1_prediction_R2: 0.4791 - output_2_1_prediction_mse: 0.0494 - output_2_1_prediction_pearsons_r: 2.2024 - output_2_1_prediction_SMAPE: 0.8811 - output_2_1_prediction_MBE: 0.0785 - output_2_1_prediction_R2: 0.3130 - output_3_1_prediction_mse: 0.0491 - output_3_1_prediction_pearsons_r: 0.9988 - output_3_1_prediction_SMAPE: 0.8815 - output_3_1_prediction_MBE: 0.0740 - output_3_1_prediction_R2: 0.2605 - output_4_1_prediction_mse: 0.0498 - output_4_1_prediction_pearsons_r: 2.0035 - output_4_1_prediction_SMAPE: 0.8885 - output_4_1_prediction_MBE: 0.0741 - output_4_1_prediction_R2: -0.0758 - output_5_1_prediction_mse: 0.0490 - output_5_1_prediction_pearsons_r: 2.8397 - output_5_1_prediction_SMAPE: 0.8812 - output_5_1_prediction_MBE: 0.0737 - output_5_1_prediction_R2: 0.2631 - output_6_1_prediction_mse: 0.0493 - output_6_1_prediction_pearsons_r: 1.9259 - output_6_1_prediction_SMAPE: 0.8823 - output_6_1_prediction_MBE: 0.0742 - output_6_1_prediction_R2: 0.1121 - output_7_1_prediction_mse: 0.0502 - output_7_1_prediction_pearsons_r: 1.1530 - output_7_1_prediction_SMAPE: 0.8905 - output_7_1_prediction_MBE: 0.0765 - output_7_1_prediction_R2: -0.1579 - val_loss: 1.0843 - val_output_0_1_prediction_loss: 0.0862 - val_output_0_2_quantile_05_loss: 0.0087 - val_output_0_3_quantile_95_loss: 0.0277 - val_output_1_1_prediction_loss: 0.1093 - val_output_1_2_quantile_05_loss: 0.0062 - val_output_1_3_quantile_95_loss: 0.0319 - val_output_2_1_prediction_loss: 0.0951 - val_output_2_2_quantile_05_loss: 0.0042 - val_output_2_3_quantile_95_loss: 0.0210 - val_output_3_1_prediction_loss: 0.0909 - val_output_3_2_quantile_05_loss: 0.0043 - val_output_3_3_quantile_95_loss: 0.0304 - val_output_4_1_prediction_loss: 0.1102 - val_output_4_2_quantile_05_loss: 0.0066 - val_output_4_3_quantile_95_loss: 0.0295 - val_output_5_1_prediction_loss: 0.0959 - val_output_5_2_quantile_05_loss: 0.0072 - val_output_5_3_quantile_95_loss: 0.0289 - val_output_6_1_prediction_loss: 0.0955 - val_output_6_2_quantile_05_loss: 0.0050 - val_output_6_3_quantile_95_loss: 0.0298 - val_output_7_1_prediction_loss: 0.1216 - val_output_7_2_quantile_05_loss: 0.0061 - val_output_7_3_quantile_95_loss: 0.0320 - val_output_0_1_prediction_mse: 0.0112 - val_output_0_1_prediction_pearsons_r: 0.3212 - val_output_0_1_prediction_SMAPE: 0.9984 - val_output_0_1_prediction_MBE: -0.0339 - val_output_0_1_prediction_R2: 0.3066 - val_output_1_1_prediction_mse: 0.0150 - val_output_1_1_prediction_pearsons_r: 0.1553 - val_output_1_1_prediction_SMAPE: 1.0799 - val_output_1_1_prediction_MBE: -0.0708 - val_output_1_1_prediction_R2: 0.8936 - val_output_2_1_prediction_mse: 0.0125 - val_output_2_1_prediction_pearsons_r: 0.1262 - val_output_2_1_prediction_SMAPE: 1.0320 - val_output_2_1_prediction_MBE: -0.0493 - val_output_2_1_prediction_R2: -0.8353 - val_output_3_1_prediction_mse: 0.0118 - val_output_3_1_prediction_pearsons_r: 0.1662 - val_output_3_1_prediction_SMAPE: 1.0162 - val_output_3_1_prediction_MBE: -0.0421 - val_output_3_1_prediction_R2: 0.8698 - val_output_4_1_prediction_mse: 0.0152 - val_output_4_1_prediction_pearsons_r: 0.0261 - val_output_4_1_prediction_SMAPE: 1.0825 - val_output_4_1_prediction_MBE: -0.0720 - val_output_4_1_prediction_R2: 0.0410 - val_output_5_1_prediction_mse: 0.0126 - val_output_5_1_prediction_pearsons_r: 0.2961 - val_output_5_1_prediction_SMAPE: 1.0347 - val_output_5_1_prediction_MBE: -0.0505 - val_output_5_1_prediction_R2: 0.8622 - val_output_6_1_prediction_mse: 0.0125 - val_output_6_1_prediction_pearsons_r: 0.1757 - val_output_6_1_prediction_SMAPE: 1.0332 - val_output_6_1_prediction_MBE: -0.0498 - val_output_6_1_prediction_R2: -0.2637 - val_output_7_1_prediction_mse: 0.0177 - val_output_7_1_prediction_pearsons_r: 0.2511 - val_output_7_1_prediction_SMAPE: 1.1158 - val_output_7_1_prediction_MBE: -0.0883 - val_output_7_1_prediction_R2: 0.2926 - lr: 1.8500e-04\n",
      "Epoch 15/2000\n",
      "52/52 [==============================] - 25s 488ms/step - loss: 1.6146 - output_0_1_prediction_loss: 0.1610 - output_0_2_quantile_05_loss: 0.0118 - output_0_3_quantile_95_loss: 0.0288 - output_1_1_prediction_loss: 0.1626 - output_1_2_quantile_05_loss: 0.0112 - output_1_3_quantile_95_loss: 0.0286 - output_2_1_prediction_loss: 0.1614 - output_2_2_quantile_05_loss: 0.0109 - output_2_3_quantile_95_loss: 0.0309 - output_3_1_prediction_loss: 0.1607 - output_3_2_quantile_05_loss: 0.0107 - output_3_3_quantile_95_loss: 0.0285 - output_4_1_prediction_loss: 0.1634 - output_4_2_quantile_05_loss: 0.0110 - output_4_3_quantile_95_loss: 0.0297 - output_5_1_prediction_loss: 0.1605 - output_5_2_quantile_05_loss: 0.0111 - output_5_3_quantile_95_loss: 0.0284 - output_6_1_prediction_loss: 0.1608 - output_6_2_quantile_05_loss: 0.0108 - output_6_3_quantile_95_loss: 0.0285 - output_7_1_prediction_loss: 0.1620 - output_7_2_quantile_05_loss: 0.0115 - output_7_3_quantile_95_loss: 0.0296 - output_0_1_prediction_mse: 0.0493 - output_0_1_prediction_pearsons_r: 1.9845 - output_0_1_prediction_SMAPE: 0.8795 - output_0_1_prediction_MBE: 0.0773 - output_0_1_prediction_R2: -0.0651 - output_1_1_prediction_mse: 0.0496 - output_1_1_prediction_pearsons_r: 2.7842 - output_1_1_prediction_SMAPE: 0.8871 - output_1_1_prediction_MBE: 0.0746 - output_1_1_prediction_R2: 0.4694 - output_2_1_prediction_mse: 0.0493 - output_2_1_prediction_pearsons_r: 1.8372 - output_2_1_prediction_SMAPE: 0.8813 - output_2_1_prediction_MBE: 0.0758 - output_2_1_prediction_R2: 0.3104 - output_3_1_prediction_mse: 0.0491 - output_3_1_prediction_pearsons_r: 2.0073 - output_3_1_prediction_SMAPE: 0.8782 - output_3_1_prediction_MBE: 0.0769 - output_3_1_prediction_R2: 0.2528 - output_4_1_prediction_mse: 0.0503 - output_4_1_prediction_pearsons_r: 0.7075 - output_4_1_prediction_SMAPE: 0.8899 - output_4_1_prediction_MBE: 0.0745 - output_4_1_prediction_R2: -0.0877 - output_5_1_prediction_mse: 0.0490 - output_5_1_prediction_pearsons_r: 2.7822 - output_5_1_prediction_SMAPE: 0.8773 - output_5_1_prediction_MBE: 0.0769 - output_5_1_prediction_R2: 0.2556 - output_6_1_prediction_mse: 0.0491 - output_6_1_prediction_pearsons_r: 1.9403 - output_6_1_prediction_SMAPE: 0.8786 - output_6_1_prediction_MBE: 0.0765 - output_6_1_prediction_R2: 0.1089 - output_7_1_prediction_mse: 0.0494 - output_7_1_prediction_pearsons_r: 0.7660 - output_7_1_prediction_SMAPE: 0.8844 - output_7_1_prediction_MBE: 0.0753 - output_7_1_prediction_R2: -0.1370 - val_loss: 1.2267 - val_output_0_1_prediction_loss: 0.1184 - val_output_0_2_quantile_05_loss: 0.0078 - val_output_0_3_quantile_95_loss: 0.0255 - val_output_1_1_prediction_loss: 0.1184 - val_output_1_2_quantile_05_loss: 0.0094 - val_output_1_3_quantile_95_loss: 0.0298 - val_output_2_1_prediction_loss: 0.1455 - val_output_2_2_quantile_05_loss: 0.0085 - val_output_2_3_quantile_95_loss: 0.0391 - val_output_3_1_prediction_loss: 0.1059 - val_output_3_2_quantile_05_loss: 0.0058 - val_output_3_3_quantile_95_loss: 0.0298 - val_output_4_1_prediction_loss: 0.1145 - val_output_4_2_quantile_05_loss: 0.0046 - val_output_4_3_quantile_95_loss: 0.0285 - val_output_5_1_prediction_loss: 0.1127 - val_output_5_2_quantile_05_loss: 0.0044 - val_output_5_3_quantile_95_loss: 0.0320 - val_output_6_1_prediction_loss: 0.1068 - val_output_6_2_quantile_05_loss: 0.0042 - val_output_6_3_quantile_95_loss: 0.0304 - val_output_7_1_prediction_loss: 0.1063 - val_output_7_2_quantile_05_loss: 0.0120 - val_output_7_3_quantile_95_loss: 0.0266 - val_output_0_1_prediction_mse: 0.0169 - val_output_0_1_prediction_pearsons_r: 0.0810 - val_output_0_1_prediction_SMAPE: 1.1067 - val_output_0_1_prediction_MBE: -0.0837 - val_output_0_1_prediction_R2: -0.0648 - val_output_1_1_prediction_mse: 0.0170 - val_output_1_1_prediction_pearsons_r: 0.1189 - val_output_1_1_prediction_SMAPE: 1.1068 - val_output_1_1_prediction_MBE: -0.0838 - val_output_1_1_prediction_R2: 0.8799 - val_output_2_1_prediction_mse: 0.0242 - val_output_2_1_prediction_pearsons_r: 0.0339 - val_output_2_1_prediction_SMAPE: 1.1748 - val_output_2_1_prediction_MBE: -0.1201 - val_output_2_1_prediction_R2: -3.3728 - val_output_3_1_prediction_mse: 0.0143 - val_output_3_1_prediction_pearsons_r: 0.0553 - val_output_3_1_prediction_SMAPE: 1.0689 - val_output_3_1_prediction_MBE: -0.0658 - val_output_3_1_prediction_R2: 0.8436 - val_output_4_1_prediction_mse: 0.0161 - val_output_4_1_prediction_pearsons_r: 0.0039 - val_output_4_1_prediction_SMAPE: 1.0954 - val_output_4_1_prediction_MBE: -0.0782 - val_output_4_1_prediction_R2: -0.0185 - val_output_5_1_prediction_mse: 0.0157 - val_output_5_1_prediction_pearsons_r: 0.0106 - val_output_5_1_prediction_SMAPE: 1.0901 - val_output_5_1_prediction_MBE: -0.0756 - val_output_5_1_prediction_R2: 0.8293 - val_output_6_1_prediction_mse: 0.0145 - val_output_6_1_prediction_pearsons_r: 0.0071 - val_output_6_1_prediction_SMAPE: 1.0718 - val_output_6_1_prediction_MBE: -0.0671 - val_output_6_1_prediction_R2: -0.5165 - val_output_7_1_prediction_mse: 0.0144 - val_output_7_1_prediction_pearsons_r: -0.0044 - val_output_7_1_prediction_SMAPE: 1.0703 - val_output_7_1_prediction_MBE: -0.0664 - val_output_7_1_prediction_R2: 0.4240 - lr: 1.8500e-04\n",
      "Epoch 16/2000\n",
      "52/52 [==============================] - 24s 464ms/step - loss: 1.6211 - output_0_1_prediction_loss: 0.1632 - output_0_2_quantile_05_loss: 0.0109 - output_0_3_quantile_95_loss: 0.0288 - output_1_1_prediction_loss: 0.1625 - output_1_2_quantile_05_loss: 0.0111 - output_1_3_quantile_95_loss: 0.0290 - output_2_1_prediction_loss: 0.1614 - output_2_2_quantile_05_loss: 0.0106 - output_2_3_quantile_95_loss: 0.0293 - output_3_1_prediction_loss: 0.1622 - output_3_2_quantile_05_loss: 0.0111 - output_3_3_quantile_95_loss: 0.0284 - output_4_1_prediction_loss: 0.1653 - output_4_2_quantile_05_loss: 0.0112 - output_4_3_quantile_95_loss: 0.0290 - output_5_1_prediction_loss: 0.1610 - output_5_2_quantile_05_loss: 0.0110 - output_5_3_quantile_95_loss: 0.0285 - output_6_1_prediction_loss: 0.1620 - output_6_2_quantile_05_loss: 0.0109 - output_6_3_quantile_95_loss: 0.0284 - output_7_1_prediction_loss: 0.1638 - output_7_2_quantile_05_loss: 0.0122 - output_7_3_quantile_95_loss: 0.0293 - output_0_1_prediction_mse: 0.0501 - output_0_1_prediction_pearsons_r: 1.1625 - output_0_1_prediction_SMAPE: 0.8893 - output_0_1_prediction_MBE: 0.0742 - output_0_1_prediction_R2: -0.0732 - output_1_1_prediction_mse: 0.0499 - output_1_1_prediction_pearsons_r: 2.7682 - output_1_1_prediction_SMAPE: 0.8865 - output_1_1_prediction_MBE: 0.0747 - output_1_1_prediction_R2: 0.4679 - output_2_1_prediction_mse: 0.0493 - output_2_1_prediction_pearsons_r: 0.4641 - output_2_1_prediction_SMAPE: 0.8794 - output_2_1_prediction_MBE: 0.0738 - output_2_1_prediction_R2: 0.3146 - output_3_1_prediction_mse: 0.0496 - output_3_1_prediction_pearsons_r: -0.0068 - output_3_1_prediction_SMAPE: 0.8836 - output_3_1_prediction_MBE: 0.0749 - output_3_1_prediction_R2: 0.2447 - output_4_1_prediction_mse: 0.0508 - output_4_1_prediction_pearsons_r: 0.3076 - output_4_1_prediction_SMAPE: 0.8997 - output_4_1_prediction_MBE: 0.0702 - output_4_1_prediction_R2: -0.0887 - output_5_1_prediction_mse: 0.0491 - output_5_1_prediction_pearsons_r: 2.8144 - output_5_1_prediction_SMAPE: 0.8783 - output_5_1_prediction_MBE: 0.0753 - output_5_1_prediction_R2: 0.2533 - output_6_1_prediction_mse: 0.0496 - output_6_1_prediction_pearsons_r: 0.4318 - output_6_1_prediction_SMAPE: 0.8827 - output_6_1_prediction_MBE: 0.0745 - output_6_1_prediction_R2: 0.1073 - output_7_1_prediction_mse: 0.0506 - output_7_1_prediction_pearsons_r: 0.4739 - output_7_1_prediction_SMAPE: 0.8938 - output_7_1_prediction_MBE: 0.0755 - output_7_1_prediction_R2: -0.1623 - val_loss: 1.1980 - val_output_0_1_prediction_loss: 0.1102 - val_output_0_2_quantile_05_loss: 0.0041 - val_output_0_3_quantile_95_loss: 0.0280 - val_output_1_1_prediction_loss: 0.1137 - val_output_1_2_quantile_05_loss: 0.0115 - val_output_1_3_quantile_95_loss: 0.0313 - val_output_2_1_prediction_loss: 0.1081 - val_output_2_2_quantile_05_loss: 0.0052 - val_output_2_3_quantile_95_loss: 0.0298 - val_output_3_1_prediction_loss: 0.0994 - val_output_3_2_quantile_05_loss: 0.0057 - val_output_3_3_quantile_95_loss: 0.0269 - val_output_4_1_prediction_loss: 0.1503 - val_output_4_2_quantile_05_loss: 0.0217 - val_output_4_3_quantile_95_loss: 0.0330 - val_output_5_1_prediction_loss: 0.1006 - val_output_5_2_quantile_05_loss: 0.0083 - val_output_5_3_quantile_95_loss: 0.0266 - val_output_6_1_prediction_loss: 0.1003 - val_output_6_2_quantile_05_loss: 0.0043 - val_output_6_3_quantile_95_loss: 0.0263 - val_output_7_1_prediction_loss: 0.1143 - val_output_7_2_quantile_05_loss: 0.0047 - val_output_7_3_quantile_95_loss: 0.0336 - val_output_0_1_prediction_mse: 0.0152 - val_output_0_1_prediction_pearsons_r: -0.0078 - val_output_0_1_prediction_SMAPE: 1.0825 - val_output_0_1_prediction_MBE: -0.0720 - val_output_0_1_prediction_R2: 0.0507 - val_output_1_1_prediction_mse: 0.0159 - val_output_1_1_prediction_pearsons_r: 0.2010 - val_output_1_1_prediction_SMAPE: 1.0932 - val_output_1_1_prediction_MBE: -0.0771 - val_output_1_1_prediction_R2: 0.8873 - val_output_2_1_prediction_mse: 0.0147 - val_output_2_1_prediction_pearsons_r: 0.0482 - val_output_2_1_prediction_SMAPE: 1.0761 - val_output_2_1_prediction_MBE: -0.0691 - val_output_2_1_prediction_R2: -1.3753 - val_output_3_1_prediction_mse: 0.0132 - val_output_3_1_prediction_pearsons_r: 0.0520 - val_output_3_1_prediction_SMAPE: 1.0471 - val_output_3_1_prediction_MBE: -0.0561 - val_output_3_1_prediction_R2: 0.8558 - val_output_4_1_prediction_mse: 0.0257 - val_output_4_1_prediction_pearsons_r: -0.0639 - val_output_4_1_prediction_SMAPE: 1.1857 - val_output_4_1_prediction_MBE: -0.1262 - val_output_4_1_prediction_R2: -0.6453 - val_output_5_1_prediction_mse: 0.0134 - val_output_5_1_prediction_pearsons_r: 0.1673 - val_output_5_1_prediction_SMAPE: 1.0511 - val_output_5_1_prediction_MBE: -0.0579 - val_output_5_1_prediction_R2: 0.8540 - val_output_6_1_prediction_mse: 0.0133 - val_output_6_1_prediction_pearsons_r: -0.0165 - val_output_6_1_prediction_SMAPE: 1.0502 - val_output_6_1_prediction_MBE: -0.0574 - val_output_6_1_prediction_R2: -0.3674 - val_output_7_1_prediction_mse: 0.0160 - val_output_7_1_prediction_pearsons_r: 0.0785 - val_output_7_1_prediction_SMAPE: 1.0949 - val_output_7_1_prediction_MBE: -0.0779 - val_output_7_1_prediction_R2: 0.3597 - lr: 1.8500e-04\n",
      "Epoch 17/2000\n",
      "52/52 [==============================] - 23s 453ms/step - loss: 1.6250 - output_0_1_prediction_loss: 0.1618 - output_0_2_quantile_05_loss: 0.0106 - output_0_3_quantile_95_loss: 0.0297 - output_1_1_prediction_loss: 0.1627 - output_1_2_quantile_05_loss: 0.0115 - output_1_3_quantile_95_loss: 0.0298 - output_2_1_prediction_loss: 0.1614 - output_2_2_quantile_05_loss: 0.0106 - output_2_3_quantile_95_loss: 0.0324 - output_3_1_prediction_loss: 0.1623 - output_3_2_quantile_05_loss: 0.0109 - output_3_3_quantile_95_loss: 0.0292 - output_4_1_prediction_loss: 0.1639 - output_4_2_quantile_05_loss: 0.0121 - output_4_3_quantile_95_loss: 0.0291 - output_5_1_prediction_loss: 0.1617 - output_5_2_quantile_05_loss: 0.0110 - output_5_3_quantile_95_loss: 0.0289 - output_6_1_prediction_loss: 0.1621 - output_6_2_quantile_05_loss: 0.0108 - output_6_3_quantile_95_loss: 0.0287 - output_7_1_prediction_loss: 0.1633 - output_7_2_quantile_05_loss: 0.0113 - output_7_3_quantile_95_loss: 0.0291 - output_0_1_prediction_mse: 0.0498 - output_0_1_prediction_pearsons_r: 1.5688 - output_0_1_prediction_SMAPE: 0.8830 - output_0_1_prediction_MBE: 0.0760 - output_0_1_prediction_R2: -0.0728 - output_1_1_prediction_mse: 0.0499 - output_1_1_prediction_pearsons_r: 2.8275 - output_1_1_prediction_SMAPE: 0.8858 - output_1_1_prediction_MBE: 0.0732 - output_1_1_prediction_R2: 0.4708 - output_2_1_prediction_mse: 0.0498 - output_2_1_prediction_pearsons_r: 1.7399 - output_2_1_prediction_SMAPE: 0.8826 - output_2_1_prediction_MBE: 0.0775 - output_2_1_prediction_R2: 0.3091 - output_3_1_prediction_mse: 0.0498 - output_3_1_prediction_pearsons_r: 0.3315 - output_3_1_prediction_SMAPE: 0.8840 - output_3_1_prediction_MBE: 0.0742 - output_3_1_prediction_R2: 0.2521 - output_4_1_prediction_mse: 0.0494 - output_4_1_prediction_pearsons_r: 1.4923 - output_4_1_prediction_SMAPE: 0.8893 - output_4_1_prediction_MBE: 0.0670 - output_4_1_prediction_R2: -0.0713 - output_5_1_prediction_mse: 0.0496 - output_5_1_prediction_pearsons_r: 2.8117 - output_5_1_prediction_SMAPE: 0.8816 - output_5_1_prediction_MBE: 0.0745 - output_5_1_prediction_R2: 0.2553 - output_6_1_prediction_mse: 0.0497 - output_6_1_prediction_pearsons_r: 1.3875 - output_6_1_prediction_SMAPE: 0.8829 - output_6_1_prediction_MBE: 0.0741 - output_6_1_prediction_R2: 0.1021 - output_7_1_prediction_mse: 0.0499 - output_7_1_prediction_pearsons_r: -0.6892 - output_7_1_prediction_SMAPE: 0.8880 - output_7_1_prediction_MBE: 0.0710 - output_7_1_prediction_R2: -0.1431 - val_loss: 1.2946 - val_output_0_1_prediction_loss: 0.1139 - val_output_0_2_quantile_05_loss: 0.0042 - val_output_0_3_quantile_95_loss: 0.0311 - val_output_1_1_prediction_loss: 0.1436 - val_output_1_2_quantile_05_loss: 0.0178 - val_output_1_3_quantile_95_loss: 0.0331 - val_output_2_1_prediction_loss: 0.1278 - val_output_2_2_quantile_05_loss: 0.0050 - val_output_2_3_quantile_95_loss: 0.0178 - val_output_3_1_prediction_loss: 0.1177 - val_output_3_2_quantile_05_loss: 0.0065 - val_output_3_3_quantile_95_loss: 0.0308 - val_output_4_1_prediction_loss: 0.0941 - val_output_4_2_quantile_05_loss: 0.0071 - val_output_4_3_quantile_95_loss: 0.0223 - val_output_5_1_prediction_loss: 0.1327 - val_output_5_2_quantile_05_loss: 0.0080 - val_output_5_3_quantile_95_loss: 0.0328 - val_output_6_1_prediction_loss: 0.1322 - val_output_6_2_quantile_05_loss: 0.0043 - val_output_6_3_quantile_95_loss: 0.0301 - val_output_7_1_prediction_loss: 0.1471 - val_output_7_2_quantile_05_loss: 0.0063 - val_output_7_3_quantile_95_loss: 0.0283 - val_output_0_1_prediction_mse: 0.0159 - val_output_0_1_prediction_pearsons_r: 0.0402 - val_output_0_1_prediction_SMAPE: 1.0937 - val_output_0_1_prediction_MBE: -0.0773 - val_output_0_1_prediction_R2: 3.3776e-04 - val_output_1_1_prediction_mse: 0.0237 - val_output_1_1_prediction_pearsons_r: 0.0824 - val_output_1_1_prediction_SMAPE: 1.1706 - val_output_1_1_prediction_MBE: -0.1177 - val_output_1_1_prediction_R2: 0.8328 - val_output_2_1_prediction_mse: 0.0193 - val_output_2_1_prediction_pearsons_r: -0.1464 - val_output_2_1_prediction_SMAPE: 1.1320 - val_output_2_1_prediction_MBE: -0.0968 - val_output_2_1_prediction_R2: -2.3570 - val_output_3_1_prediction_mse: 0.0168 - val_output_3_1_prediction_pearsons_r: 0.0406 - val_output_3_1_prediction_SMAPE: 1.1047 - val_output_3_1_prediction_MBE: -0.0828 - val_output_3_1_prediction_R2: 0.8172 - val_output_4_1_prediction_mse: 0.0123 - val_output_4_1_prediction_pearsons_r: 0.0400 - val_output_4_1_prediction_SMAPE: 1.0281 - val_output_4_1_prediction_MBE: -0.0475 - val_output_4_1_prediction_R2: 0.2290 - val_output_5_1_prediction_mse: 0.0206 - val_output_5_1_prediction_pearsons_r: 0.0410 - val_output_5_1_prediction_SMAPE: 1.1445 - val_output_5_1_prediction_MBE: -0.1035 - val_output_5_1_prediction_R2: 0.7768 - val_output_6_1_prediction_mse: 0.0205 - val_output_6_1_prediction_pearsons_r: -0.1013 - val_output_6_1_prediction_SMAPE: 1.1433 - val_output_6_1_prediction_MBE: -0.1029 - val_output_6_1_prediction_R2: -1.2416 - val_output_7_1_prediction_mse: 0.0247 - val_output_7_1_prediction_pearsons_r: -0.0040 - val_output_7_1_prediction_SMAPE: 1.1787 - val_output_7_1_prediction_MBE: -0.1222 - val_output_7_1_prediction_R2: 0.0134 - lr: 1.8500e-04\n",
      "Epoch 18/2000\n",
      "52/52 [==============================] - 24s 465ms/step - loss: 1.9952 - output_0_1_prediction_loss: 0.1638 - output_0_2_quantile_05_loss: 0.0112 - output_0_3_quantile_95_loss: 0.0293 - output_1_1_prediction_loss: 0.1758 - output_1_2_quantile_05_loss: 0.0113 - output_1_3_quantile_95_loss: 0.0304 - output_2_1_prediction_loss: 0.1628 - output_2_2_quantile_05_loss: 0.0106 - output_2_3_quantile_95_loss: 0.0336 - output_3_1_prediction_loss: 0.1632 - output_3_2_quantile_05_loss: 0.0107 - output_3_3_quantile_95_loss: 0.0292 - output_4_1_prediction_loss: 0.1691 - output_4_2_quantile_05_loss: 0.0135 - output_4_3_quantile_95_loss: 0.0307 - output_5_1_prediction_loss: 0.1625 - output_5_2_quantile_05_loss: 0.0113 - output_5_3_quantile_95_loss: 0.0289 - output_6_1_prediction_loss: 0.1640 - output_6_2_quantile_05_loss: 0.0112 - output_6_3_quantile_95_loss: 0.0291 - output_7_1_prediction_loss: 0.3977 - output_7_2_quantile_05_loss: 0.1125 - output_7_3_quantile_95_loss: 0.0328 - output_0_1_prediction_mse: 0.0505 - output_0_1_prediction_pearsons_r: 0.6299 - output_0_1_prediction_SMAPE: 0.8923 - output_0_1_prediction_MBE: 0.0762 - output_0_1_prediction_R2: -0.0890 - output_1_1_prediction_mse: 0.0568 - output_1_1_prediction_pearsons_r: 2.4528 - output_1_1_prediction_SMAPE: 0.9503 - output_1_1_prediction_MBE: 0.0698 - output_1_1_prediction_R2: 0.3934 - output_2_1_prediction_mse: 0.0499 - output_2_1_prediction_pearsons_r: 1.1652 - output_2_1_prediction_SMAPE: 0.8875 - output_2_1_prediction_MBE: 0.0751 - output_2_1_prediction_R2: 0.3073 - output_3_1_prediction_mse: 0.0501 - output_3_1_prediction_pearsons_r: 2.0972 - output_3_1_prediction_SMAPE: 0.8888 - output_3_1_prediction_MBE: 0.0749 - output_3_1_prediction_R2: 0.2430 - output_4_1_prediction_mse: 0.0531 - output_4_1_prediction_pearsons_r: 1.9508 - output_4_1_prediction_SMAPE: 0.9173 - output_4_1_prediction_MBE: 0.0700 - output_4_1_prediction_R2: -0.1472 - output_5_1_prediction_mse: 0.0499 - output_5_1_prediction_pearsons_r: 2.2498 - output_5_1_prediction_SMAPE: 0.8864 - output_5_1_prediction_MBE: 0.0757 - output_5_1_prediction_R2: 0.2481 - output_6_1_prediction_mse: 0.0506 - output_6_1_prediction_pearsons_r: 1.2729 - output_6_1_prediction_SMAPE: 0.8936 - output_6_1_prediction_MBE: 0.0763 - output_6_1_prediction_R2: 0.0873 - output_7_1_prediction_mse: 0.9947 - output_7_1_prediction_pearsons_r: 1.3934 - output_7_1_prediction_SMAPE: 1.0647 - output_7_1_prediction_MBE: -0.0883 - output_7_1_prediction_R2: -27.1062 - val_loss: 2.6539 - val_output_0_1_prediction_loss: 0.0682 - val_output_0_2_quantile_05_loss: 0.0065 - val_output_0_3_quantile_95_loss: 0.0210 - val_output_1_1_prediction_loss: 0.0854 - val_output_1_2_quantile_05_loss: 0.0061 - val_output_1_3_quantile_95_loss: 0.0168 - val_output_2_1_prediction_loss: 0.0695 - val_output_2_2_quantile_05_loss: 0.0042 - val_output_2_3_quantile_95_loss: 0.0340 - val_output_3_1_prediction_loss: 0.0743 - val_output_3_2_quantile_05_loss: 0.0055 - val_output_3_3_quantile_95_loss: 0.0226 - val_output_4_1_prediction_loss: 0.0985 - val_output_4_2_quantile_05_loss: 0.0051 - val_output_4_3_quantile_95_loss: 0.0177 - val_output_5_1_prediction_loss: 0.0693 - val_output_5_2_quantile_05_loss: 0.0076 - val_output_5_3_quantile_95_loss: 0.0247 - val_output_6_1_prediction_loss: 0.0678 - val_output_6_2_quantile_05_loss: 0.0100 - val_output_6_3_quantile_95_loss: 0.0248 - val_output_7_1_prediction_loss: 1.4475 - val_output_7_2_quantile_05_loss: 0.4436 - val_output_7_3_quantile_95_loss: 0.0231 - val_output_0_1_prediction_mse: 0.0126 - val_output_0_1_prediction_pearsons_r: -0.0908 - val_output_0_1_prediction_SMAPE: 0.9780 - val_output_0_1_prediction_MBE: 0.0472 - val_output_0_1_prediction_R2: 0.2400 - val_output_1_1_prediction_mse: 0.0111 - val_output_1_1_prediction_pearsons_r: -0.2709 - val_output_1_1_prediction_SMAPE: 0.9951 - val_output_1_1_prediction_MBE: -0.0324 - val_output_1_1_prediction_R2: 0.9202 - val_output_2_1_prediction_mse: 0.0106 - val_output_2_1_prediction_pearsons_r: -0.0984 - val_output_2_1_prediction_SMAPE: 0.9541 - val_output_2_1_prediction_MBE: 0.0175 - val_output_2_1_prediction_R2: 0.0199 - val_output_3_1_prediction_mse: 0.0152 - val_output_3_1_prediction_pearsons_r: 0.1680 - val_output_3_1_prediction_SMAPE: 1.1385 - val_output_3_1_prediction_MBE: 0.0691 - val_output_3_1_prediction_R2: 0.8289 - val_output_4_1_prediction_mse: 0.0130 - val_output_4_1_prediction_pearsons_r: 0.2287 - val_output_4_1_prediction_SMAPE: 1.0437 - val_output_4_1_prediction_MBE: -0.0545 - val_output_4_1_prediction_R2: 0.1827 - val_output_5_1_prediction_mse: 0.0106 - val_output_5_1_prediction_pearsons_r: -0.1023 - val_output_5_1_prediction_SMAPE: 0.9552 - val_output_5_1_prediction_MBE: 0.0191 - val_output_5_1_prediction_R2: 0.8808 - val_output_6_1_prediction_mse: 0.0118 - val_output_6_1_prediction_pearsons_r: 0.0605 - val_output_6_1_prediction_SMAPE: 0.9642 - val_output_6_1_prediction_MBE: 0.0384 - val_output_6_1_prediction_R2: 0.0217 - val_output_7_1_prediction_mse: 2.1054 - val_output_7_1_prediction_pearsons_r: 0.0151 - val_output_7_1_prediction_SMAPE: 1.8056 - val_output_7_1_prediction_MBE: -1.4490 - val_output_7_1_prediction_R2: -83.3326 - lr: 1.8500e-04\n",
      "Epoch 19/2000\n",
      " 5/52 [=>............................] - ETA: 22s - loss: 11.1580 - output_0_1_prediction_loss: 0.1886 - output_0_2_quantile_05_loss: 0.0139 - output_0_3_quantile_95_loss: 0.0281 - output_1_1_prediction_loss: 0.2305 - output_1_2_quantile_05_loss: 0.0135 - output_1_3_quantile_95_loss: 0.0364 - output_2_1_prediction_loss: 0.1834 - output_2_2_quantile_05_loss: 0.0119 - output_2_3_quantile_95_loss: 0.0259 - output_3_1_prediction_loss: 0.1915 - output_3_2_quantile_05_loss: 0.0121 - output_3_3_quantile_95_loss: 0.0277 - output_4_1_prediction_loss: 0.1831 - output_4_2_quantile_05_loss: 0.0151 - output_4_3_quantile_95_loss: 0.0327 - output_5_1_prediction_loss: 0.1916 - output_5_2_quantile_05_loss: 0.0138 - output_5_3_quantile_95_loss: 0.0277 - output_6_1_prediction_loss: 0.1920 - output_6_2_quantile_05_loss: 0.0132 - output_6_3_quantile_95_loss: 0.0270 - output_7_1_prediction_loss: 8.7988 - output_7_2_quantile_05_loss: 0.3848 - output_7_3_quantile_95_loss: 0.3148 - output_0_1_prediction_mse: 0.0603 - output_0_1_prediction_pearsons_r: -1.0139 - output_0_1_prediction_SMAPE: 0.9668 - output_0_1_prediction_MBE: 0.0833 - output_0_1_prediction_R2: -0.1436 - output_1_1_prediction_mse: 0.0802 - output_1_1_prediction_pearsons_r: -0.1933 - output_1_1_prediction_SMAPE: 1.1474 - output_1_1_prediction_MBE: 0.0295 - output_1_1_prediction_R2: 0.1033 - output_2_1_prediction_mse: 0.0590 - output_2_1_prediction_pearsons_r: -2.8078 - output_2_1_prediction_SMAPE: 0.9408 - output_2_1_prediction_MBE: 0.0964 - output_2_1_prediction_R2: 0.2919 - output_3_1_prediction_mse: 0.0650 - output_3_1_prediction_pearsons_r: 2.0827 - output_3_1_prediction_SMAPE: 1.0257 - output_3_1_prediction_MBE: 0.1072 - output_3_1_prediction_R2: -0.0666 - output_4_1_prediction_mse: 0.0524 - output_4_1_prediction_pearsons_r: 2.3151 - output_4_1_prediction_SMAPE: 0.8993 - output_4_1_prediction_MBE: 0.0481 - output_4_1_prediction_R2: -0.0288 - output_5_1_prediction_mse: 0.0687 - output_5_1_prediction_pearsons_r: -1.7522 - output_5_1_prediction_SMAPE: 1.0222 - output_5_1_prediction_MBE: 0.1398 - output_5_1_prediction_R2: -0.1508 - output_6_1_prediction_mse: 0.0618 - output_6_1_prediction_pearsons_r: -1.8006 - output_6_1_prediction_SMAPE: 0.9779 - output_6_1_prediction_MBE: 0.0823 - output_6_1_prediction_R2: 0.0393 - output_7_1_prediction_mse: 99.0561 - output_7_1_prediction_pearsons_r: -0.7127 - output_7_1_prediction_SMAPE: 1.8611 - output_7_1_prediction_MBE: -1.8846 - output_7_1_prediction_R2: -2469.3354"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "\n",
    "# Set the local directory path\n",
    "local_dir = \"./\"\n",
    "\n",
    "n_folds = 10\n",
    "\n",
    "def get_train_test_data(input_data, target_data, fold, n_folds):\n",
    "    fold_size = len(input_data) // n_folds\n",
    "    test_start = fold * fold_size\n",
    "    test_end = (fold + 1) * fold_size\n",
    "\n",
    "    train_input = np.concatenate((input_data[:test_start], input_data[test_end:]))\n",
    "    test_input = input_data[test_start:test_end]\n",
    "\n",
    "    train_target = np.concatenate((target_data[:test_start], target_data[test_end:]))\n",
    "    test_target = target_data[test_start:test_end]\n",
    "\n",
    "    return train_input, test_input, train_target, test_target\n",
    "\n",
    "# Loop through each fold\n",
    "\n",
    "for trial in range(3):  # Train 3 models for each fold\n",
    "    for fold in range(n_folds):\n",
    "        input_data, target_data, btc_scalers, target_scalers, means = prepare_data(PATH)\n",
    "\n",
    "        # Prepare data\n",
    "        train_input, test_input, train_target, test_target = get_train_test_data(input_data, target_data, fold, n_folds)\n",
    "        print(f\"Train Input shape: {train_input.shape} Test Input shape: {test_input.shape}\")\n",
    "        print(f\"Train Target shape: {train_target.shape} Test Target shape: {test_target.shape}\")\n",
    "        # Build and train model\n",
    "        os.makedirs(\"./tmp\", exist_ok=True)\n",
    "        os.makedirs(\"./tmp/backup\", exist_ok=True)\n",
    "        os.makedirs(\"./tmp/checkpoint\", exist_ok=True)\n",
    "        model = build_model()\n",
    "        history = model.fit(\n",
    "            train_input,\n",
    "            train_target,\n",
    "            validation_data=(test_input, test_target),\n",
    "            epochs=2000,\n",
    "            callbacks=[\n",
    "                EarlyStopping(monitor=\"val_loss\", patience=100, restore_best_weights=True, verbose=1),\n",
    "                ReduceLROnPlateau(monitor=\"val_loss\", patience=25),\n",
    "                ModelCheckpoint(os.path.join(local_dir, f\"tmp/checkpoint/model_checkpoint_fold_{fold}_trial_{trial}_epoch_{{epoch}}.hdf5\"), save_freq=5),\n",
    "                TensorBoard(log_dir=os.path.join(local_dir, f\"logs/fold_{fold}_trial_{trial}\")),\n",
    "                BackupAndRestore(os.path.join(local_dir, f\"tmp/backup/fold_{fold}_trial_{trial}\"))\n",
    "            ],\n",
    "        )\n",
    "        \n",
    "        # Save model and history\n",
    "        os.makedirs(os.path.join(local_dir, f\"train/models/fold_{fold}\"), exist_ok=True)\n",
    "        model.save(os.path.join(local_dir, f\"train/models/fold_{fold}/model_trial_{trial}.hdf5\"))\n",
    "\n",
    "        history_dict = history.history\n",
    "        os.makedirs(os.path.join(local_dir, f\"train/history/fold_{fold}\"), exist_ok=True)\n",
    "        with open(os.path.join(local_dir, f\"train/history/fold_{fold}/history_trial_{trial}.pkl\"), \"wb\") as pickle_file:\n",
    "            pickle.dump(history_dict, pickle_file)\n",
    "\n",
    "        # Extract plot data\n",
    "        plot_data = extract_plot_data(model, input_data, target_data, target_scalers)  # Assuming target_scalers is defined\n",
    "\n",
    "        # Save plot data\n",
    "        os.makedirs(os.path.join(local_dir, f\"train/predictions/fold_{fold}\"), exist_ok=True)\n",
    "        with open(os.path.join(local_dir, f\"train/predictions/fold_{fold}/plot_data_trial_{trial}.json\"), \"w\") as json_file:\n",
    "            json.dump(plot_data, json_file)\n",
    "\n",
    "        # Remove temporary files\n",
    "        os.system(f\"rm -r ./tmp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNOOHeCNmMOziJfBfI641Ea",
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
