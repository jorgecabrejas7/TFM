{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0766c45-dec1-447a-969b-9ed2123d3f24",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Transformer model tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca21bfb-8f65-41ea-82b7-59254030468b",
   "metadata": {},
   "source": [
    "## Index\n",
    "* [Data Preparation](#Title)\n",
    "* [Second Bullet Header](#second-bullet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a216dac-edd0-43a4-b316-578c2d4c2386",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 19:18:36.685545: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-11 19:18:36.712116: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-11 19:18:37.131873: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import (\n",
    "    BatchNormalization,\n",
    "    Concatenate,\n",
    "    Conv1D,\n",
    "    ConvLSTM1D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    Layer,\n",
    "    LayerNormalization,\n",
    "    MaxPooling1D,\n",
    "    MultiHeadAttention,\n",
    ")\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.utils import Sequence\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "from keras_tuner.tuners import Hyperband, RandomSearch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from metrics import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "\n",
    "PATH = \"./data\"\n",
    "SYMBOLS = [\"ADA\", \"BNB\", \"BTC\", \"EOS\", \"ETH\", \"LTC\", \"TRX\", \"VET\", \"XRP\"]\n",
    "\n",
    "\n",
    "def to_csvf(x):\n",
    "    return x + \"USDT.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45d73d80-73b6-47ea-8187-063160c5227d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_file(symbol: str, tf: str, timestamp_unit: str = \"ms\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a CSV file, assigns column names, converts the 'date' column to datetime,\n",
    "    and sets it as the DataFrame's index.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    symbol : str\n",
    "        The symbol.\n",
    "    tf : str\n",
    "        The tf.\n",
    "    timestamp_unit : str, default 'ms'\n",
    "        The unit of the timestamp in the 'date' column. By default, it's 'ms' (milliseconds).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The DataFrame with the 'date' column converted to datetime and set as the index.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(to_csvf(os.path.join(PATH, tf, symbol)), header=None).iloc[:, 0:6]\n",
    "    df.columns = [\"date\", \"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], unit=timestamp_unit)\n",
    "    df.set_index(\"date\", inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29397b07-8a16-4711-9814-8c6fa4da38f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "PATH = \"./data\"\n",
    "SYMBOLS = [\"ADA\", \"BNB\", \"BTC\", \"EOS\", \"ETH\", \"LTC\", \"TRX\", \"VET\", \"XRP\"]\n",
    "\n",
    "\n",
    "def read_file(symbol: str, tf: str, timestamp_unit: str = \"ms\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a CSV file, assigns column names, converts the 'date' column to datetime,\n",
    "    and sets it as the DataFrame's index.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    symbol : str\n",
    "        The symbol.\n",
    "    tf : str\n",
    "        The tf.\n",
    "    timestamp_unit : str, default 'ms'\n",
    "        The unit of the timestamp in the 'date' column. By default, it's 'ms' (milliseconds).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The DataFrame with the 'date' column converted to datetime and set as the index.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(to_csvf(os.path.join(PATH, tf, symbol)), header=None).iloc[:, 0:6]\n",
    "    df.columns = [\"date\", \"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], unit=timestamp_unit)\n",
    "    df.set_index(\"date\", inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_input_tensor(data, lookback=250 * 24):\n",
    "    inputs = []\n",
    "    for i in range(0, len(data) - lookback, 24):\n",
    "        inputs.append(data.iloc[i : i + lookback].values)\n",
    "        # print(data.iloc[i+lookback])\n",
    "\n",
    "    return np.array(inputs)\n",
    "\n",
    "\n",
    "def create_target_tensor(data_dict):\n",
    "    # Step 1: Create a dataframe with closing prices for each currency\n",
    "    close_prices_df = pd.DataFrame(\n",
    "        {symbol: df[\"close\"] for symbol, df in data_dict.items()}\n",
    "    ).dropna()\n",
    "    # Step 2: Repeat each value three times\n",
    "    # print(close_prices_df)\n",
    "    target_array = np.array(\n",
    "        close_prices_df.apply(\n",
    "            lambda x: np.array([item for item in x for _ in range(3)]), axis=1\n",
    "        ).values\n",
    "    )\n",
    "\n",
    "    return np.vstack(target_array)\n",
    "\n",
    "\n",
    "def prepare_data(PATH):\n",
    "    # 1. Read BTC hourly data\n",
    "    btc_data = read_file(\"BTC\", \"1h\")\n",
    "    # Create a new index to fill missing values\n",
    "    full_index = pd.date_range(btc_data.index.min(), btc_data.index.max(), freq=\"H\")\n",
    "    df_full = pd.DataFrame(index=full_index)\n",
    "    # Create the new dataframe forwarding missing values\n",
    "    btc_data = df_full.merge(\n",
    "        btc_data, left_index=True, right_index=True, how=\"left\"\n",
    "    ).fillna(method=\"ffill\")\n",
    "    # 2. Read other currencies' daily data\n",
    "    daily_data = {}\n",
    "    for symbol in SYMBOLS:\n",
    "        if symbol != \"BTC\":\n",
    "            daily_data[symbol] = read_file(f\"{symbol}\", \"1d\")\n",
    "\n",
    "    # 3. Find overlapping date range\n",
    "    min_date = btc_data.index.min()\n",
    "    max_date = btc_data.index.max()\n",
    "    for df in daily_data.values():\n",
    "        min_date = max(min_date, df.index.min())\n",
    "        max_date = min(max_date, df.index.max())\n",
    "\n",
    "    # 4. Prune each dataset to the overlapping range\n",
    "    btc_data = btc_data.loc[\n",
    "        min_date - pd.Timedelta(days=250, hours=1) : max_date - pd.Timedelta(hours=1)\n",
    "    ]\n",
    "    for symbol in daily_data:\n",
    "        daily_data[symbol] = daily_data[symbol].loc[min_date:max_date]\n",
    "    # 5. Scale the BTC data and each feature separately\n",
    "    scalers_btc = {}\n",
    "    for col in btc_data.columns:\n",
    "        scaler = MinMaxScaler()\n",
    "        btc_data[col] = scaler.fit_transform(btc_data[col].values.reshape(-1, 1))\n",
    "        scalers_btc[col] = scaler\n",
    "\n",
    "    # Create input tensor from scaled BTC hourly data\n",
    "\n",
    "    input_tensor = create_input_tensor(btc_data)\n",
    "    # 6. Scale target data (Close Price) for each currency\n",
    "    scalers_targets = {}\n",
    "    scaled_targets = {}\n",
    "    for symbol, df in daily_data.items():\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled_data = scaler.fit_transform(df[\"close\"].values.reshape(-1, 1))\n",
    "        scaled_targets[symbol] = pd.DataFrame(\n",
    "            scaled_data, columns=[\"close\"], index=df.index\n",
    "        )  # Save the scaled data as dataframe\n",
    "        scalers_targets[symbol] = scaler\n",
    "    # Create target tensor using scaled data\n",
    "    target_tensors = create_target_tensor(scaled_targets)\n",
    "\n",
    "    return input_tensor, target_tensors, scalers_btc, scalers_targets\n",
    "\n",
    "\n",
    "# Use the function\n",
    "input_data, target_data, btc_scalers, target_scalers = prepare_data(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d087ba3-0070-43f4-9b00-3ab4088ac915",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((294, 6000, 5), (74, 6000, 5), (294, 24), (74, 24))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the index for an 80-20 split\n",
    "index_80_percent = int(0.8 * len(input_data))\n",
    "\n",
    "hyperparam_input = input_data[index_80_percent:]\n",
    "hyperparam_target = target_data[index_80_percent:]\n",
    "\n",
    "# 2. Splitting the 20% further into training and validation\n",
    "\n",
    "# Finding the index for an 80-20 split within the hyperparameter data\n",
    "index_hyperparam_80_percent = int(0.8 * len(hyperparam_input))\n",
    "\n",
    "# Splitting the data\n",
    "train_input = hyperparam_input[:index_hyperparam_80_percent]\n",
    "train_target = hyperparam_target[:index_hyperparam_80_percent]\n",
    "\n",
    "valid_input = hyperparam_input[index_hyperparam_80_percent:]\n",
    "valid_target = hyperparam_target[index_hyperparam_80_percent:]\n",
    "\n",
    "train_input.shape, valid_input.shape, train_target.shape, valid_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe90523f-f831-4d4c-9442-22cc2d864dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Time2Vec(Layer):\n",
    "    def __init__(self, output_dim=None, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(Time2Vec, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(\n",
    "            name=\"W\",\n",
    "            shape=(input_shape[-1], self.output_dim),\n",
    "            initializer=\"uniform\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.P = self.add_weight(\n",
    "            name=\"P\",\n",
    "            shape=(input_shape[1], self.output_dim),\n",
    "            initializer=\"uniform\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.w = self.add_weight(\n",
    "            name=\"w\", shape=(input_shape[1], 1), initializer=\"uniform\", trainable=True\n",
    "        )\n",
    "        self.p = self.add_weight(\n",
    "            name=\"p\", shape=(input_shape[1], 1), initializer=\"uniform\", trainable=True\n",
    "        )\n",
    "        super(Time2Vec, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        original = self.w * x + self.p\n",
    "        sin_trans = K.sin(K.dot(x, self.W) + self.P)\n",
    "\n",
    "        return K.concatenate([sin_trans, original], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f16772f-567f-4231-80e6-4f40b266bd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 19:18:38.048570: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-11 19:18:38.064070: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-11 19:18:38.064188: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-11 19:18:38.065214: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysf"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from random_search/TimeSeries/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s-bus-pci#L344-L355\n",
      "2023-08-11 19:18:38.065308: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-11 19:18:38.065357: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-11 19:18:38.120209: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-11 19:18:38.120336: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-11 19:18:38.120394: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-11 19:18:38.120445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21666 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "conv              |conv              |decoder_layer_type\n",
      "2                 |2                 |num_transformer_layers\n",
      "1                 |1                 |num_attention_heads\n",
      "0.15              |0.15              |dropout_rate\n",
      "64                |64                |kernel_size\n",
      "2                 |2                 |conv_layers\n",
      "Adam              |Adam              |optimizer\n",
      "1.0468e-05        |1.0468e-05        |learning_rate\n",
      "\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 19:18:38.895432: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [294,6000,5]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-08-11 19:18:38.895590: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_8' with dtype double and shape [294,24]\n",
      "\t [[{{node Placeholder/_8}}]]\n",
      "2023-08-11 19:18:41.012571: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-08-11 19:18:51.045514: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.37GiB (rounded to 5764800000)requested by op model/time2_vec/concat\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-08-11 19:18:51.045539: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2023-08-11 19:18:51.045544: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 220, Chunks in use: 220. 55.0KiB allocated for chunks. 55.0KiB in use in bin. 6.8KiB client-requested in use in bin.\n",
      "2023-08-11 19:18:51.045546: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 9, Chunks in use: 8. 4.8KiB allocated for chunks. 4.0KiB in use in bin. 4.0KiB client-requested in use in bin.\n",
      "2023-08-11 19:18:51.045549: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2023-08-11 19:18:51.045551: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 1, Chunks in use: 1. 3.8KiB allocated for chunks. 3.8KiB in use in bin. 3.8KiB client-requested in use in bin.\n",
      "2023-08-11 19:18:51.045553: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-08-11 19:18:51.045556: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 1, Chunks in use: 1. 14.0KiB allocated for chunks. 14.0KiB in use in bin. 13.9KiB client-requested in use in bin.\n",
      "2023-08-11 19:18:51.045558: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 25, Chunks in use: 25. 587.5KiB allocated for chunks. 587.5KiB in use in bin. 586.2KiB client-requested in use in bin.\n",
      "2023-08-11 19:18:51.045561: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 2, Chunks in use: 2. 101.0KiB allocated for chunks. 101.0KiB in use in bin. 78.6KiB client-requested in use in bin.\n",
      "2023-08-11 19:18:51.045563: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 3, Chunks in use: 3. 351.8KiB allocated for chunks. 351.8KiB in use in bin. 351.6KiB client-requested in use in bin.\n",
      "2023-08-11 19:18:51.045565: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 1, Chunks in use: 0. 168.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-08-11 19:18:51.045567: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-08-11 19:18:51.045569: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 72, Chunks in use: 72. 52.17MiB allocated for chunks. 52.17MiB in use in bin. 52.17MiB client-requested in use in bin.\n",
      "2023-08-11 19:18:51.045571: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-08-11 19:18:51.045572: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-08-11 19:18:51.045575: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 3, Chunks in use: 2. 13.73MiB allocated for chunks. 9.16MiB in use in bin. 9.16MiB client-requested in use in bin.\n",
      "2023-08-11 19:18:51.045576: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-08-11 19:18:51.045579: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 2, Chunks in use: 1. 44.13MiB allocated for chunks. 16.94MiB in use in bin. 16.94MiB client-requested in use in bin.\n",
      "2023-08-11 19:18:51.045580: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-08-11 19:18:51.045582: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 22, Chunks in use: 22. 1.99GiB allocated for chunks. 1.99GiB in use in bin. 1.99GiB client-requested in use in bin.\n",
      "2023-08-11 19:18:51.045588: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 22, Chunks in use: 22. 3.34GiB allocated for chunks. 3.34GiB in use in bin. 3.22GiB client-requested in use in bin.\n",
      "2023-08-11 19:18:51.045590: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 3, Chunks in use: 2. 15.71GiB allocated for chunks. 10.73GiB in use in bin. 10.73GiB client-requested in use in bin.\n",
      "2023-08-11 19:18:51.045592: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 5.37GiB was 256.00MiB, Chunk State: \n",
      "2023-08-11 19:18:51.045597: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 4.99GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 5.36GiB | Requested Size: 5.36GiB | in_use: 1 | bin_num: -1\n",
      "2023-08-11 19:18:51.045598: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 22718447616\n",
      "2023-08-11 19:18:51.045602: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1390000000 of size 70560000 next 1\n",
      "2023-08-11 19:18:51.045603: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f139434a900 of size 1280 next 2\n",
      "2023-08-11 19:18:51.045605: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f139434ae00 of size 56576 next 3\n",
      "2023-08-11 19:18:51.045607: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1394358b00 of size 256 next 4\n",
      "2023-08-11 19:18:51.045608: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1394358c00 of size 256 next 5\n",
      "2023-08-11 19:18:51.045610: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1394358d00 of size 256 next 6\n",
      "2023-08-11 19:18:51.045611: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1394358e00 of size 256 next 7\n",
      "2023-08-11 19:18:51.045612: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1394358f00 of size 256 next 8\n",
      "2023-08-11 19:18:51.045614: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1394359000 of size 17760000 next 9\n",
      "2023-08-11 19:18:51.045616: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1395448f00 of size 14336 next 10\n",
      "2023-08-11 19:18:51.045617: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f139544c700 of size 256 next 11\n",
      "2023-08-11 19:18:51.045618: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f139544c800 of size 256 next 12\n",
      "2023-08-11 19:18:51.045620: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f139544c900 of size 256 next 15\n",
      "2023-08-11 19:18:51.045621: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f139544ca00 of size 256 next 13\n",
      "2023-08-11 19:18:51.045623: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f139544cb00 of size 256 next 24\n",
      "2023-08-11 19:18:51.045624: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f139544cc00 of size 24064 next 14\n",
      "2023-08-11 19:18:51.045626: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1395452a00 of size 24064 next 21\n",
      "2023-08-11 19:18:51.045627: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1395458800 of size 24064 next 22\n",
      "2023-08-11 19:18:51.045629: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f139545e600 of size 24064 next 23\n",
      "2023-08-11 19:18:51.045630: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1395464400 of size 24064 next 20\n",
      "2023-08-11 19:18:51.045631: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f139546a200 of size 256 next 27\n",
      "2023-08-11 19:18:51.045633: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f139546a300 of size 256 next 30\n",
      "2023-08-11 19:18:51.045634: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f139546a400 of size 24064 next 31\n",
      "2023-08-11 19:18:51.045636: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1395470200 of size 256 next 32\n",
      "2023-08-11 19:18:51.045637: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1395470300 of size 24064 next 34\n",
      "2023-08-11 19:18:51.045639: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1395476100 of size 24064 next 35\n",
      "2023-08-11 19:18:51.045641: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f139547bf00 of size 46848 next 17\n",
      "2023-08-11 19:18:51.045642: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1395487600 of size 120064 next 18\n",
      "2023-08-11 19:18:51.045644: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f13954a4b00 of size 144000000 next 195\n",
      "2023-08-11 19:18:51.045645: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f139ddf8f00 of size 144000000 next 19\n",
      "2023-08-11 19:18:51.045647: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f13a674d300 of size 144000000 next 16\n",
      "2023-08-11 19:18:51.045648: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f13af0a1700 of size 24064 next 39\n",
      "2023-08-11 19:18:51.045650: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f13af0a7500 of size 24064 next 36\n",
      "2023-08-11 19:18:51.045651: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f13af0ad300 of size 24064 next 37\n",
      "2023-08-11 19:18:51.045652: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f13af0b3100 of size 24064 next 43\n",
      "2023-08-11 19:18:51.045654: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f13af0b8f00 of size 24064 next 45\n",
      "2023-08-11 19:18:51.045655: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f13af0bed00 of size 256 next 46\n",
      "2023-08-11 19:18:51.045657: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f13af0bee00 of size 256 next 47\n",
      "2023-08-11 19:18:51.045658: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f13af0bef00 of size 512 next 48\n",
      "2023-08-11 19:18:51.045659: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f13af0bf100 of size 256 next 49\n",
      "2023-08-11 19:18:51.045661: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f13af0bf200 of size 256 next 52\n",
      "2023-08-11 19:18:51.045662: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f13af0bf300 of size 143998208 next 26\n",
      "2023-08-11 19:18:51.045664: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f13b7a13000 of size 144120064 next 25\n",
      "2023-08-11 19:18:51.045665: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f13c0384900 of size 144120064 next 28\n",
      "2023-08-11 19:18:51.045667: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f13c8cf6200 of size 144120064 next 29\n",
      "2023-08-11 19:18:51.045668: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f13d1667b00 of size 144120064 next 33\n",
      "2023-08-11 19:18:51.045670: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f13d9fd9400 of size 144120064 next 38\n",
      "2023-08-11 19:18:51.045671: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f13e294ad00 of size 144120064 next 41\n",
      "2023-08-11 19:18:51.045672: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f13eb2bc600 of size 144120064 next 40\n",
      "2023-08-11 19:18:51.045674: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f13f3c2df00 of size 144120064 next 42\n",
      "2023-08-11 19:18:51.045675: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f13fc59f800 of size 144120064 next 44\n",
      "2023-08-11 19:18:51.045677: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1404f11100 of size 98385920 next 56\n",
      "2023-08-11 19:18:51.045678: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace5100 of size 256 next 54\n",
      "2023-08-11 19:18:51.045680: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace5200 of size 256 next 53\n",
      "2023-08-11 19:18:51.045681: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace5300 of size 256 next 55\n",
      "2023-08-11 19:18:51.045682: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace5400 of size 256 next 58\n",
      "2023-08-11 19:18:51.045684: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace5500 of size 256 next 57\n",
      "2023-08-11 19:18:51.045685: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace5600 of size 256 next 63\n",
      "2023-08-11 19:18:51.045687: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace5700 of size 512 next 59\n",
      "2023-08-11 19:18:51.045689: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace5900 of size 256 next 64\n",
      "2023-08-11 19:18:51.045690: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace5a00 of size 256 next 72\n",
      "2023-08-11 19:18:51.045691: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace5b00 of size 256 next 74\n",
      "2023-08-11 19:18:51.045693: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace5c00 of size 256 next 76\n",
      "2023-08-11 19:18:51.045694: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace5d00 of size 512 next 69\n",
      "2023-08-11 19:18:51.045696: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace5f00 of size 256 next 71\n",
      "2023-08-11 19:18:51.045697: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace6000 of size 256 next 82\n",
      "2023-08-11 19:18:51.045698: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace6100 of size 256 next 84\n",
      "2023-08-11 19:18:51.045700: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace6200 of size 256 next 86\n",
      "2023-08-11 19:18:51.045701: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace6300 of size 512 next 80\n",
      "2023-08-11 19:18:51.045703: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace6500 of size 256 next 81\n",
      "2023-08-11 19:18:51.045704: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace6600 of size 256 next 92\n",
      "2023-08-11 19:18:51.045705: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace6700 of size 256 next 94\n",
      "2023-08-11 19:18:51.045707: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace6800 of size 256 next 96\n",
      "2023-08-11 19:18:51.045708: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace6900 of size 512 next 89\n",
      "2023-08-11 19:18:51.045710: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace6b00 of size 256 next 91\n",
      "2023-08-11 19:18:51.045711: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace6c00 of size 256 next 102\n",
      "2023-08-11 19:18:51.045713: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace6d00 of size 256 next 104\n",
      "2023-08-11 19:18:51.045714: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace6e00 of size 256 next 106\n",
      "2023-08-11 19:18:51.045715: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace6f00 of size 512 next 100\n",
      "2023-08-11 19:18:51.045717: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace7100 of size 256 next 101\n",
      "2023-08-11 19:18:51.045718: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace7200 of size 256 next 112\n",
      "2023-08-11 19:18:51.045720: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace7300 of size 256 next 114\n",
      "2023-08-11 19:18:51.045721: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace7400 of size 256 next 116\n",
      "2023-08-11 19:18:51.045722: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace7500 of size 512 next 109\n",
      "2023-08-11 19:18:51.045724: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace7700 of size 256 next 111\n",
      "2023-08-11 19:18:51.045725: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace7800 of size 256 next 122\n",
      "2023-08-11 19:18:51.045727: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace7900 of size 256 next 124\n",
      "2023-08-11 19:18:51.045728: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace7a00 of size 256 next 126\n",
      "2023-08-11 19:18:51.045729: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace7b00 of size 512 next 120\n",
      "2023-08-11 19:18:51.045731: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace7d00 of size 256 next 121\n",
      "2023-08-11 19:18:51.045732: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace7e00 of size 256 next 132\n",
      "2023-08-11 19:18:51.045734: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace7f00 of size 256 next 134\n",
      "2023-08-11 19:18:51.045736: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace8000 of size 256 next 136\n",
      "2023-08-11 19:18:51.045737: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace8100 of size 256 next 129\n",
      "2023-08-11 19:18:51.045738: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace8200 of size 256 next 131\n",
      "2023-08-11 19:18:51.045740: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace8300 of size 256 next 138\n",
      "2023-08-11 19:18:51.045741: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace8400 of size 256 next 139\n",
      "2023-08-11 19:18:51.045743: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace8500 of size 256 next 140\n",
      "2023-08-11 19:18:51.045744: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace8600 of size 256 next 141\n",
      "2023-08-11 19:18:51.045745: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace8700 of size 256 next 142\n",
      "2023-08-11 19:18:51.045747: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace8800 of size 256 next 143\n",
      "2023-08-11 19:18:51.045748: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace8900 of size 256 next 144\n",
      "2023-08-11 19:18:51.045750: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace8a00 of size 256 next 145\n",
      "2023-08-11 19:18:51.045751: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace8b00 of size 256 next 146\n",
      "2023-08-11 19:18:51.045752: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace8c00 of size 256 next 147\n",
      "2023-08-11 19:18:51.045754: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace8d00 of size 256 next 148\n",
      "2023-08-11 19:18:51.045755: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace8e00 of size 256 next 149\n",
      "2023-08-11 19:18:51.045757: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace8f00 of size 256 next 150\n",
      "2023-08-11 19:18:51.045758: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace9000 of size 256 next 151\n",
      "2023-08-11 19:18:51.045759: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace9100 of size 256 next 152\n",
      "2023-08-11 19:18:51.045761: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace9200 of size 256 next 153\n",
      "2023-08-11 19:18:51.045762: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace9300 of size 256 next 154\n",
      "2023-08-11 19:18:51.045764: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace9400 of size 256 next 155\n",
      "2023-08-11 19:18:51.045765: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace9500 of size 256 next 156\n",
      "2023-08-11 19:18:51.045766: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace9600 of size 256 next 157\n",
      "2023-08-11 19:18:51.045768: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace9700 of size 256 next 158\n",
      "2023-08-11 19:18:51.045769: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace9800 of size 256 next 159\n",
      "2023-08-11 19:18:51.045771: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace9900 of size 256 next 160\n",
      "2023-08-11 19:18:51.045772: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace9a00 of size 256 next 161\n",
      "2023-08-11 19:18:51.045773: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace9b00 of size 256 next 162\n",
      "2023-08-11 19:18:51.045775: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace9c00 of size 256 next 163\n",
      "2023-08-11 19:18:51.045776: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace9d00 of size 256 next 164\n",
      "2023-08-11 19:18:51.045778: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace9e00 of size 256 next 165\n",
      "2023-08-11 19:18:51.045779: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ace9f00 of size 256 next 166\n",
      "2023-08-11 19:18:51.045781: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140acea000 of size 256 next 167\n",
      "2023-08-11 19:18:51.045782: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140acea100 of size 256 next 168\n",
      "2023-08-11 19:18:51.045783: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140acea200 of size 256 next 169\n",
      "2023-08-11 19:18:51.045785: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140acea300 of size 256 next 170\n",
      "2023-08-11 19:18:51.045786: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140acea400 of size 256 next 171\n",
      "2023-08-11 19:18:51.045788: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140acea500 of size 256 next 172\n",
      "2023-08-11 19:18:51.045789: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140acea600 of size 256 next 173\n",
      "2023-08-11 19:18:51.045790: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140acea700 of size 256 next 174\n",
      "2023-08-11 19:18:51.045792: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140acea800 of size 256 next 175\n",
      "2023-08-11 19:18:51.045793: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140acea900 of size 256 next 176\n",
      "2023-08-11 19:18:51.045795: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140aceaa00 of size 256 next 177\n",
      "2023-08-11 19:18:51.045796: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140aceab00 of size 256 next 178\n",
      "2023-08-11 19:18:51.045797: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140aceac00 of size 256 next 179\n",
      "2023-08-11 19:18:51.045799: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140acead00 of size 256 next 180\n",
      "2023-08-11 19:18:51.045801: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140aceae00 of size 256 next 181\n",
      "2023-08-11 19:18:51.045802: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140aceaf00 of size 256 next 182\n",
      "2023-08-11 19:18:51.045803: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140aceb000 of size 256 next 183\n",
      "2023-08-11 19:18:51.045805: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140aceb100 of size 256 next 184\n",
      "2023-08-11 19:18:51.045806: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140aceb200 of size 256 next 185\n",
      "2023-08-11 19:18:51.045808: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140aceb300 of size 256 next 186\n",
      "2023-08-11 19:18:51.045809: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140aceb400 of size 256 next 187\n",
      "2023-08-11 19:18:51.045810: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140aceb500 of size 256 next 188\n",
      "2023-08-11 19:18:51.045812: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140aceb600 of size 256 next 189\n",
      "2023-08-11 19:18:51.045813: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140aceb700 of size 256 next 190\n",
      "2023-08-11 19:18:51.045815: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140aceb800 of size 256 next 191\n",
      "2023-08-11 19:18:51.045816: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140aceb900 of size 256 next 192\n",
      "2023-08-11 19:18:51.045817: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140aceba00 of size 256 next 193\n",
      "2023-08-11 19:18:51.045819: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140acebb00 of size 120064 next 194\n",
      "2023-08-11 19:18:51.045820: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad09000 of size 24064 next 196\n",
      "2023-08-11 19:18:51.045822: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad0ee00 of size 24064 next 197\n",
      "2023-08-11 19:18:51.045823: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad14c00 of size 24064 next 198\n",
      "2023-08-11 19:18:51.045825: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad1aa00 of size 24064 next 199\n",
      "2023-08-11 19:18:51.045826: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad20800 of size 24064 next 200\n",
      "2023-08-11 19:18:51.045828: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad26600 of size 24064 next 201\n",
      "2023-08-11 19:18:51.045829: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2c400 of size 256 next 202\n",
      "2023-08-11 19:18:51.045830: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2c500 of size 256 next 203\n",
      "2023-08-11 19:18:51.045832: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2c600 of size 256 next 204\n",
      "2023-08-11 19:18:51.045833: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2c700 of size 256 next 205\n",
      "2023-08-11 19:18:51.045835: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2c800 of size 256 next 207\n",
      "2023-08-11 19:18:51.045836: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2c900 of size 256 next 209\n",
      "2023-08-11 19:18:51.045837: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2ca00 of size 256 next 211\n",
      "2023-08-11 19:18:51.045839: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2cb00 of size 256 next 213\n",
      "2023-08-11 19:18:51.045840: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2cc00 of size 256 next 215\n",
      "2023-08-11 19:18:51.045842: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2cd00 of size 256 next 216\n",
      "2023-08-11 19:18:51.045843: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2ce00 of size 256 next 218\n",
      "2023-08-11 19:18:51.045845: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2cf00 of size 256 next 220\n",
      "2023-08-11 19:18:51.045846: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2d000 of size 256 next 222\n",
      "2023-08-11 19:18:51.045847: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2d100 of size 256 next 224\n",
      "2023-08-11 19:18:51.045849: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2d200 of size 256 next 226\n",
      "2023-08-11 19:18:51.045850: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2d300 of size 256 next 228\n",
      "2023-08-11 19:18:51.045852: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2d400 of size 256 next 230\n",
      "2023-08-11 19:18:51.045853: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2d500 of size 256 next 232\n",
      "2023-08-11 19:18:51.045854: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2d600 of size 256 next 234\n",
      "2023-08-11 19:18:51.045856: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2d700 of size 256 next 236\n",
      "2023-08-11 19:18:51.045857: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2d800 of size 256 next 238\n",
      "2023-08-11 19:18:51.045859: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2d900 of size 256 next 240\n",
      "2023-08-11 19:18:51.045860: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2da00 of size 256 next 242\n",
      "2023-08-11 19:18:51.045861: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2db00 of size 256 next 244\n",
      "2023-08-11 19:18:51.045863: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2dc00 of size 256 next 246\n",
      "2023-08-11 19:18:51.045864: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2dd00 of size 256 next 248\n",
      "2023-08-11 19:18:51.045866: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2de00 of size 256 next 250\n",
      "2023-08-11 19:18:51.045867: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2df00 of size 256 next 252\n",
      "2023-08-11 19:18:51.045868: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2e000 of size 256 next 254\n",
      "2023-08-11 19:18:51.045870: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2e100 of size 256 next 256\n",
      "2023-08-11 19:18:51.045871: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2e200 of size 256 next 258\n",
      "2023-08-11 19:18:51.045873: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2e300 of size 256 next 260\n",
      "2023-08-11 19:18:51.045876: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad2e400 of size 120064 next 261\n",
      "2023-08-11 19:18:51.045880: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad4b900 of size 24064 next 263\n",
      "2023-08-11 19:18:51.045882: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad51700 of size 24064 next 264\n",
      "2023-08-11 19:18:51.045884: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad57500 of size 24064 next 265\n",
      "2023-08-11 19:18:51.045885: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad5d300 of size 24064 next 266\n",
      "2023-08-11 19:18:51.045887: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad63100 of size 24064 next 267\n",
      "2023-08-11 19:18:51.045888: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad68f00 of size 24064 next 268\n",
      "2023-08-11 19:18:51.045890: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad6ed00 of size 256 next 270\n",
      "2023-08-11 19:18:51.045891: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad6ee00 of size 256 next 272\n",
      "2023-08-11 19:18:51.045892: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad6ef00 of size 256 next 274\n",
      "2023-08-11 19:18:51.045894: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad6f000 of size 256 next 276\n",
      "2023-08-11 19:18:51.045895: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad6f100 of size 256 next 278\n",
      "2023-08-11 19:18:51.045897: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad6f200 of size 256 next 280\n",
      "2023-08-11 19:18:51.045898: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad6f300 of size 256 next 282\n",
      "2023-08-11 19:18:51.045899: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad6f400 of size 256 next 284\n",
      "2023-08-11 19:18:51.045901: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad6f500 of size 256 next 286\n",
      "2023-08-11 19:18:51.045902: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad6f600 of size 256 next 288\n",
      "2023-08-11 19:18:51.045904: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad6f700 of size 256 next 290\n",
      "2023-08-11 19:18:51.045905: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad6f800 of size 256 next 292\n",
      "2023-08-11 19:18:51.045907: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad6f900 of size 256 next 294\n",
      "2023-08-11 19:18:51.045908: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad6fa00 of size 256 next 296\n",
      "2023-08-11 19:18:51.045909: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad6fb00 of size 256 next 298\n",
      "2023-08-11 19:18:51.045911: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad6fc00 of size 256 next 300\n",
      "2023-08-11 19:18:51.045912: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad6fd00 of size 256 next 302\n",
      "2023-08-11 19:18:51.045914: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad6fe00 of size 256 next 304\n",
      "2023-08-11 19:18:51.045915: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad6ff00 of size 256 next 306\n",
      "2023-08-11 19:18:51.045916: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad70000 of size 256 next 308\n",
      "2023-08-11 19:18:51.045918: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad70100 of size 256 next 310\n",
      "2023-08-11 19:18:51.045919: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad70200 of size 256 next 312\n",
      "2023-08-11 19:18:51.045921: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad70300 of size 256 next 314\n",
      "2023-08-11 19:18:51.045922: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad70400 of size 256 next 316\n",
      "2023-08-11 19:18:51.045924: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad70500 of size 256 next 318\n",
      "2023-08-11 19:18:51.045925: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad70600 of size 256 next 320\n",
      "2023-08-11 19:18:51.045926: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad70700 of size 256 next 322\n",
      "2023-08-11 19:18:51.045928: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad70800 of size 256 next 324\n",
      "2023-08-11 19:18:51.045929: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad70900 of size 256 next 326\n",
      "2023-08-11 19:18:51.045931: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad70a00 of size 256 next 328\n",
      "2023-08-11 19:18:51.045932: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad70b00 of size 256 next 330\n",
      "2023-08-11 19:18:51.045934: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad70c00 of size 256 next 332\n",
      "2023-08-11 19:18:51.045935: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad70d00 of size 256 next 333\n",
      "2023-08-11 19:18:51.045939: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad70e00 of size 256 next 334\n",
      "2023-08-11 19:18:51.045941: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad70f00 of size 256 next 335\n",
      "2023-08-11 19:18:51.045944: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad71000 of size 256 next 336\n",
      "2023-08-11 19:18:51.045947: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad71100 of size 256 next 337\n",
      "2023-08-11 19:18:51.045950: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad71200 of size 256 next 338\n",
      "2023-08-11 19:18:51.045952: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad71300 of size 256 next 339\n",
      "2023-08-11 19:18:51.045953: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad71400 of size 256 next 340\n",
      "2023-08-11 19:18:51.045954: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad71500 of size 256 next 341\n",
      "2023-08-11 19:18:51.045956: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad71600 of size 256 next 342\n",
      "2023-08-11 19:18:51.045957: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad71700 of size 256 next 343\n",
      "2023-08-11 19:18:51.045959: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad71800 of size 256 next 344\n",
      "2023-08-11 19:18:51.045960: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad71900 of size 256 next 345\n",
      "2023-08-11 19:18:51.045961: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad71a00 of size 256 next 346\n",
      "2023-08-11 19:18:51.045963: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad71b00 of size 256 next 347\n",
      "2023-08-11 19:18:51.045964: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad71c00 of size 256 next 348\n",
      "2023-08-11 19:18:51.045966: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad71d00 of size 256 next 349\n",
      "2023-08-11 19:18:51.045967: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad71e00 of size 256 next 350\n",
      "2023-08-11 19:18:51.045969: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad71f00 of size 256 next 351\n",
      "2023-08-11 19:18:51.045970: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad72000 of size 256 next 352\n",
      "2023-08-11 19:18:51.045971: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad72100 of size 256 next 357\n",
      "2023-08-11 19:18:51.045973: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad72200 of size 256 next 359\n",
      "2023-08-11 19:18:51.045974: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad72300 of size 256 next 360\n",
      "2023-08-11 19:18:51.045976: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad72400 of size 256 next 362\n",
      "2023-08-11 19:18:51.045977: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad72500 of size 256 next 363\n",
      "2023-08-11 19:18:51.045978: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad72600 of size 256 next 364\n",
      "2023-08-11 19:18:51.045980: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad72700 of size 256 next 365\n",
      "2023-08-11 19:18:51.045981: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad72800 of size 256 next 366\n",
      "2023-08-11 19:18:51.045983: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad72900 of size 256 next 367\n",
      "2023-08-11 19:18:51.045984: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad72a00 of size 256 next 368\n",
      "2023-08-11 19:18:51.045986: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad72b00 of size 256 next 369\n",
      "2023-08-11 19:18:51.045987: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad72c00 of size 256 next 370\n",
      "2023-08-11 19:18:51.045988: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad72d00 of size 256 next 371\n",
      "2023-08-11 19:18:51.045990: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad72e00 of size 256 next 372\n",
      "2023-08-11 19:18:51.045991: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad72f00 of size 256 next 373\n",
      "2023-08-11 19:18:51.045993: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad73000 of size 256 next 374\n",
      "2023-08-11 19:18:51.045994: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad73100 of size 256 next 375\n",
      "2023-08-11 19:18:51.045995: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad73200 of size 256 next 376\n",
      "2023-08-11 19:18:51.045997: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad73300 of size 256 next 377\n",
      "2023-08-11 19:18:51.045998: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad73400 of size 256 next 378\n",
      "2023-08-11 19:18:51.046000: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad73500 of size 256 next 379\n",
      "2023-08-11 19:18:51.046001: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad73600 of size 256 next 380\n",
      "2023-08-11 19:18:51.046002: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad73700 of size 256 next 381\n",
      "2023-08-11 19:18:51.046004: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad73800 of size 256 next 382\n",
      "2023-08-11 19:18:51.046005: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad73900 of size 256 next 383\n",
      "2023-08-11 19:18:51.046007: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad73a00 of size 256 next 384\n",
      "2023-08-11 19:18:51.046008: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad73b00 of size 256 next 385\n",
      "2023-08-11 19:18:51.046009: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f140ad73c00 of size 768 next 353\n",
      "2023-08-11 19:18:51.046011: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad73f00 of size 3840 next 355\n",
      "2023-08-11 19:18:51.046013: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f140ad74e00 of size 172288 next 60\n",
      "2023-08-11 19:18:51.046014: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ad9ef00 of size 759808 next 61\n",
      "2023-08-11 19:18:51.046016: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ae58700 of size 759808 next 62\n",
      "2023-08-11 19:18:51.046017: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140af11f00 of size 759808 next 214\n",
      "2023-08-11 19:18:51.046019: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140afcb700 of size 759808 next 66\n",
      "2023-08-11 19:18:51.046020: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140b084f00 of size 759808 next 65\n",
      "2023-08-11 19:18:51.046021: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140b13e700 of size 759808 next 73\n",
      "2023-08-11 19:18:51.046023: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140b1f7f00 of size 759808 next 75\n",
      "2023-08-11 19:18:51.046024: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140b2b1700 of size 759808 next 77\n",
      "2023-08-11 19:18:51.046026: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140b36af00 of size 759808 next 83\n",
      "2023-08-11 19:18:51.046027: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140b424700 of size 759808 next 85\n",
      "2023-08-11 19:18:51.046029: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140b4ddf00 of size 759808 next 87\n",
      "2023-08-11 19:18:51.046030: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140b597700 of size 759808 next 93\n",
      "2023-08-11 19:18:51.046032: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140b650f00 of size 759808 next 95\n",
      "2023-08-11 19:18:51.046033: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140b70a700 of size 759808 next 97\n",
      "2023-08-11 19:18:51.046034: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140b7c3f00 of size 759808 next 103\n",
      "2023-08-11 19:18:51.046036: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140b87d700 of size 759808 next 105\n",
      "2023-08-11 19:18:51.046038: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140b936f00 of size 759808 next 107\n",
      "2023-08-11 19:18:51.046039: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140b9f0700 of size 759808 next 113\n",
      "2023-08-11 19:18:51.046041: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140baa9f00 of size 759808 next 115\n",
      "2023-08-11 19:18:51.046042: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140bb63700 of size 759808 next 117\n",
      "2023-08-11 19:18:51.046043: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140bc1cf00 of size 759808 next 123\n",
      "2023-08-11 19:18:51.046045: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140bcd6700 of size 759808 next 125\n",
      "2023-08-11 19:18:51.046046: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140bd8ff00 of size 759808 next 127\n",
      "2023-08-11 19:18:51.046048: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140be49700 of size 759808 next 133\n",
      "2023-08-11 19:18:51.046049: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140bf02f00 of size 759808 next 135\n",
      "2023-08-11 19:18:51.046051: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140bfbc700 of size 759808 next 137\n",
      "2023-08-11 19:18:51.046052: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140c075f00 of size 759808 next 217\n",
      "2023-08-11 19:18:51.046054: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140c12f700 of size 759808 next 219\n",
      "2023-08-11 19:18:51.046055: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140c1e8f00 of size 759808 next 221\n",
      "2023-08-11 19:18:51.046057: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140c2a2700 of size 759808 next 223\n",
      "2023-08-11 19:18:51.046058: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140c35bf00 of size 759808 next 225\n",
      "2023-08-11 19:18:51.046060: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140c415700 of size 759808 next 227\n",
      "2023-08-11 19:18:51.046061: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140c4cef00 of size 759808 next 229\n",
      "2023-08-11 19:18:51.046064: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140c588700 of size 759808 next 231\n",
      "2023-08-11 19:18:51.046065: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140c641f00 of size 759808 next 233\n",
      "2023-08-11 19:18:51.046067: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140c6fb700 of size 759808 next 235\n",
      "2023-08-11 19:18:51.046068: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140c7b4f00 of size 759808 next 237\n",
      "2023-08-11 19:18:51.046070: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140c86e700 of size 759808 next 239\n",
      "2023-08-11 19:18:51.046071: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140c927f00 of size 759808 next 241\n",
      "2023-08-11 19:18:51.046073: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140c9e1700 of size 759808 next 243\n",
      "2023-08-11 19:18:51.046074: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ca9af00 of size 759808 next 245\n",
      "2023-08-11 19:18:51.046076: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140cb54700 of size 759808 next 247\n",
      "2023-08-11 19:18:51.046077: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140cc0df00 of size 759808 next 249\n",
      "2023-08-11 19:18:51.046079: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ccc7700 of size 759808 next 251\n",
      "2023-08-11 19:18:51.046080: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140cd80f00 of size 759808 next 253\n",
      "2023-08-11 19:18:51.046082: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140ce3a700 of size 759808 next 255\n",
      "2023-08-11 19:18:51.046083: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140cef3f00 of size 759808 next 257\n",
      "2023-08-11 19:18:51.046085: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140cfad700 of size 759808 next 259\n",
      "2023-08-11 19:18:51.046086: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140d066f00 of size 759808 next 285\n",
      "2023-08-11 19:18:51.046087: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140d120700 of size 759808 next 287\n",
      "2023-08-11 19:18:51.046089: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140d1d9f00 of size 759808 next 289\n",
      "2023-08-11 19:18:51.046090: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140d293700 of size 759808 next 291\n",
      "2023-08-11 19:18:51.046092: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140d34cf00 of size 759808 next 293\n",
      "2023-08-11 19:18:51.046093: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140d406700 of size 759808 next 295\n",
      "2023-08-11 19:18:51.046095: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140d4bff00 of size 759808 next 297\n",
      "2023-08-11 19:18:51.046096: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140d579700 of size 759808 next 299\n",
      "2023-08-11 19:18:51.046098: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140d632f00 of size 759808 next 301\n",
      "2023-08-11 19:18:51.046099: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140d6ec700 of size 759808 next 303\n",
      "2023-08-11 19:18:51.046101: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140d7a5f00 of size 759808 next 305\n",
      "2023-08-11 19:18:51.046102: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140d85f700 of size 759808 next 307\n",
      "2023-08-11 19:18:51.046104: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140d918f00 of size 759808 next 309\n",
      "2023-08-11 19:18:51.046105: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140d9d2700 of size 759808 next 311\n",
      "2023-08-11 19:18:51.046106: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140da8bf00 of size 759808 next 313\n",
      "2023-08-11 19:18:51.046108: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140db45700 of size 759808 next 315\n",
      "2023-08-11 19:18:51.046109: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140dbfef00 of size 759808 next 317\n",
      "2023-08-11 19:18:51.046111: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140dcb8700 of size 759808 next 319\n",
      "2023-08-11 19:18:51.046112: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140dd71f00 of size 759808 next 321\n",
      "2023-08-11 19:18:51.046114: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140de2b700 of size 759808 next 323\n",
      "2023-08-11 19:18:51.046115: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140dee4f00 of size 759808 next 325\n",
      "2023-08-11 19:18:51.046117: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140df9e700 of size 759808 next 327\n",
      "2023-08-11 19:18:51.046118: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140e057f00 of size 759808 next 329\n",
      "2023-08-11 19:18:51.046120: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140e111700 of size 759808 next 331\n",
      "2023-08-11 19:18:51.046121: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140e1caf00 of size 4800000 next 361\n",
      "2023-08-11 19:18:51.046123: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f140e65ed00 of size 4800000 next 354\n",
      "2023-08-11 19:18:51.046124: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f140eaf2b00 of size 4800000 next 356\n",
      "2023-08-11 19:18:51.046126: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f140ef86900 of size 28518400 next 51\n",
      "2023-08-11 19:18:51.046128: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1410ab9100 of size 196771840 next 50\n",
      "2023-08-11 19:18:51.046129: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f141c661100 of size 98385920 next 70\n",
      "2023-08-11 19:18:51.046131: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1422435100 of size 98385920 next 68\n",
      "2023-08-11 19:18:51.046132: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1428209100 of size 196771840 next 67\n",
      "2023-08-11 19:18:51.046134: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1433db1100 of size 98385920 next 90\n",
      "2023-08-11 19:18:51.046135: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1439b85100 of size 98385920 next 79\n",
      "2023-08-11 19:18:51.046137: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f143f959100 of size 196771840 next 78\n",
      "2023-08-11 19:18:51.046138: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f144b501100 of size 196771840 next 88\n",
      "2023-08-11 19:18:51.046140: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f14570a9100 of size 98385920 next 110\n",
      "2023-08-11 19:18:51.046141: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f145ce7d100 of size 98385920 next 99\n",
      "2023-08-11 19:18:51.046143: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1462c51100 of size 196771840 next 98\n",
      "2023-08-11 19:18:51.046144: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f146e7f9100 of size 196771840 next 108\n",
      "2023-08-11 19:18:51.046146: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f147a3a1100 of size 98385920 next 130\n",
      "2023-08-11 19:18:51.046147: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1480175100 of size 98385920 next 119\n",
      "2023-08-11 19:18:51.046149: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1485f49100 of size 196771840 next 118\n",
      "2023-08-11 19:18:51.046150: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1491af1100 of size 196771840 next 128\n",
      "2023-08-11 19:18:51.046152: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f149d699100 of size 98385920 next 206\n",
      "2023-08-11 19:18:51.046153: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f14a346d100 of size 98385920 next 208\n",
      "2023-08-11 19:18:51.046155: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f14a9241100 of size 98385920 next 210\n",
      "2023-08-11 19:18:51.046156: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f14af015100 of size 98385920 next 212\n",
      "2023-08-11 19:18:51.046158: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f14b4de9100 of size 144000000 next 262\n",
      "2023-08-11 19:18:51.046159: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f14bd73d500 of size 98385920 next 269\n",
      "2023-08-11 19:18:51.046161: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f14c3511500 of size 98385920 next 271\n",
      "2023-08-11 19:18:51.046162: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f14c92e5500 of size 98385920 next 273\n",
      "2023-08-11 19:18:51.046164: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f14cf0b9500 of size 98385920 next 275\n",
      "2023-08-11 19:18:51.046165: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f14d4e8d500 of size 98385920 next 277\n",
      "2023-08-11 19:18:51.046167: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f14dac61500 of size 98385920 next 279\n",
      "2023-08-11 19:18:51.046168: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f14e0a35500 of size 98385920 next 281\n",
      "2023-08-11 19:18:51.046169: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f14e6809500 of size 98385920 next 283\n",
      "2023-08-11 19:18:51.046171: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f14ec5dd500 of size 5760000000 next 358\n",
      "2023-08-11 19:18:51.046173: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1643b07500 of size 5760000000 next 386\n",
      "2023-08-11 19:18:51.046175: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f179b031500 of size 5353827072 next 18446744073709551615\n",
      "2023-08-11 19:18:51.046176: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2023-08-11 19:18:51.046179: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 220 Chunks of size 256 totalling 55.0KiB\n",
      "2023-08-11 19:18:51.046181: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 8 Chunks of size 512 totalling 4.0KiB\n",
      "2023-08-11 19:18:51.046182: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-08-11 19:18:51.046184: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 3840 totalling 3.8KiB\n",
      "2023-08-11 19:18:51.046186: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 14336 totalling 14.0KiB\n",
      "2023-08-11 19:18:51.046188: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 25 Chunks of size 24064 totalling 587.5KiB\n",
      "2023-08-11 19:18:51.046189: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 46848 totalling 45.8KiB\n",
      "2023-08-11 19:18:51.046191: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 56576 totalling 55.2KiB\n",
      "2023-08-11 19:18:51.046193: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 120064 totalling 351.8KiB\n",
      "2023-08-11 19:18:51.046194: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 72 Chunks of size 759808 totalling 52.17MiB\n",
      "2023-08-11 19:18:51.046196: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 4800000 totalling 9.16MiB\n",
      "2023-08-11 19:18:51.046198: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 17760000 totalling 16.94MiB\n",
      "2023-08-11 19:18:51.046200: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 70560000 totalling 67.29MiB\n",
      "2023-08-11 19:18:51.046201: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 21 Chunks of size 98385920 totalling 1.92GiB\n",
      "2023-08-11 19:18:51.046203: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 143998208 totalling 137.33MiB\n",
      "2023-08-11 19:18:51.046205: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 144000000 totalling 549.32MiB\n",
      "2023-08-11 19:18:51.046206: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 9 Chunks of size 144120064 totalling 1.21GiB\n",
      "2023-08-11 19:18:51.046208: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 8 Chunks of size 196771840 totalling 1.47GiB\n",
      "2023-08-11 19:18:51.046210: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 5760000000 totalling 10.73GiB\n",
      "2023-08-11 19:18:51.046212: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 16.14GiB\n",
      "2023-08-11 19:18:51.046213: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 22718447616 memory_limit_: 22718447616 available bytes: 0 curr_region_allocation_bytes_: 45436895232\n",
      "2023-08-11 19:18:51.046218: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                     22718447616\n",
      "InUse:                     17331129088\n",
      "MaxInUse:                  17331129088\n",
      "NumAllocs:                         652\n",
      "MaxAllocSize:               5760000000\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-08-11 19:18:51.046224: W tensorflow/tsl/framework/bfc_allocator.cc:497] *****************************************************************************_______________________\n",
      "2023-08-11 19:18:51.046239: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at concat_op.cc:163 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[40,6000,6005] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "2023-08-11 19:18:51.046258: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[40,6000,6005] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node model/time2_vec/concat}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/base_tuner.py\", line 270, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/base_tuner.py\", line 235, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/tuner.py\", line 287, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/tuner.py\", line 214, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/hypermodel.py\", line 144, in fit\n",
      "    return model.fit(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/tensorflow/python/eager/execute.py\", line 58, in quick_execute\n",
      "    except TypeError as e:\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:\n",
      "\n",
      "Detected at node 'model/time2_vec/concat' defined at (most recent call last):\n",
      "    File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "    File \"<frozen runpy>\", line 88, in _run_code\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "      app.launch_new_instance()\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "      app.start()\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 711, in start\n",
      "      self.io_loop.start()\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 215, in start\n",
      "      self.asyncio_loop.run_forever()\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "      self._run_once()\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "      handle._run()\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "      self._context.run(self._callback, *self._args)\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
      "      await self.process_one()\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
      "      await dispatch(*args)\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
      "      await result\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "      reply_content = await reply_content\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n",
      "      res = shell.run_cell(\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n",
      "      return super().run_cell(*args, **kwargs)\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n",
      "      result = self._run_cell(\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n",
      "      result = runner(coro)\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "      coro.send(None)\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n",
      "      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n",
      "      if await self.run_code(code, result, async_=asy):\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "      exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"/tmp/ipykernel_28177/2042983326.py\", line 121, in <module>\n",
      "      tuner.search(\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/base_tuner.py\", line 230, in search\n",
      "      self._try_run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/base_tuner.py\", line 270, in _try_run_and_update_trial\n",
      "      self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/base_tuner.py\", line 235, in _run_and_update_trial\n",
      "      results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/tuner.py\", line 287, in run_trial\n",
      "      obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/tuner.py\", line 214, in _build_and_fit_model\n",
      "      results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/hypermodel.py\", line 144, in fit\n",
      "      return model.fit(*args, **kwargs)\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/training.py\", line 1685, in fit\n",
      "      tmp_logs = self.train_function(iterator)\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/training.py\", line 1284, in train_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/training.py\", line 1268, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/training.py\", line 1249, in run_step\n",
      "      outputs = model.train_step(data)\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/training.py\", line 1050, in train_step\n",
      "      y_pred = self(x, training=True)\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/training.py\", line 558, in __call__\n",
      "      return super().__call__(*args, **kwargs)\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/functional.py\", line 512, in call\n",
      "      return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/tmp/ipykernel_28177/2654059636.py\", line 31, in call\n",
      "      return K.concatenate([sin_trans, original], -1)\n",
      "    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/backend.py\", line 3581, in concatenate\n",
      "      return tf.concat([to_dense(x) for x in tensors], axis)\n",
      "Node: 'model/time2_vec/concat'\n",
      "OOM when allocating tensor with shape[40,6000,6005] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node model/time2_vec/concat}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      " [Op:__inference_train_function_9129]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of consecutive failures excceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/base_tuner.py\", line 270, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/base_tuner.py\", line 235, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/tuner.py\", line 287, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/tuner.py\", line 214, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/hypermodel.py\", line 144, in fit\n    return model.fit(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/tensorflow/python/eager/execute.py\", line 58, in quick_execute\n    except TypeError as e:\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:\n\nDetected at node 'model/time2_vec/concat' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_28177/2042983326.py\", line 121, in <module>\n      tuner.search(\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/base_tuner.py\", line 230, in search\n      self._try_run_and_update_trial(trial, *fit_args, **fit_kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/base_tuner.py\", line 270, in _try_run_and_update_trial\n      self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/base_tuner.py\", line 235, in _run_and_update_trial\n      results = self.run_trial(trial, *fit_args, **fit_kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/tuner.py\", line 287, in run_trial\n      obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/tuner.py\", line 214, in _build_and_fit_model\n      results = self.hypermodel.fit(hp, model, *args, **kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/hypermodel.py\", line 144, in fit\n      return model.fit(*args, **kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/tmp/ipykernel_28177/2654059636.py\", line 31, in call\n      return K.concatenate([sin_trans, original], -1)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/backend.py\", line 3581, in concatenate\n      return tf.concat([to_dense(x) for x in tensors], axis)\nNode: 'model/time2_vec/concat'\nOOM when allocating tensor with shape[40,6000,6005] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/time2_vec/concat}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_9129]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 121\u001b[0m\n\u001b[1;32m    111\u001b[0m tuner \u001b[38;5;241m=\u001b[39m RandomSearch(\n\u001b[1;32m    112\u001b[0m     build_model,\n\u001b[1;32m    113\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m     executions_per_trial\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    117\u001b[0m )\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Pass the callback to the search method\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m tuner\u001b[38;5;241m.\u001b[39msearch(\n\u001b[1;32m    122\u001b[0m     train_dataset,\n\u001b[1;32m    123\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mval_dataset,\n\u001b[1;32m    124\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m    125\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[PrintHyperparameters()],\n\u001b[1;32m    126\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/base_tuner.py:231\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/base_tuner.py:335\u001b[0m, in \u001b[0;36mBaseTuner.on_trial_end\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_trial_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial):\n\u001b[1;32m    330\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called at the end of a trial.\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m        trial: A `Trial` instance.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mend_trial(trial)\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;66;03m# Display needs the updated trial scored by the Oracle.\u001b[39;00m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_display\u001b[38;5;241m.\u001b[39mon_trial_end(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id))\n",
      "File \u001b[0;32m~/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/oracle.py:107\u001b[0m, in \u001b[0;36msynchronized.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m     LOCKS[oracle]\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    106\u001b[0m     THREADS[oracle] \u001b[38;5;241m=\u001b[39m thread_name\n\u001b[0;32m--> 107\u001b[0m ret_val \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_acquire:\n\u001b[1;32m    109\u001b[0m     THREADS[oracle] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/oracle.py:434\u001b[0m, in \u001b[0;36mOracle.end_trial\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry(trial):\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_order\u001b[38;5;241m.\u001b[39mappend(trial\u001b[38;5;241m.\u001b[39mtrial_id)\n\u001b[0;32m--> 434\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_consecutive_failures()\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_trial(trial)\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[0;32m~/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/oracle.py:386\u001b[0m, in \u001b[0;36mOracle._check_consecutive_failures\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    384\u001b[0m     consecutive_failures \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consecutive_failures \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_consecutive_failed_trials:\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of consecutive failures excceeded the limit \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_consecutive_failed_trials\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;241m+\u001b[39m trial\u001b[38;5;241m.\u001b[39mmessage\n\u001b[1;32m    390\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Number of consecutive failures excceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/base_tuner.py\", line 270, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/base_tuner.py\", line 235, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/tuner.py\", line 287, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/tuner.py\", line 214, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/hypermodel.py\", line 144, in fit\n    return model.fit(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/tensorflow/python/eager/execute.py\", line 58, in quick_execute\n    except TypeError as e:\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:\n\nDetected at node 'model/time2_vec/concat' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_28177/2042983326.py\", line 121, in <module>\n      tuner.search(\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/base_tuner.py\", line 230, in search\n      self._try_run_and_update_trial(trial, *fit_args, **fit_kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/base_tuner.py\", line 270, in _try_run_and_update_trial\n      self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/base_tuner.py\", line 235, in _run_and_update_trial\n      results = self.run_trial(trial, *fit_args, **fit_kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/tuner.py\", line 287, in run_trial\n      obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/tuner.py\", line 214, in _build_and_fit_model\n      results = self.hypermodel.fit(hp, model, *args, **kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras_tuner/engine/hypermodel.py\", line 144, in fit\n      return model.fit(*args, **kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/tmp/ipykernel_28177/2654059636.py\", line 31, in call\n      return K.concatenate([sin_trans, original], -1)\n    File \"/home/apollo/anaconda3/envs/tfm/lib/python3.11/site-packages/keras/backend.py\", line 3581, in concatenate\n      return tf.concat([to_dense(x) for x in tensors], axis)\nNode: 'model/time2_vec/concat'\nOOM when allocating tensor with shape[40,6000,6005] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/time2_vec/concat}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_9129]\n"
     ]
    }
   ],
   "source": [
    "# No necesariamente time to vec, otros metodos, coseno dia de la semana, del mes ...\n",
    "lookback = 6000\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "def build_model(hp):\n",
    "    input_shape = (lookback, 5)  # for example\n",
    "\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = Time2Vec(lookback)(input_layer)\n",
    "\n",
    "    decoder_layer_type = hp.Choice(\n",
    "        \"decoder_layer_type\", values=[\"conv\", \"dense\"], default=\"conv\"\n",
    "    )\n",
    "    num_transformer_layers = hp.Int(\n",
    "        \"num_transformer_layers\", min_value=1, max_value=2, step=1\n",
    "    )\n",
    "    num_attention_heads = hp.Int(\n",
    "        \"num_attention_heads\", min_value=1, max_value=4, step=1\n",
    "    )\n",
    "    dropout_rate = hp.Float(\"dropout_rate\", min_value=0.0, max_value=0.3, step=0.15)\n",
    "\n",
    "    for _ in range(num_transformer_layers, 0, -1):\n",
    "        mha = MultiHeadAttention(num_heads=num_attention_heads, key_dim=lookback)(x, x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        x = LayerNormalization()(x)\n",
    "\n",
    "    encoder_output = x\n",
    "    # Define output branches\n",
    "    outputs = []\n",
    "    losses = {}\n",
    "    for i in range(8):\n",
    "        if decoder_layer_type == \"conv\":\n",
    "            kernel_size = hp.Int(\"kernel_size\", min_value=16, max_value=64, step=16)\n",
    "            conv_layers = hp.Int(\"conv_layers\", min_value=1, max_value=2, step=1)\n",
    "            for j in range(conv_layers, 0, -1):\n",
    "                x = Conv1D(32 * (2**j), kernel_size)(encoder_output)\n",
    "            x = MaxPooling1D(2)(x)\n",
    "            x = Flatten()(x)\n",
    "        # elif decoder_layer_type == \"conv_lstm\":\n",
    "        #     kernel_size = hp.Int(\"kernel_size\", min_value=2, max_value=128, step=16)\n",
    "        #     conv_layers = hp.Int(\"conv_lstm_layers\", min_value=1, max_value=3, step=1)\n",
    "        #     for j in range(conv_layers, 0, -1):\n",
    "        #         x = ConvLSTM1D(32 * (2**j), kernel_size)(encoder_output)\n",
    "        #     x = MaxPooling1D(2)(x)\n",
    "        else:\n",
    "            dense_units = hp.Int(\"dense_units\", min_value=16, max_value=64, step=32)\n",
    "            dense_layers = hp.Int(\"dense_layers\", min_value=1, max_value=2, step=1)\n",
    "\n",
    "            for j in range(dense_layers, 0, -1):\n",
    "                x = Dense(dense_units * (2**j), activation=\"relu\")(encoder_output)\n",
    "            x = BatchNormalization()(x)\n",
    "        output_1 = Dense(1, name=f\"output_{i}_1_prediction\")(x)\n",
    "        output_2 = Dense(1, name=f\"output_{i}_2_quantile_05\")(x)\n",
    "        output_3 = Dense(1, name=f\"output_{i}_3_quantile_95\")(x)\n",
    "        losses[f\"output_{i}_1_prediction\"] = \"mse\"\n",
    "        losses[f\"output_{i}_2_quantile_05\"] = tfa.losses.PinballLoss(tau=0.05)\n",
    "        losses[f\"output_{i}_3_quantile_95\"] = tfa.losses.PinballLoss(tau=0.95)\n",
    "        outputs.extend([output_1, output_2, output_3])\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=outputs)\n",
    "\n",
    "    # Define losses\n",
    "    optimizer = hp.Choice(\"optimizer\", values=[\"Adam\", \"RMSprop\"])\n",
    "    opt = Adam if optimizer == \"Adam\" else RMSprop\n",
    "    model.compile(\n",
    "        loss=losses,\n",
    "        optimizer=opt(\n",
    "            learning_rate=hp.Float(\n",
    "                \"learning_rate\", min_value=1e-5, max_value=1e-2, sampling=\"LOG\"\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "class PrintHyperparameters(Callback):\n",
    "    def on_trial_begin(self, trial):\n",
    "        print(trial.hyperparameters.values)\n",
    "\n",
    "\n",
    "def create_dataset(input_data, target_data, batch_size, window_size):\n",
    "    # Create datasets\n",
    "    input_dataset = tf.data.Dataset.from_tensor_slices(input_data)\n",
    "    target_dataset = tf.data.Dataset.from_tensor_slices(target_data)\n",
    "\n",
    "    # Windowing the data. This will create windows of `window_size` for inputs and targets.\n",
    "    input_dataset = input_dataset.window(window_size, shift=1, drop_remainder=True)\n",
    "    input_dataset = input_dataset.flat_map(lambda x: x.batch(window_size))\n",
    "\n",
    "    target_dataset = target_dataset.window(window_size, shift=1, drop_remainder=True)\n",
    "    target_dataset = target_dataset.flat_map(lambda y: y.batch(window_size))\n",
    "\n",
    "    # Zip the datasets together\n",
    "    dataset = tf.data.Dataset.zip((input_dataset, target_dataset))\n",
    "\n",
    "    # Batching the data\n",
    "    dataset = dataset.batch(batch_size).prefetch(1)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "batch_size = 4\n",
    "window_size = 10\n",
    "\n",
    "train_dataset = create_dataset(train_input, train_target, batch_size, window_size)\n",
    "val_dataset = create_dataset(valid_input, valid_target, batch_size, window_size)\n",
    "train_dataset = train_dataset.map(lambda x, y: (tf.reshape(x, (-1, 6000, 5)), y))\n",
    "val_dataset = val_dataset.map(lambda x, y: (tf.reshape(x, (-1, 6000, 5)), y))\n",
    "\n",
    "# Tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective=\"val_loss\",\n",
    "    directory=\"random_search\",\n",
    "    project_name=\"TimeSeries\",\n",
    "    executions_per_trial=2,\n",
    ")\n",
    "\n",
    "\n",
    "# Pass the callback to the search method\n",
    "tuner.search(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=20,\n",
    "    callbacks=[PrintHyperparameters()],\n",
    ")\n",
    "#\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1bc384-bda4-4eaf-a44b-e941c5d85867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd951ef-876d-45ce-b834-a773d63a9fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
